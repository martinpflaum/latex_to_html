<!doctype html>
<head>
  <script src="https://distill.pub/template.v2.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css">
  <script src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/auto-render.min.js"></script>

  <link rel="icon" href="icon.png" type="image/png" sizes="16x16">
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf8">
</head>

<body>
  <!--<distill-header></distill-header>-->
  <!--"published": "1 9 2017",
{
        "author":"Shan Carter",
        "authorURL":"https://shancarter.com/",
        "affiliations": [
          {"name": "Google Brain", "url": "https://g.co/brain"},
          {"name": "NYT", "url": "https://nytimes.com"}
        ]
      }
-->
  <d-front-matter>
    <script id='distill-front-matter' type="text/json"></script>

  </d-front-matter>
  <d-title>
    <p></p>
  </d-title>
  <d-byline></d-byline>

<!---
"""
<ol class="enumeration" type="1">
  <li value="(O1)">This is item three.</li>
  <li value="(O2)">This is item fifty.</li>
  <li value="(O3)">
      Something Aweakkjlk
      <ol class="enumeration" type="1">
      <li value="">This is item three.</li>
      <li value="(A5)">This is item fifty.</li>
      <li value="(A6)">This is item one hundred.</li>
    </ol>
  </li>
</ol>
"""-->


  <style>

    ol.enumeration {
        margin-left: 2em;
        padding-left: 2em;
    }
    li {
        display: block;
        margin-bottom: .5em;
        margin-left: 2em;
    }
    li:before {
        content:attr(value) ' ';
        width: 2em;
        margin-left: -2em;
        display: inline-block;
    }
  </style>
    
  
<d-article>
<p>

\frontmatter
\title \mbox\chancery F A N C y 
[2mm]
\chancery\Large  an online documentation project on 
[3mm]
\chancery \underlineFunctional \underlineAnalysis and \underlineNon-\underlineCommutative Geometr\underliney
\addcontentslinetocchapterPreliminaries
\addcontentslinetocsectionTitlepage
\authorFounded by \scshape Markus J.~Pflaum
\maketitle

\phantomsection 


\mainmatter
\partFundamentals

\setcounterchapter0
\chapterTools from Analysis
</p><h1>1 Some useful inequalities</h1><p>

In this section we collect several inequalities from real analysis which will 
be of use later in this monograph. 
<br><br><strong>Theorem 1.1</strong>[Young's inequality]

Let <span class='inline'>a,b \geq 0</span>, and assume that <span class='inline'>p,q  > 1</span> satisfy the relation <span class='inline'>\frac 1p + \frac 1q =1</span>. Then 
<br><br><span class='display'>
   ab \leq \frac 1p a^p + \frac 1q b^q \: .
</span><br>
  Equality holds if and only if <span class='inline'>a^p = b^q</span>. 
<br><br>
<br><i>Proof.</i>
Since the second derivative <span class='inline'>\exp''</span> of the exponential function attains
only positive values, the function <span class='inline'>\exp</span> is strictly convex that means satisfies
<br><br><span class='display'>
   \exp \big( \lambda x + (1-\lambda) y \big) \leq 
   \lambda \exp ( x ) +   (1-\lambda)  \exp ( y ) 
</span><br>
for all <span class='inline'>x,y\in \mathbb{R}</span> and <span class='inline'>\lambda \in [0,1]</span> with equality holding true if and only if <span class='inline'>x = y</span> or <span class='inline'>\lambda \in \{ 1,0 \}</span>.
Putting <span class='inline'>x = p \ln a</span>, <span class='inline'>y = q \ln b</span>, and <span class='inline'>\lambda = \frac 1p</span> one obtains
<br><br><span class='display'>
   ab = \exp\big( \lambda x + (1-\lambda) y \big)   \leq 
   \lambda \exp ( x ) +   (1-\lambda)  \exp ( y ) = \frac 1p a^p + \frac 1q b^q \: .
</span><br>
Equality holds if and only if <span class='inline'>x = y</span> which is equivalent to  <span class='inline'>a^p = b^q</span>.

<br><br><strong>Theorem 1.2</strong>[Cauchy--Schwarz inequality for sums]

Let <span class='inline'>v,w \in \mathbb{C}^n</span>. Then 
<br><br><span class='display'>
  \Big| \sum_{i=1}^n v_i \overline{w_i} \: \Big|^2 \leq \Big( \sum_{i1}^n |v_i|^2 \Big)  \Big( \sum_{i=1}^n |w_i|^2 \Big).
</span><br>  
Equality holds true if and only if  <span class='inline'>v</span> and <span class='inline'>w</span> are linearly dependant. 
<br><br>
<br><i>Proof.</i>
Let us use the <i>inner product</i> notation 
<br><br><span class='display'>
   \langle v,w\rangle := \sum_{i=1}^n v_i \overline{w_i} \quad \text{for } v,w\in \mathbb{C}^n.
</span><br>
Then the <span class='inline'>\ell^2</span>-<i>norm</i>
<br><br><span class='display'>
  \| v \| :=  \left( \sum_{i=1}^n |v_i|^2\right)^{1/2} = \langle v , v \rangle^{1/2}
</span><br>
is well-defined and non-negative for any <span class='inline'>v\in \mathbb{C}^n</span>. If <span class='inline'>\|v \| =0</span> or <span class='inline'>\| w \|= 0</span>, then <span class='inline'>v=0</span> or <span class='inline'>w=0</span>, and 
the claim is trivial. So we assume <span class='inline'>\|v \|, \| w \|  >  0</span> and compute 
<br><br><span class='display'> \tag{1.1}


  0 \leq \,  \big\langle \|w\| v - \|v\| w , \|w\| v - \|v\| w \big\rangle  = 
  \sum_{i=1}^n \big( \|w\| v_i - \|v\| w_i \big)\big( \|w\| \overline{v_i} - \|v\| \overline{w_i} \big)  = </span><br><br><span class='display'> 
  = \,    \sum_{i=1}^n \|w\|^2 v_i\overline{v_i} - \|w\| \|v\| v_i \overline{w_i}  -  \|w\| \|v\| w_i \overline{v_i} 
    +  \|v\|^2 w_i\overline{w_i}  = </span><br><br><span class='display'>
  = \,   2 \|v\|\|w\| \Big(  \|v\|\|w\| - \Re \langle v,w \rangle \Big) .

</span><br><br>
Now choose <span class='inline'>c \in \mathbb{C}</span> with <span class='inline'>|c|=1</span> such that <span class='inline'> c \langle  v,w \rangle = |\langle  v,w \rangle|</span>. Replacing <span class='inline'>v</span> by <span class='inline'>cv</span> 
in inequality \eqrefeq:inequality-chain and observing that <span class='inline'>\|cv \|</span> and <span class='inline'> \| w \| </span> are positive then entails
<br><br><span class='display'>
  0 \leq \|c v\|\|w\| - \Re \langle c v,w \rangle  =  \|v\|\|w\| - \Re (c \langle v,w \rangle) =
  \|v\|\|w\| -  |\langle  v,w \rangle|,
</span><br> 
which is the claimed Cauchy--Schwartz inequality for sums in abbreviated form. 

Equality holds true if and only if <span class='inline'>\|w\| c v - \|v\| w =0</span>. So if <span class='inline'>\|v\|\|w\| =  |\langle  v,w \rangle| </span>,
then <span class='inline'>v</span> and <span class='inline'>w</span> are linearly dependant. To show the converse, assume that <span class='inline'>av =bw</span> for some <span class='inline'>a,b\in \mathbb{C}</span> 
with <span class='inline'>(a,b) \neq (0,0)</span>. Because we consider  the nontrivial case where both <span class='inline'>v</span> and <span class='inline'>w</span> are nonzero, we can 
assume without loss of generality that <span class='inline'>b=1</span>. But then 
<br><br><span class='display'> |\langle v,w \rangle |= |\langle v, av \rangle | = |a| \|v\|^2 = \|v\| \, \|w\| , </span><br>
hence equality holds in this case. The proof is finished.


<br><br><strong>1.3</strong>
Besides the <span class='inline'>\ell^2</span>-norm on <span class='inline'>\mathbb{C}^n</span> one has the so-called <span class='inline'>\ell^p</span>-norms 
<span class='inline'>\| \cdot \| : \mathbb{C}^n \to \mathbb{R}_{\geq 0}</span> for <span class='inline'>p \geq 1</span>. 
They are defined by 
<br><br><span class='display'>
  \| v \|_p = \left( \sum_{k=1}^n |v_k|^p \right)^{1/p} \quad \text{for } v \in \mathbb{C}^n  . 
</span><br> 
The <i>maximum norm</i> or <span class='inline'>\ell^\infty</span>-norm <span class='inline'>\| \cdot \|_\infty</span> is given by 
<br><br><span class='display'>
  \| v \|_\infty = \sup \big\{ |v_k| \bigm\vert k = 1,\ldots , n \big\}  .
</span><br>
The <span class='inline'>\ell^p</span>-norms are all norms indeed as we will later see. 
<br><br><strong>Theorem 1.4</strong>[H\"older's inequality for sums]
Let <span class='inline'>p,q \in [1, \infty )</span> such that <span class='inline'>\frac 1p + \frac 1q =1</span>. Then 
<br><br><span class='display'>
   \sum_{k=1}^n | v_k w_k | \leq  \| v \|_p \cdot \| w\|_q \quad \text{for all } v,w\in \mathbb{C}^n .
</span><br>
<br><br>
<br><i>Proof.</i>
If <span class='inline'>p=1</span> or <span class='inline'>q=1</span> the claim is immediate, because then <span class='inline'>q=\infty</span>  or <span class='inline'>p=\infty</span>, respectively,
and  the two estimates
<br><br><span class='display'>
  \sum_{k=1}^n | v_k w_k | \leq  \left( \sum_{k=1}^n | v_k | \right) \cdot 
  \sup\big\{ |w_k| \bigm\vert k = 1,\ldots , n \big\} 
</span><br>
and
<br><br><span class='display'>
  \sum_{k=1}^n | v_k w_k | \leq  \left( \sum_{k=1}^n | w_k | \right) \cdot 
  \sup \big\{ |v_k| \bigm\vert k = 1,\ldots , n \big\} 
</span><br>
obviously hold. So we can assume <span class='inline'>1  <  p,q  <  \infty</span>. Moreover we can assume that both <span class='inline'>v</span> and <span class='inline'>w</span> 
are nonzero because otherwise the claim is trivial. Now observe that by Young's inequality
<br><br><span class='display'>
  \frac{|v_k|}{\| v \|_p} \cdot \frac{|w_k|}{\| w \|_q} =
  \left(\frac{|v_k|^p}{\| v \|_p^p} \right)^{1/p} \cdot \left(\frac{|w_k|^q}{\| w \|_q^q} \right)^{1/q}
  \leq \frac 1p \frac{|v_k|^p}{\| v \|_p^p} + \frac 1q \frac{|w_k|^q}{\| w \|_q^q} \quad 
  \text{for } k=1,\ldots , n.
</span><br>
Summing over all <span class='inline'>k</span> gives
<br><br><span class='display'>
   \sum_{k=1}^n \frac{|v_k|}{\| v \|_p} \cdot \frac{|w_k|}{\| w \|_q} \leq 
   \frac 1p  \frac{\|v\|_p^p}{\| v \|_p^p} + \frac 1q \frac{\|w\|_q^q}{\| w \|_q^q} = 
   \frac 1p + \frac 1q = 1 .
</span><br>
Multiplication of both sides by <span class='inline'> \| v \|_p \cdot \| w\|_q</span> entails H\"older's inequality.


<br><br><strong>Theorem 1.5</strong>[Minkowski's inequality for sums]
Let <span class='inline'>p  \in [1, \infty )</span>. Then
<br><br><span class='display'>
   \| v + w \|_p \leq \| v\|_q + \| w \|_p \quad \text{for all } v,w\in \mathbb{C}^n .
</span><br> 
<br><br>

<br><i>Proof.</i>
For <span class='inline'>p=1</span> the claim is trivial, likewise for <span class='inline'>p=\infty</span>. So assume <span class='inline'>1   <  p  <   \infty</span>
and put <span class='inline'>q := \frac{p}{p-1}</span>. Then <span class='inline'>\frac 1p + \frac 1q =1</span>, and we can apply   
H\"older's inequality to compute
<br><br><span class='display'>
  
   \| v + w \|_p^p\,   =  \sum_{k=1}^n | v_k + w_k|^p \leq  
   \sum_{k=1}^n |v_k| \, | v_k + w_k|^{p-1} +  |v_k| \, | v_k + w_k|^{p-1} 
   \leq </span><br><br><span class='display'>
   \leq  \| v \|_p \cdot \left(  | v_k + w_k|^{(p-1)q} \right)^{1/q} +
   \| w \|_p \cdot \left(  | v_k + w_k|^{(p-1)q} \right)^{1/q}  = </span><br><br><span class='display'>
    = \left( \| v \|_p +  \| w \|_p \right) \,  \| v + w \|_p^{p/q} . 

</span><br>
Minkowski's inequality follows. 




\chapterGeneral Topology
  
  
  
  
  
  
  

\chapterMeasure and Integration theory

</p><h1>2 The category of measurable spaces and functions</h1><p>
</p><h2>Definitions and first examples</h2><p>\addcontentslinetocsubsectionDefinitions and first examples
<br><br><strong>Definition 2.1</strong>
  Let <span class='inline'>\Omega</span> be a set. By an <i>algebra on</i> <span class='inline'>\Omega</span> one understands a collection <span class='inline'>\mathscr{A}</span> of subsets of <span class='inline'>\Omega</span>
  or in other words an element <span class='inline'>\mathscr{A}\in \mathscr{P}(\Omega)</span> such that
  </p><ol class='enumeration'>
  <li value=' (A1)'> <span class='inline'>\Omega \in \mathscr{A}</span>,
  </li><li value=' (A2)'> for each <span class='inline'>A\in \mathscr{A}</span>, the complement <span class='inline'>\complement A = \Omega \setminus A </span> belongs to <span class='inline'>\mathscr{A}</span>,
  </li><li value=' (A3)'> for each finite sequence <span class='inline'>(A_k)_{k=1}^n</span> of elements of <span class='inline'>\mathscr{A}</span> the union <span class='inline'>A= \bigcup\limits_{k=1}^n A_k</span>
        belongs to <span class='inline'>\mathscr{A}</span>. 
  </li></ol><p>
  If in addition 
  </p><ol class='enumeration'>
  \setcounterenumi3
  <li value=' (A1)'> for each sequence <span class='inline'>(A_k)_{k\in \mathbb{N}}</span> of elements of <span class='inline'>\mathscr{A}</span> the union <span class='inline'>A= \bigcup\limits_{k\in\mathbb{N}} A_k</span>
        belongs to <span class='inline'>\mathscr{A}</span>,
  </li></ol><p>
  then the algebra <span class='inline'>\mathscr{A}</span> is called a <i><span class='inline'>\sigma</span>-algebra</i>.
  A set <span class='inline'>\Omega</span> equipped with a <span class='inline'>\sigma</span>-algebra <span class='inline'>\mathscr A</span> is called a 
  <i>measurable space</i>.  The elements of <span class='inline'>\mathscr A</span> are termed the 
  <i>measurable subsets</i> of <span class='inline'>\Omega</span>.
<br><br>

<br><br><strong>Proposition 2.2</strong>
  If <span class='inline'>\mathscr{A}</span> is an algebra on a set <span class='inline'>\Omega</span>, the empty set and the intersection of finitely many
  elements of <span class='inline'>\mathscr{A}</span> lies in <span class='inline'>\mathscr{A}</span>.
  If <span class='inline'>\mathscr{A}</span> is a <span class='inline'>\sigma</span>-algebra on <span class='inline'>\Omega</span>, then the intersection of countably many
  measurable sets is also measurable.
<br><br>
<br><i>Proof.</i>
  These facts follow immediately from the axioms and the set-theoretic de Morgan's laws. 


<br><br><strong>Examples 2.3</strong>

  </p><ol class='enumeration'>

<li value='(a) '> Let <span class='inline'>\Omega</span> be any set. Then the power set of <span class='inline'>\Omega</span> is a <span class='inline'>\sigma</span>-algebra.  
  The set <span class='inline'>\{ \emptyset , \Omega \}</span> is also a <span class='inline'>\sigma</span>-algebra. These are the  largest and smallest
  <span class='inline'>\sigma</span>-algebra on <span class='inline'>\Omega</span>, respectively. 
</li><li value='(b) '>
  Let <span class='inline'>\Omega</span> be any set.  Let <span class='inline'>\mathscr A</span> be the set of all sets <span class='inline'>A\subset \Omega</span> such that <span class='inline'>A</span> or <span class='inline'>\Omega \backslash A</span> is
  a countable set.  Then <span class='inline'>\mathscr A</span> is a <span class='inline'>\sigma</span>-algebra.

  </li></ol><p>

<br><br>

<br><br><strong>Remark 2.4</strong>
  Obviously, the set of algebras on a set <span class='inline'>\Omega</span> and the set of <span class='inline'>\sigma</span>-algebras on <span class='inline'>\Omega</span> are both ordered
  by set-theoretic inclusion. When talking about a ``smaller`` <span class='inline'>\sigma</span>-algebra or a ``largest'' one we always
  implicitely mean in regard to set-theoretic inclusion as underlying order relation.
<br><br>

The following two results are extremely useful when constructing examples.

<br><br><strong>Proposition 2.5</strong>
  Let <span class='inline'>(\mathscr{A}_i)_{i\in I}</span> a family of algebras on a set <span class='inline'>\Omega</span>.
  Then the intersection
  <span class='inline'>\mathscr{A} = \bigcap\limits_{i\in I} \mathscr{A}_i</span> is an algebra on <span class='inline'>\Omega</span>.
  If each of the <span class='inline'>\mathscr{A}_i</span> is a <span class='inline'>\sigma</span>-algebra, then <span class='inline'>\mathscr{A}</span> is so, too. 
<br><br>
<br><i>Proof.</i>
  Assume first that each <span class='inline'>\mathscr{A}_i</span> is an algebra on <span class='inline'>\Omega</span>. 
  Obviously, <span class='inline'>\Omega \in \mathscr{A}</span> because  <span class='inline'>\Omega \in \mathscr{A}_i</span> for all <span class='inline'>i\in I</span>.
  Similarly, if <span class='inline'>A  \in \mathscr{A}</span>, then <span class='inline'>A \in \mathscr{A}_i</span>, hence <span class='inline'>\complement A \in \mathscr{A}_i</span>
  for all <span class='inline'>i\in I</span>. Therefore <span class='inline'>\complement A </span> is in the intersection
  <span class='inline'>\mathscr{A} = \bigcap\limits_{i\in I} \mathscr{A}_i</span>. Now assume that <span class='inline'>(A_k)_{k=1}^n</span> is a finite
  sequence of  sets belonging to <span class='inline'>\mathscr{A}</span>. Then <span class='inline'>A_k \in \mathscr{A}_i</span>  for <span class='inline'>k=1,\ldots,n</span> and all
  <span class='inline'>i\in I</span>  which entails that <span class='inline'>\bigcup\limits_{k=1}^n A_k</span> is in each of the <span class='inline'>\mathscr{A}_i</span>, hence in the
  intersection <span class='inline'>\mathscr{A}</span>. The latter argument also works under the condition that each <span class='inline'>\mathscr{A}_i</span> is a <span class='inline'>\sigma</span>-algebra
  to verify that for a sequence <span class='inline'>(A_k)_{k\in\mathbb{N}}</span>  in <span class='inline'>\mathscr{A}</span> the union <span class='inline'>\bigcup\limits_{k\in\mathbb{N}} A_k</span>
  is in <span class='inline'>\mathscr{A}</span>. So the proposition is proved. 



<br><br><strong>Corollary 2.6</strong>
  Let <span class='inline'>\mathscr F</span> be a collection of subsets of a set <span class='inline'>\Omega</span>.  Then there is a unique smallest <span class='inline'>\sigma</span>-algebra,
  <span class='inline'>\sigma (\mathscr F)</span>, on <span class='inline'>\Omega</span> containing <span class='inline'>\mathcal F</span>.  It is called the <i><span class='inline'>\sigma</span>-algebra</i> generated by
  <span class='inline'>\mathscr F</span>.
<br><br>

<br><i>Proof.</i>
  Let <span class='inline'>{\mathcal M}</span> be the family of all <span class='inline'>\sigma</span>-algebras which contain <span class='inline'>\mathscr F</span>.  The set of all subsets of <span class='inline'>\Omega</span> is
  certainly a <span class='inline'>\sigma</span>-algebra, so <span class='inline'>{\mathcal M} \neq \emptyset</span>.  Let <span class='inline'>\sigma (\mathscr F)</span> be the intersection of all
  <span class='inline'>\sigma</span>-algebras in the family <span class='inline'>{\mathcal M}</span>.  By the preceding proposition <span class='inline'>\sigma (\mathscr F)</span> is a <span class='inline'>\sigma</span>-algebra.
  Since every element of <span class='inline'>{\mathcal M}</span> contains <span class='inline'>\mathscr F</span>, the intersection
  <span class='inline'>\sigma (\mathscr F) = \bigcap\limits_{\mathscr{A}\in \mathcal{M}}\mathscr{A}</span> contains <span class='inline'>\mathscr F</span> as well. By construction,
  <span class='inline'>\sigma (\mathscr F)</span> is minimal with that property.


<br><br><strong>Example 2.7</strong>
  Let <span class='inline'>X</span> be a topological space.  The <span class='inline'>\sigma</span>-algebra, <span class='inline'>\mathscr B (X)</span>, generated by all open subsets of <span class='inline'>X</span> is called the
  \em Borel <span class='inline'>\sigma</span>-algebra on <span class='inline'>X</span>. Its elements are the \em Borel measurable sets or simply the \em Borel sets of <span class='inline'>X</span>.
  Obviously all open and all closed sets of <span class='inline'>X</span> are Borel measurable, as are all countable unions of closed sets and countable
  intersections of open sets.
<br><br>



<br><br><strong>Example 2.8</strong>

  </p><ol class='enumeration'>

<li value='(a) '> All intervals including the half-open intervals <span class='inline'>[a,b)</span> and <span class='inline'>(a,b]</span> with <span class='inline'>a < b</span> are Borel subsets of <span class='inline'>\mathbb{R}</span>.
</li><li value='(b) '> If <span class='inline'>X</span> is a topological space with the discrete topology, then every subset of <span class='inline'>X</span> is Borel measurable.
</li><li value='(c) '> If <span class='inline'>X</span> is a topological space carrying the topology <span class='inline'>\{ X ,\emptyset \}</span>, then the <span class='inline'>\sigma</span>-algebra
      of Borel sets is the set <span class='inline'>\mathscr B = \{ X , \emptyset \}</span>.

  </li></ol><p>

<br><br>



<br><br><strong>Definition 2.9</strong>
Let <span class='inline'>\Omega</span> be a measurable space, and <span class='inline'>Y</span> a topological space.  A map <span class='inline'>f\colon \Omega \rightarrow Y</span> is termed \em measurable if the set <span class='inline'>f^{-1}[U]</span> is measurable for every open subset <span class='inline'>U\subseteq Y</span>.
<br><br>

<br><br><strong>Proposition 2.10</strong> 
Let <span class='inline'>f\colon \Omega \rightarrow Y</span> be a measurable function.  Then the inverse image <span class='inline'>f^{-1}[B]</span> is measurable whenever <span class='inline'>B\subseteq Y</span> is a Borel set.
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>\mathcal M</span> be the collection of all subsets <span class='inline'>E\subseteq Y</span>  such that the inverse image <span class='inline'>f^{-1}[E] \subseteq \Omega</span> is measurable.  It is easy to check the axioms required to show that <span class='inline'>\mathcal M</span> is a <span class='inline'>\sigma</span>-algebra.

Since the function <span class='inline'>f</span> is measurable, the <span class='inline'>\sigma</span>-algebra <span class='inline'>\mathcal M</span> contains all open sets of <span class='inline'>Y</span>, and therefore all Borel sets.  Thus, by definition of the <span class='inline'>\sigma</span>-algebra <span class='inline'>\mathcal M</span>, the set <span class='inline'>f^{-1}[B]</span> is measurable whenever <span class='inline'>B</span> is a Borel set.


<br><br><strong>Definition 2.11</strong>
Let <span class='inline'>f\colon X\rightarrow Y</span> be a mapping between topological spaces.  If <span class='inline'>f</span> is measurable with respect to the <span class='inline'>\sigma</span>-algebra of all Borel sets in <span class='inline'>X</span>, then we call <span class='inline'>f</span> a Borel function.
<br><br>

Thus a function is a Borel function if the inverse image of any open set is a Borel set.  In particular, any continuous function is a Borel function.

<br><br><strong>Proposition 2.12</strong> 
Let <span class='inline'>f\colon \Omega \rightarrow X</span> be a measurable function, and let <span class='inline'>g\colon X\rightarrow Y</span> be a Borel function.  Then the composite <span class='inline'>g\circ f \colon \Omega \rightarrow Y</span> is measurable.
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>U\subseteq Y</span> be an open set.  Then the inverse image <span class='inline'>g^{-1}[U]</span> is a Borel set, so by proposition 2.10 the inverse image <span class='inline'>(g\circ f)^{-1}[U]</span> is measurable.


As a corollary, the composite of a measurable and a continuous function is measurable.

<br><br><strong>Example 2.13</strong> 
  Let <span class='inline'>X</span> be a measure space, and let <span class='inline'>E\subseteq X</span> be a measurable set.  Then the function
  <span class='inline'>\chi_E \colon X\rightarrow {\mathbb C}</span> given by the formula
  <span class='inline'></span>\chi_E (x) = \left\ \beginarrayll 1 & x\in E 

  0 & x\not\in E 

  \endarray \right.<span class='inline'></span>
is measurable.
<br><br>

The function <span class='inline'>\chi_E</span> is called the \em characteristic function of <span class='inline'>E</span>.

</p><h2>Algebras of real and complex valued Borel measurable functions</h2><p>\addcontentslinetocsubsectionAlgebras of real and complex valued Borel measurable functions

<br><br><strong>Proposition 2.14</strong> 
Let <span class='inline'>u,v\colon X\rightarrow {\mathbb R}</span> be measurable functions, and let <span class='inline'>\Phi \colon {\mathbb R}^2 \rightarrow Y</span> be continuous.  Define a function <span class='inline'>h\colon X\rightarrow Y</span> by the formula
<span class='inline'></span>h(x) = \Phi (u(x),v(x))<span class='inline'></span>
Then the function <span class='inline'>h</span> is measurable.
<br><br>

<br><i>Proof.</i>
Define <span class='inline'>f\colon X\rightarrow {\mathbb R}^2</span> by the formula <span class='inline'>f(x) = (u(x),v(x))</span>.  In view of proposition 2.12 it suffices to prove that the function <span class='inline'>f</span> is measurable.  Observe that:
<span class='inline'></span>f^-1((a,b)\times (c,d)) = u^-1(a,b)\cap v^-1(c,d)<span class='inline'></span>
so the inverse image <span class='inline'>f^{-1}((a,b)\times (c,d))</span> is measurable since <span class='inline'>u</span> and <span class='inline'>v</span> are measurable functions.

But every open set <span class='inline'>U\subseteq {\mathbb R}^2</span> is a countable union of rectangles of the form <span class='inline'>(a,b)\times (c,d)</span>.  The <span class='inline'>\sigma</span>-algebra axioms thus ensure that the inverse image <span class='inline'>f^{-1}[U]</span> is measurable whenever <span class='inline'>U\subseteq {\mathbb R}^2</span> is an open set.


The above proposition and proof still function if the function <span class='inline'>\Phi</span> is a Borel function rather than a continuous function.

<br><br><strong>Corollary 2.15</strong> 
Let <span class='inline'>f\colon X\rightarrow {\mathbb C}</span> be a function on a measurable space <span class='inline'>X</span>.  Then the function <span class='inline'>f</span> is measurable if and only if the functions <span class='inline'>\Re (f)</span> and <span class='inline'>\Im (f)</span> are measurable.
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>u,v\colon X\rightarrow {\mathbb R}</span> be measurable functions.  Define <span class='inline'>\Phi \colon {\mathbb R}^2\rightarrow {\mathbb C}</span> by the formula <span class='inline'>\Phi (x,y) = x+iy</span>.  Then the function <span class='inline'>u+iv</span> is measurable by proposition 2.14.

The converse follows immediately from proposition 2.12 since the functions <span class='inline'>\Re</span> and <span class='inline'>\Im</span> are continuous.


<br><br><strong>Corollary 2.16</strong> 
Let <span class='inline'>f,g\colon X\rightarrow {\mathbb C}</span> be measurable functions.  Then the functions <span class='inline'>f+g</span> and <span class='inline'>fg</span> are measurable.
<br><br>

<br><i>Proof.</i>
In view of corollary 2.15 it suffices to prove this result for real-valued measurable functions.  If we define continuous functions <span class='inline'>\Phi_1,\Phi_2 \colon {\mathbb R}^2\rightarrow {\mathbb R}</span> by the formulae <span class='inline'>\Phi_1 (s,t)=s+t</span> and <span class='inline'>\Phi_2 (s,t)=st</span>, then the result follows immediately from proposition 2.14




<br><br><strong>Proposition 2.17</strong>
Let <span class='inline'>f\colon X\rightarrow {\mathbb C}</span> be a measurable function.  Then the function <span class='inline'>|f|</span> is measurable, and there is a measurable function <span class='inline'>\alpha \colon X\rightarrow {\mathbb C}</span> such that <span class='inline'>|\alpha (x)| =1</span> for all <span class='inline'>x\in X</span>, and <span class='inline'>f=\alpha |f|</span>.
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>E = \{ x\in X |f(x)=0 \}</span>.  Then the set <span class='inline'>E</span> is the inverse image of a closed subset, and so measurable.  We can define a continuous function <span class='inline'>\varphi \colon {\mathbb C}\backslash \{ 0\} \rightarrow {\mathbb C}</span> by the formula <span class='inline'>\varphi (z) = z/|z|</span>.  It follows from example 2.13, corollary 2.16, and proposition 2.12 that the function <span class='inline'>\alpha \colon X\rightarrow {\mathbb C}</span> defined by the formula
<span class='inline'></span>\alpha (x) = \varphi (f(x) + \chi_E (x))<span class='inline'></span>
is measurable.  The formulae <span class='inline'>|\alpha (x)| =1</span> and <span class='inline'>f=\alpha |f|</span> are easy to check.


</p><h2>Measurable functions to the extended real line</h2><p>\addcontentslinetocsubsectionMeasurable functions to the extended real line

<br><br><strong>Definition 2.18</strong>
Let <span class='inline'>(a_n)</span> be a sequence of real numbers.  Then we define
<span class='inline'></span>\lim \sup_n\rightarrow \infty a_n = \lim \sup_n\rightarrow \infty \ a_n , a_n+1 , a_n+2 , \ldots \<span class='inline'></span>
and
<span class='inline'></span>\lim \inf_n\rightarrow \infty a_n = \lim \inf_n\rightarrow \infty \ a_n , a_n+1 , a_n+2 , \ldots \<span class='inline'></span>
<br><br>

We can pass from results about <span class='inline'>\lim \sup</span> to results about <span class='inline'>\lim \inf</span>, or conversely, by the observation
<span class='inline'></span>\lim \sup_n\rightarrow \infty a_n = - \lim \inf_n\rightarrow \infty (-a_n)<span class='inline'></span>

It will occasionally be convenient to us to allow <span class='inline'>\infty</span> and <span class='inline'>-\infty</span> as values of limits and functions.  This is a safe enough option provided we do not attempt to do arithmetic with these symbols; for example, expressions such as `<span class='inline'>\infty - \infty</span>' are completely meaningless.

However, we can form `intervals'
<span class='inline'></span>[a,\infty ] = [a ,\infty )\cup \ \infty \  \qquad [\infty ,b] = (\infty ,b]\cup \ \infty \<span class='inline'></span>
and so on.  These intervals are topological spaces.  We can also allow ourselves the inequality
<span class='inline'></span>-\infty  <  a  <  \infty<span class='inline'></span>
for all <span class='inline'>a\in {\mathbb R}</span>.  The standard result about <span class='inline'>\lim \sup</span> and <span class='inline'>\lim \inf</span> can now be expressed quite simply; although a number of special cases need to be examined in the proof.

<br><br><strong>Theorem 2.19</strong>
Let <span class='inline'>(a_n)</span> be a real-valued sequence.  Then the limits
<span class='inline'></span>\lim \inf_n\rightarrow \infty a_n \in [-\infty , \infty ) \qquad \lim \sup_n\rightarrow \infty a_n \in (-\infty , \infty ]<span class='inline'></span>
exist and satisfy the inequality
<span class='inline'></span>\lim \inf_n\rightarrow \infty a_n \leq \lim \sup_n\rightarrow \infty a_n<span class='inline'></span>

Further, the equality
<span class='inline'></span>\lim \inf_n\rightarrow \infty a_n = a = \lim \sup_n\rightarrow \infty a_n<span class='inline'></span>
holds precisely when the sequence <span class='inline'>(a_n)</span> converges to the real number <span class='inline'>a</span>.
<strong>proof to be filled in!</strong>
<br><br>

Note that the number <span class='inline'>a</span> in the above result must be finite.

<br><br><strong>Proposition 2.20</strong>
Let <span class='inline'>\Omega</span> be a measurable space, and let <span class='inline'>f\colon \Omega \rightarrow [\infty , \infty]</span> be any map.  Suppose that the inverse image <span class='inline'>f^{-1}((\alpha , \infty ])</span> is measurable for every point <span class='inline'>\alpha \in {\mathbb R}</span>.  Then the function <span class='inline'>f</span> is measurable.
<br><br>

<br><i>Proof.</i>
Let
<span class='inline'></span>\mathcal M = \ E\subseteq [-\infty ,\infty]|f^-1[E] \textrm is measurable  \<span class='inline'></span>

By proposition 2.10 the set <span class='inline'>\mathcal M</span> is a <span class='inline'>\sigma</span>-algebra.  Choose points <span class='inline'>\alpha \in {\mathbb R}</span> and <span class='inline'>\alpha_n  <  \alpha</span> such that <span class='inline'>\lim_{n\rightarrow \infty} \alpha_n = \alpha</span>.  Since the set <span class='inline'>(\alpha_n , \infty ]</span> is measurable by hypothesis, and
<span class='inline'></span>[-\infty , \alpha ) = \bigcup_n=1^\infty [-\infty , \alpha_n ] = \bigcup_n=1^\infty [-\infty , \infty ]\backslash (\alpha_n , \infty]<span class='inline'></span>
it follows that <span class='inline'>[-\infty , \alpha )\in \Omega</span>.  Hence
<span class='inline'></span>(\alpha , \beta ) = [-\infty , \beta ) \cap (\alpha , \infty ] \in \Omega<span class='inline'></span>
for every point <span class='inline'>\alpha , \beta \in {\mathbb R}</span>.  Since every open set in <span class='inline'>[-\infty , \infty ]</span> is a countable union of such open intervals, the collection <span class='inline'>\mathcal M</span> contains every open set.  Thus the map <span class='inline'>f</span> is measurable.


<br><br><strong>Corollary 2.21</strong>
Let <span class='inline'>f_n\colon X\rightarrow [-\infty , \infty]</span> be measurable functions for <span class='inline'>n\in {\mathbb N}</span>.  Then the functions
<span class='inline'></span>\sup \ f_n \ \quad \lim \sup_n\rightarrow \infty f_n \quad \inf \ f_n \ \quad \lim \inf_n\rightarrow \infty f_n<span class='inline'></span>
are measurable.
<br><br> 

<br><i>Proof.</i>
Let <span class='inline'>a\in {\mathbb R}</span>.  Observe that the set
<span class='inline'></span>(\sup \ f_n \)^-1 (a,\infty ] = \bigcup_n=1^\infty f_n^-1(a,\infty ]<span class='inline'></span>
is measurable.  Hence by the above proposition, the function <span class='inline'>\sup \{ f_n \}</span> is measurable.  The formula <span class='inline'>\inf \{ f_n \} = - \sup \{ -f_n \}</span> tells us that the function <span class='inline'>\inf \{ f_n \}</span> is also measurable.

Now, for each point <span class='inline'>x\in \Omega</span>, the sequence of numbers
<span class='inline'></span>g_n (x) = \sup \ f_n (x) , f_n+1 (x) , f_n+2(x) , \ldots \<span class='inline'></span>
is monotonic increasing.  It follows that
<span class='inline'></span>\lim \sup _n\rightarrow \infty f_n (x) = \inf \ g_n (x) \<span class='inline'></span>

We know that each function <span class='inline'>f_n</span> is measurable.  The above argument tells us that each function <span class='inline'>g_n</span> is measurable, and that the function <span class='inline'>{\lim \sup}_{n\rightarrow \infty}f_n</span> is measurable.  A similar argument tells us that the function <span class='inline'>{\lim \inf}_{n\rightarrow \infty}g_n</span> is measurable.



<br><br><strong>Corollary 2.22</strong>
If <span class='inline'>f,g\colon X\rightarrow [-\infty, \infty ]</span> are measurable functions, then so are the functions <span class='inline'>\max \{ f,g \}</span> and <span class='inline'>\min \{ f,g \}</span>.
<strong>proof to be filled in!</strong>
<br><br>

<br><br><strong>Corollary 2.23</strong>
The limit of a pointwise-convergent sequence of meaurable functions is measurable.
<strong>proof to be filled in!</strong>
<br><br>

</p><h1>3 Measure Spaces</h1><p>

<br><br><strong>Definition 3.1</strong>
Let <span class='inline'>\Omega</span> be a measurable space, equipped with a <span class='inline'>\sigma</span>-algebra <span class='inline'>\mathscr A</span>.  
A <i>measure</i> on <span class='inline'>\Omega</span> is a function <span class='inline'>\mu \colon {\mathscr A}\rightarrow [0,\infty ]</span> such that:
</p><ol class='enumeration'>
<li value=' (M1)'> The function <span class='inline'>\mu</span> is <i><span class='inline'>\sigma</span>-additive</i>, i.e.
<br><br><span class='display'>  \mu \left( \bigcup_{n=1}^\infty A_n \right) = \sum_{n=1}^\infty \mu (A_n ) , </span><br> 
whenever <span class='inline'>(A_n)_{n\in \mathbb{N}}</span> is a sequence of disjoint mesaurable sets.  
</li><li value=' (M2)'> There is a measurable set <span class='inline'>A</span> such that <span class='inline'>\mu (A) < \infty</span>.
</li></ol><p>
The number <span class='inline'>\mu (A)</span> is called the <i>measure</i> of a set <span class='inline'>A</span>.  A measurable space equipped with some measure is called a 
<i>measure space</i>.
<br><br>

For the above definition to make sense, we need to make a convention concerning our `number' <span class='inline'>\infty</span>, namely that <span class='inline'>a + \infty = \infty</span> whenever <span class='inline'>a\in [0,\infty ]</span>.  

<br><br><strong>Example 3.2</strong>
Let <span class='inline'>\Omega</span> be a measurable space.  For any measurable set <span class='inline'>E\subseteq \Omega</span>, let us define
<span class='inline'>\mu (E) = |E|</span>, where <span class='inline'>|E|</span> denotes the number of elements of <span class='inline'>E</span>.  Then <span class='inline'>\mu</span> is a measure on <span class='inline'>\Omega</span>, called the \em counting measure.
<br><br>

<br><br><strong>Example 3.3</strong>
Let <span class='inline'>\Omega</span> be a measurable space, and let <span class='inline'>x_0 \in \Omega</span>.  For any measurable set <span class='inline'>E\subseteq \Omega</span>, let us define
<span class='inline'></span>\mu (E) = \left\ \beginarrayll
1 & x_0 \in E 

0 & x_0 \not\in E 

\endarray \right.<span class='inline'></span>

Then <span class='inline'>\mu</span> is a measure on <span class='inline'>\Omega</span>, called the \em Dirac measure.
<br><br>

<br><br><strong>Proposition 3.4</strong>
Let <span class='inline'>\Omega</span> be a measure space, with measure <span class='inline'>\mu</span>.  Then <span class='inline'>\mu (\emptyset ) =0</span>.
<br><br>

<br><i>Proof.</i>
Choose a measurable set <span class='inline'>A</span> such that <span class='inline'>\mu (A) < \infty</span>.  Then
<span class='inline'></span>\mu (A) =  \mu (A) + \mu (\emptyset ) + \mu (\emptyset ) +\cdots<span class='inline'></span>
Hence <span class='inline'>\mu (\emptyset ) =0</span>.


<br><br><strong>Corollary 3.5</strong>
Let <span class='inline'>A_1 , \ldots , A_n</span> be disjoint measurable sets.  Then
<span class='inline'></span>\mu (A_1 \cup \cdots \cup A_n ) = \mu (A_1 ) + \cdots + \mu (A_n)<span class='inline'></span>
<strong>proof to be filled in!</strong>
<br><br>

<br><br><strong>Corollary 3.6</strong>
Let <span class='inline'>A</span> and <span class='inline'>B</span> be measurable set where <span class='inline'>A\subseteq B</span>.  Then <span class='inline'>\mu (A) \leq \mu (B)</span>.
<br><br>

<br><i>Proof.</i>
The set <span class='inline'>B\backslash A = B\cap (\Omega \backslash A )</span> is measurable, the sets <span class='inline'>A</span> and <span class='inline'>B\backslash A</span> are disjoint, and <span class='inline'>B = A\cup B\backslash A</span>.  By the above corollary
<span class='inline'></span>\mu (B) = \mu (A) + \mu (B\backslash A)<span class='inline'></span>

The inequality <span class='inline'>\mu (A)\leq \mu (B)</span> follows since <span class='inline'>\mu (B\backslash A)\geq 0</span>.


<br><br><strong>Proposition 3.7</strong> 
Let <span class='inline'>(A_n )</span> be a sequence of measurable sets such that <span class='inline'>A_n \subseteq A_{n+1}</span> for all <span class='inline'>n</span>.  Let <span class='inline'>A = \bigcup_{n=1}^\infty A_n</span>.  Then <span class='inline'>\lim_{n\rightarrow \infty} \mu (A_n ) = \mu (A)</span>.
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>B_1 =A_1</span>, and <span class='inline'>B_n = A_n \backslash A_{n-1}</span> when <span class='inline'>n\geq 2</span>.  Then the sets <span class='inline'>B_n</span> are measurable and disjoint.  Further
<span class='inline'></span>A_n = B_1 \cup \cdots \cup A_n \qquad A= \bigcup_n=1^\infty B_n<span class='inline'></span>

Hence
<span class='inline'></span>\mu (A) = \sum_n=1^\infty \mu (B_n) = \lim_N\rightarrow \sum_n=1^N \mu (B_n) = \lim_N\rightarrow \infty\mu (A_N)<span class='inline'></span>


<br><br><strong>Corollary 3.8</strong>
Let <span class='inline'>(A_n)</span> be a sequence of measurable sets such that <span class='inline'>\mu (A_1) < \infty</span> and <span class='inline'>A_{n+1}\subseteq A_n</span> for all <span class='inline'>n</span>.    Let <span class='inline'>A = \bigcap_{n=1}^\infty A_n</span>.  Then <span class='inline'>\lim_{n\rightarrow \infty} \mu (A_n ) = \mu (A)</span>.
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>C_n =A_1\backslash A_n</span>.  Then the set <span class='inline'>C_n</span> is measurable, <span class='inline'>C_n\subseteq C_{n+1}</span> for all <span class='inline'>n</span>, and <span class='inline'>\bigcup_{n=1}^\infty C_n = A_1 \backslash A</span>.  Hence, by the above proposition
<span class='inline'></span>\lim_n\rightarrow \infty\mu (C_n) = \mu (A_1 \backslash A)<span class='inline'></span>

We know that the measure <span class='inline'>\mu (A_1)</span> is finite, and that we have disjoint unions<span class='inline'></span>A_1 = A_n \cup C_n \qquad A_1 = A_1\backslash A \cup A<span class='inline'></span>
Hence
<span class='inline'></span>\mu (A_1 )- \lim_n\rightarrow \infty \mu (A_n) = \mu (A_1 ) - \mu (A)<span class='inline'></span>
and
<span class='inline'></span>\lim_n\rightarrow \infty \mu (A_n ) = \mu (A)<span class='inline'></span>


The above corollary is false if we omit the assumption that <span class='inline'>\mu (A_1) < \infty</span>.


</p><h1>4 Lebesgue integration</h1><p>

</p><h2>Simple Functions</h2><p>\addcontentslinetocsubsectionSimple Functions

<br><br><strong>Definition 4.1</strong>
A function <span class='inline'>s\colon \Omega \rightarrow {\mathbb C}</span> on a measurable space <span class='inline'>\Omega</span> is called \em simple if the range of <span class='inline'>s</span> is a finite set of points.
<br><br>

Let <span class='inline'>s\colon \Omega \rightarrow {\mathbb C}</span> be a simple function, with image <span class='inline'>s[X] = \{ 0 \} \cup \{ \alpha_1 , \ldots , \alpha_n \}</span>.  Write <span class='inline'>A_i = s^{-1}(\alpha_i )</span>.  Then clearly
<span class='inline'></span>s = \sum_i=1^n \alpha_i \chi_A_i<span class='inline'></span>
and the function <span class='inline'>s</span> is measurable if and only if each set <span class='inline'>A_i</span> is measurable.

<br><br><strong>Proposition 4.2</strong> 
Let <span class='inline'>f\colon \Omega \rightarrow [0,\infty ]</span> be a measurable function.  Then there are simple measurable functions <span class='inline'>s_n \colon X\rightarrow [0,\infty )</span> such that the sequence <span class='inline'>(s_n (x))</span> is monotonically increasing, with limit <span class='inline'>f(x)</span> for each point <span class='inline'>x\in X</span>.
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>n\in {\mathbb N}</span>, and <span class='inline'>t\in [0,\infty ]</span>.  Then there is a unique integer <span class='inline'>k_n (t)</span> such that
<span class='inline'></span>k_n (T) 2^-n \leq t \leq (k_n (t) +1)2^-n<span class='inline'></span>

Define
<span class='inline'></span>\varphi_n (t) = \left\ \beginarrayll
k_n (t)2^-n & 0\leq t <  n 

n & n\leq t\leq \infty 

\endarray \right.<span class='inline'></span>

The function <span class='inline'>\varphi_n \colon [0,\infty ]\rightarrow [0,\infty ]</span> is a Borel function, and
<span class='inline'></span>t-2^-n \leq \varphi_n (t) \leq t<span class='inline'></span>
if <span class='inline'>0\leq t\leq n</span>.  Thus we have a monotonically increasing sequence <span class='inline'>(\varphi_n (t))</span> with limit <span class='inline'>t</span>.  If we write <span class='inline'>s_n = \varphi_n \circ f</span>, then <span class='inline'>(s_n)</span> is a monotonically increasing sequence of simple measurable functions, with pointwise limit <span class='inline'>f</span> as required.


We now come to the first of our definitions of the integral.

<br><br><strong>Definition 4.3</strong>
Let <span class='inline'>\Omega</span> be a measure space, with measure <span class='inline'>\mu</span>.  Let <span class='inline'>s\colon \Omega \rightarrow {\mathbb C}</span> be a measurable simple function, with set of non-zero values <span class='inline'>\{ \alpha_1 ,\ldots , \alpha_n \}</span>.  Write
<span class='inline'></span>s = \sum_k=1^n \alpha_k \chi_A_k<span class='inline'></span>

Let <span class='inline'>E\subseteq \Omega</span> be a measurable subset of <span class='inline'>\Omega</span>.  Then we define the \em integral of <span class='inline'>s</span> over <span class='inline'>E</span> to be the complex number
<span class='inline'></span>\int_E sd\mu = \sum_k=1^n \alpha_k \mu (A_k \cap E )<span class='inline'></span>
<br><br>

There are several simple computations we can do immediately with integrals.  For example, with <span class='inline'>s</span> as above:
<span class='inline'></span>\int_\Omega s\chi_E d\mu = \sum_k=1^\infty \alpha_k \mu (A_k \cap E) = \int_E sd\mu<span class='inline'></span>

<br><br><strong>Lemma 4.4</strong> 
Let <span class='inline'>\Omega</span> be a measure space, with measure <span class='inline'>\mu</span>.  Let <span class='inline'>s\colon \Omega \rightarrow [0,\infty )</span> be a measurable simple function.  Then we can define a new measure <span class='inline'>\varphi</span> on <span class='inline'>\Omega</span> by the formula
<span class='inline'></span>\varphi (E) = \int_E sd\mu<span class='inline'></span>
<br><br>

<br><i>Proof.</i>
To begin with, observe that <span class='inline'>\varphi (E)\geq 0</span> for every measurable set <span class='inline'>E</span>, and that if <span class='inline'>\mu (E) < \infty</span>, then <span class='inline'>\varphi (E) < \infty</span>, so there is at least one measurable set with finite measure.  We need to test <span class='inline'>\sigma</span>-additivity.

Let <span class='inline'>(E_n)</span> be a sequence of disjoint measurable sets.  We know that
<span class='inline'></span>\mu (\bigcup_i=1^\infty E_i ) = \sum_i=1^\infty \mu (E_i)<span class='inline'></span>

Let <span class='inline'>\{ \alpha_1 , \ldots , \alpha_k \}</span> be the set of non-zero values of the simple function <span class='inline'>s</span>.  Then
<span class='inline'></span>\varphi (\bigcup_i=1^\infty E_i ) = \sum_k=1^n \sum_i=1^\infty \alpha_k \mu (A_k \cap E_i )<span class='inline'></span>

Exchanging the summation signs is possible since all of the numbers involved in the above equation are positive.  Therefore
<span class='inline'></span>\varphi (\bigcup_i=1^\infty E_i ) = \sum_i=1^\infty \sum_k=1^n \alpha_k \mu (A_k \cap E_i ) = \sum_i=1^\infty \varphi (E_i)<span class='inline'></span>
and we are done.


<br><br><strong>Proposition 4.5</strong> 
Let <span class='inline'>s,t\colon \Omega \rightarrow [0,\infty ]</span> be simple functions.  Then
<span class='inline'></span>\int_\Omega s+td\mu = \int_\Omega sd\mu + \int_\Omega td\mu<span class='inline'></span>
<br><br>

<br><i>Proof.</i>
Write as usual
<span class='inline'></span>s = \sum_i=1^m \alpha_k \chi_A_i \qquad t = \sum_j=1^n \beta_j \chi_B_j<span class='inline'></span>

Let <span class='inline'>E_{ij} = A_i \cap B_j</span>.  Then certainly
<span class='inline'></span>int_E_ij (s+t)d\mu = (\alpha_i +\beta_j)\mu (E_ij) = \int_E_ijsd\mu + \int_E_ijtd\mu<span class='inline'></span>

Now the sets <span class='inline'>\{ 0, \alpha_1 , \ldots , \alpha_m \}</span> and <span class='inline'>\{ 0, \beta_1 , \ldots ,\beta_n \}</span> are the ranges of the functions <span class='inline'>s</span> and <span class='inline'>t</span> respectively.  Let <span class='inline'>A_0 = s^{-1}[0]</span> and <span class='inline'>B_0 = t^{-1}[0]</span>.  Then
<span class='inline'></span>\Omega = \bigcup_i=0^m A_i = \bigcup_j=0^n B_j<span class='inline'></span>

Hence
<span class='inline'></span>\Omega = \bigcup_i,j=0^m,nE_ij<span class='inline'></span>

The sets <span class='inline'>E_{ij}</span> are certainly disjoint.  Hence by the above lemma, we know that
<span class='inline'></span>\int_\Omega s+t d\mu = int_\Omega sd\mu + \int_\Omega td\mu<span class='inline'></span>
and we are done.


If <span class='inline'>s</span> is a step function, and <span class='inline'>\alpha \in {\mathbb C}</span>, then clearly
<span class='inline'></span>\int_\Omega \alpha sd\mu = \alpha \int_\Omega sd\mu<span class='inline'></span>

Hence we have proven linearity for integrals of positive-valued step functions.

</p><h1>5 Integration of Positive-Valued Functions</h1><p>

<br><br><strong>Definition 5.1</strong>
Let <span class='inline'>\Omega</span> be a measure space, with measure <span class='inline'>\mu</span>.  Let <span class='inline'>f\colon \Omega \rightarrow [0,\infty ]</span> be a measurable function, and let <span class='inline'>E\subseteq \Omega</span> be a measurable set.  Let <span class='inline'>S</span> be the set of simple functions, <span class='inline'>s\colon \Omega \rightarrow [0,\infty )</span>, such that <span class='inline'>s(x) \leq f(x)</span> for all <span class='inline'>x\in \Omega</span>.  Then we define the \em integral of <span class='inline'>f</span> over <span class='inline'>E</span>:
<span class='inline'></span>\int_E fd\mu = \sup \ \int_E sd\mu |s\in S \<span class='inline'></span>
<br><br>

A few properties of the integral are easy to prove.  For example:

\beginitemize

\item Let <span class='inline'>f\colon \Omega \rightarrow [0,\infty ]</span> and <span class='inline'>E\subseteq \Omega</span> be measurable.  Then
<span class='inline'></span>\int_\Omega fd\mu = \int_\Omega f\chi_Ed\mu<span class='inline'></span>


\item Let <span class='inline'>f,g\colon \Omega \rightarrow [0,\infty ]</span> be measurable functions such that <span class='inline'>f\leq g</span>, that is to say <span class='inline'>f(x)\leq g(x)</span> for all <span class='inline'>x\in \Omega</span>.  Then
<span class='inline'></span>\int_E f \leq \int_E g<span class='inline'></span>
whenever <span class='inline'>E\subseteq \Omega</span> is a measurable subset.

\enditemize

<br><br><strong>Theorem 5.2</strong>[The Monotone Convergence Theorem]

Let <span class='inline'>f_n\colon \Omega \rightarrow [0,\infty ]</span> be a sequence of measurable functions, such that for each point <span class='inline'>x\in \Omega</span> the sequence <span class='inline'>(f_n (x))</span> is monotonically increasing, with limit <span class='inline'>f(x)</span>.  Then the function <span class='inline'>f\colon \Omega \rightarrow [0,\infty ]</span> is measurable, and
<span class='inline'></span>\int_\Omega fd\mu = \lim_n\rightarrow \infty \int_\Omega f_n d\mu<span class='inline'></span>
<br><br>

<br><i>Proof.</i>
As the limit of a sequence of measurable functions, the function <span class='inline'>f</span> is measurable.  Since the seqyebce <span class='inline'>(f_n (x))</span> is monotonic increasing, with limit <span class='inline'>f(x)</span>, we know that <span class='inline'>F_n \leq f_{n+1} \leq f</span> for all <span class='inline'>n</span>.  Therefore the sequence of integrals <span class='inline'>\left( \int_\Omega f_n \right)</span> is monotonic increasing, and
<span class='inline'></span>\int_\Omega f_n d\mu \leq \int_\Omega f d\mu<span class='inline'></span>
for all <span class='inline'>n</span>.

Choose a simple function <span class='inline'>s</span> such that <span class='inline'>0\leq s\leq f</span>.  Let <span class='inline'>0 < \alpha  < 1</span>, and write
<span class='inline'></span>E_n = \ x\in \Omega |f_n (x) \geq \alpha s(x) \<span class='inline'></span>

Each set <span class='inline'>E_n</span> is measurable, and <span class='inline'>E_n \subseteq E_{n+1}</span> for all <span class='inline'>n</span> since the sequence <span class='inline'>(f_n)</span> is monotonic increasing.  Since the sequence <span class='inline'>(f_n)</span> has pointwise limit <span class='inline'>f</span>, we see that
<span class='inline'></span>\Omega = \bigcup_n=1^\infty E_n<span class='inline'></span>

Further
<span class='inline'></span>\int_\Omega f_nd\mu \geq \int_E_n f_n d\mu \geq \alpha \int_E_nsd\mu \qquad (\ast )<span class='inline'></span>

By lemma 4.4 we can define a measure on the set <span class='inline'>\Omega</span> by the formula
<span class='inline'></span>\varphi (E) = \int_E sd\mu<span class='inline'></span>
Hence
<span class='inline'></span>\int_\Omega sd\mu = \varphi (\Omega ) = \lim_n\rightarrow \infty \varphi (E_n ) = \lim_n\rightarrow \infty \int_E_nsd\mu<span class='inline'></span>
by proposition 3.7.

Taking limits in inequality <span class='inline'>(\ast )</span>, we see that
<span class='inline'></span>\lim_n\rightarrow \infty  \int_\Omega f_n d\mu \geq \alpha \int_\Omega sd\mu<span class='inline'></span>

In particular, this inequality holds whenever <span class='inline'>0 < \alpha  < 1</span> and <span class='inline'>s\leq f</span>.  By the definition of the integral, it follows that
<span class='inline'></span>\lim_n\rightarrow \infty\int_\Omega f_n d\mu \geq \int_\Omega f d\mu<span class='inline'></span>
and we are done.


Let <span class='inline'>f\colon \Omega \rightarrow [0,\infty ]</span> be a measurable function.  By proposition 4.2, there is a monotonically increasing sequence of simple functions <span class='inline'>s\colon \Omega \rightarrow [0,\infty )</span> with pointwise limit <span class='inline'>f</span>.

The monotone convergence theorem tells us that
<span class='inline'></span>\int_\Omega f = \lim_n\rightarrow \infty \int_\Omega s_n<span class='inline'></span>
and so gives us a new way of viewing the definition of the integral.  Using this viewpoint, the following result follows immediately from proposition 4.5

<br><br><strong>Corollary 5.3</strong>
Let <span class='inline'>f,g\colon \Omega \rightarrow [0,\infty ]</span> be measurable functions, and let <span class='inline'>\alpha, \beta \in [0, \infty )</span>.  Then
<span class='inline'></span>\int_\Omega (\alpha f+ \beta g)d\mu = \alpha \int_\Omega fd\mu + \beta \int_\Omega gd\mu<span class='inline'></span>
<strong>proof to be filled in!</strong>
<br><br>

We can also immediately deduce the following result from the monotone convergence theorem.

<br><br><strong>Corollary 5.4</strong>
Consider a sequence of measurable functions <span class='inline'>f_n \colon \Omega \rightarrow [0,\infty ]</span>.  Then for any measurable subset <span class='inline'>E\subseteq \Omega</span> we have the formula<span class='inline'></span>\sum_n=1^\infty \int_E f_nd\mu = \int_E \left( \sum_n=1^\infty f_n \right) d\mu<span class='inline'></span>
<strong>proof to be filled in!</strong>
<br><br>

<br><br><strong>Theorem 5.5</strong>[Fatou's lemma]

Let <span class='inline'>f_n \colon \Omega \rightarrow [0,\infty ]</span> be a sequence of measurable functions.  Then
<span class='inline'></span>\int_\Omega \lim \inf_n\rightarrow \infty f_n \leq \lim \inf_n\rightarrow \infty \int_\Omega f_n<span class='inline'></span>
<br><br>

<br><i>Proof.</i>
Let
<span class='inline'></span>g_n (x) = \inf \ f_n (x) , f_n+1 (x) , f_n+2 (x) , \ldots \<span class='inline'></span>

Then the function <span class='inline'>g_n</span> is measurable, the sequence <span class='inline'>(g_n)</span> is monotonic increasing, and the inequality <span class='inline'>g_n \leq f_n</span> holds for all <span class='inline'>n</span>.

We know that
<span class='inline'></span>\lim_n\rightarrow \infty g_n (x) = \lim \inf_n\rightarrow \infty f_n (x)<span class='inline'></span>

Hence, by the monotone convergence theorem
<span class='inline'></span>\int_\Omega \lim \inf_n\rightarrow \infty f_n  = \lim_n\rightarrow \infty \int_\Omega g_n \leq \lim \inf_n\rightarrow \infty \int_\Omega f_n<span class='inline'></span>
and we are done.


The inequality 
<span class='inline'></span>\int_\Omega \lim \sup_n\rightarrow \infty f_n \geq \lim \sup_n\rightarrow \infty \int_\Omega f_n<span class='inline'></span>
is easily deduced from Fatou's lemma.

</p><h1>6 Integration of Complex-Valued Functions</h1><p>

<br><br><strong>Definition 6.1</strong>
Let <span class='inline'>\Omega</span> be a measure space, with measure <span class='inline'>\mu</span>.  We call a measurable function <span class='inline'>f\colon \Omega \rightarrow {\mathbb C}</span> \em integrable if
<span class='inline'></span>\int_\Omega |f|d\mu  <  \infty<span class='inline'></span>

We write <span class='inline'>L^1 (\Omega )</span> to denote the set of all integrable functions.
<br><br>

Suppose we have a measurable function <span class='inline'>f</span> and a positive-valued integrable function <span class='inline'>g</span> such that <span class='inline'>|f|\leq g</span>.  Then it follows by the above definition that the function <span class='inline'>f</span> is integrable.  This integrability criterion is often used.

<br><br><strong>Definition 6.2</strong>
Let <span class='inline'>f\colon \Omega \rightarrow {\mathbb R}</span> be any real-valued function.  Then we define functions <span class='inline'>f^+ , f^- \colon \Omega \rightarrow [0, \infty )</span> by the formulae
<span class='inline'></span>f^+ (x) = \max (f(x), 0)) \qquad f^- (x) = \max (-f(x) , 0)<span class='inline'></span>
respectively.
<br><br>

Observe that <span class='inline'>f = f^+ - f^-</span>.  If the function <span class='inline'>f</span> is measurable, then so are the functions <span class='inline'>f^+</span> and <span class='inline'>f^-</span>.

<br><br><strong>Proposition 6.3</strong>
Let <span class='inline'>f\colon \Omega \rightarrow {\mathbb R}</span> be an integrable function.  Then the functions <span class='inline'>f^+</span> and <span class='inline'>f^-</span> are also integrable.
<br><br>

<br><i>Proof.</i>
The functions <span class='inline'>f^+</span> and <span class='inline'>|f|</span> are positive-valued, and <span class='inline'>f^+ \leq |f|</span>.  We know that <span class='inline'>\int_\Omega |f|  <  \infty</span>, so <span class='inline'>\int_\Omega f^+  < \infty</span>.

The proof that the function <span class='inline'>f^-</span> is integrable is identical to the above.


<br><br><strong>Definition 6.4</strong>
Let <span class='inline'>f\colon \Omega \rightarrow {\mathbb R}</span> be an integrable function.  Then we define we define the integral
<span class='inline'></span>\int_\Omega fd\mu := \int_\Omega f^+d\mu - \int_\Omega f^-d\mu<span class='inline'></span>
<br><br>

It is easy to see that definition agrees with the previous definition when the function <span class='inline'>f</span> is positive-valued.  Further, the equation
<span class='inline'></span>\int_\Omega (\alpha f + \beta g)d\mu = \alpha \int_\Omega f d\mu + \beta \int_\Omega gd\mu<span class='inline'></span>
holds for all real numbers <span class='inline'>\alpha , \beta \in {\mathbb R}</span> and integrable functions <span class='inline'>f,g\colon \Omega \rightarrow {\mathbb R}</span>.

<br><br><strong>Definition 6.5</strong>
Let <span class='inline'>f,g\colon \Omega \rightarrow {\mathbb C}</span> be integrable functions.  Then we define the integral
<span class='inline'></span>\int_\Omega fd\mu := \int_\Omega \Re (f)d\mu +i \int_\Omega \Im (f)d\mu<span class='inline'></span>
<br><br>

An argument similar to that made above tells us that this integral is well-defined, agrees with the previous definition for real-valued functions, and is linear.

<br><br><strong>Proposition 6.6</strong> 
Let <span class='inline'>f\colon \Omega \rightarrow {\mathbb C}</span> be an integrable function.  Then
<span class='inline'></span>\left| \inf_\Omega fd\mu \right| \leq \int_\Omega |f|d\mu<span class='inline'></span>
<br><br>

<br><i>Proof.</i>
Choose <span class='inline'>\alpha \in {\mathbb C}</span> such that <span class='inline'>|\alpha |=1</span> and
<span class='inline'></span>\left| \inf_\Omega fd\mu \right| = \alpha \int_\Omega fd\mu = \int_\Omega \alpha fd\mu<span class='inline'></span>

Let <span class='inline'>g = \Re (\alpha f )</span> and <span class='inline'>h= \Im (\alpha f)</span>.  Then
<span class='inline'></span>\left| \inf_\Omega fd\mu \right| = \int_\Omega gd\mu + i \int_\Omega hd\mu<span class='inline'></span>

Certainly, <span class='inline'>\left| \inf_\Omega fd\mu \right| \in {\mathbb R}</span>, so
<span class='inline'></span>\int_\Omega hd\mu<span class='inline'></span>
and
<span class='inline'></span>\left| \inf_\Omega fd\mu \right| = \int_\Omega gd\mu<span class='inline'></span>

However
<span class='inline'></span>g\leq  |g| \leq |\alpha f| = |f|<span class='inline'></span>  
It follows that
<span class='inline'></span>\left| \inf_\Omega fd\mu \right| \leq \int_\Omega |f|d\mu<span class='inline'></span>
and we are done.


Observe that the proof of the above result uses only positivity and linearity of the integral.

<br><br><strong>Theorem 6.7</strong>[The Dominated Convergence Theorem]
Let <span class='inline'>(f_n)</span> be a sequence of measurable functions <span class='inline'>f_n \colon \Omega \rightarrow {\mathbb C}</span> such that:

\beginitemize

\item The limit
<span class='inline'></span>f(x) = \lim_n\rightarrow \infty f_n (x)<span class='inline'></span>
exists for all <span class='inline'>x\in \Omega</span>.

\item There is an integrable function <span class='inline'>g\in L^1 (\Omega )</span> such that <span class='inline'>|f_n (x)|\leq g(x)</span> for all <span class='inline'>x\in \Omega</span> and <span class='inline'>n\in {\mathbb N}</span>.

\enditemize

Then <span class='inline'>f\in L^1 (\Omega )</span>, and
<span class='inline'></span>\lim_n\rightarrow \infty \int_\Omega |f_n - f|d\mu =0<span class='inline'></span>
<br><br>

<br><i>Proof.</i>
Since each fucntion <span class='inline'>f_n</span> is measurable, the limit function <span class='inline'>f</span> is also measurable.  We know that <span class='inline'>|f_n|\leq g</span> for all <span class='inline'>n</span>.  Therefore <span class='inline'>|f|\leq g</span>.  It follows that <span class='inline'>f\in L^1 (\Omega )</span>.

Now, let
<span class='inline'></span>h_n = 2g - |f_n -f |<span class='inline'></span>

Observe that <span class='inline'>h_n \geq 0</span> for all <span class='inline'>n</span>.  Hence by Fatou's lemma
<span class='inline'></span>\int_\Omega \lim \inf_n\rightarrow \infty h_n \leq \lim \inf_n\rightarrow \infty \int_\Omega h_n<span class='inline'></span>
that is
<span class='inline'></span>\int_\Omega 2gd\mu \leq \int_\Omega 2gd\mu - \lim \inf_n\rightarrow \infty \int_\Omega |f_n -f| d\mu<span class='inline'></span>
and so
<span class='inline'></span>\lim \inf_n\rightarrow \infty \int_\Omega |f_n -f| d\mu \leq 0<span class='inline'></span>

Since <span class='inline'>|f_n -f | \geq 0</span> for all <span class='inline'>n</span>, we deduce that
<span class='inline'></span>\lim_n\rightarrow \infty \int_\Omega |f_n - f|d\mu =0<span class='inline'></span>
as required.


Combining the dominated convergence theorem with proposition ref_error we obtain the following corollary, also referred to as the dominated convergence theorem.

<br><br><strong>Corollary 6.8</strong>[The Dominated Convergence Theorem]
Let <span class='inline'>(f_n)</span> be a sequence of measurable functions <span class='inline'>f_n \colon \Omega \rightarrow {\mathbb C}</span> such that:

\beginitemize

\item The limit
<span class='inline'></span>f(x) = \lim_n\rightarrow \infty f_n (x)<span class='inline'></span>
exists for all <span class='inline'>x\in \Omega</span>.

\item There is an integrable function <span class='inline'>g\in L^1 (\Omega )</span> such that <span class='inline'>|f_n (x)|\leq g(x)</span> for all <span class='inline'>x\in \Omega</span> and <span class='inline'>n\in {\mathbb N}</span>.

\enditemize

Then <span class='inline'>f\in L^1 (\Omega )</span>, and
<span class='inline'></span>\lim_n\rightarrow \infty \int_\Omega f_n d\mu = \int_\Omega fd\mu<span class='inline'></span>
<strong>proof to be filled in!</strong>
<br><br>

</p><h1>7 Null Sets</h1><p>

<br><br><strong>Definition 7.1</strong>
Let <span class='inline'>\Omega</span> be a measure space, with measure <span class='inline'>\mu</span>.  Then a set <span class='inline'>E\subseteq \Omega</span> is called a \em null set if <span class='inline'>E</span> is measurable, and <span class='inline'>\mu (E) =0</span>.

The measure space <span class='inline'>\Omega</span> is called \em complete if every subspace of a null set is measurable.
<br><br>

The usual manipulations of the axioms tell us that every measure space is contained in a unique smallest complete measure space.  To be more precise, we have the following result.

<br><br><strong>Proposition 7.2</strong>
Let <span class='inline'>\Omega</span> be a measure space, equipped with <span class='inline'>\sigma</span>-algbebra <span class='inline'>\mathcal M</span>, and measure <span class='inline'>\mu</span>.  Let us define 
<span class='inline'></span>\mathcal M^\star := \ E\subseteq \Omega |A\subseteq E\subseteq B,\, A,B\in \Omega ,\, \mu (B\backslash A) = 0 \<span class='inline'></span>

Then the set <span class='inline'>{\mathcal M}^\star</span> is a <span class='inline'>\sigma</span>-algebra.  We can define a measure <span class='inline'>\mu^\star</span> on the set <span class='inline'>{\mathcal M}^\star</span> by writing
<span class='inline'></span>\mu^\star (E) = \mu (A) \qquad A\subseteq E\subseteq B,A,B\in \Omega ,\mu (B\backslash A) =0<span class='inline'></span>
<strong>proof to be filled in!</strong>
<br><br>

As we might expect from the terminology, null sets are irrelevant from the point of view of integration theory.

<br><br><strong>Theorem 7.3</strong>
Let <span class='inline'>f\colon \Omega \rightarrow [0,\infty ]</span> be a measurable function.  Then the integral of <span class='inline'>f</span> is zero if and only if the function <span class='inline'>f</span> is equal to zero except on a null set.
<br><br>

<br><i>Proof.</i>
Suppose that the set
<span class='inline'></span>N = \ x\in \Omega |f(x)\neq 0 \<span class='inline'></span>
is a null set.  Let <span class='inline'>s\colon \Omega \rightarrow [0,\infty ]</span> be a simple function such that <span class='inline'>s\leq f</span>.  Then <span class='inline'>s(x)=0</span> when <span class='inline'>x\not\in N</span>.  The definition of the integral of a simple function tells us that
<span class='inline'></span>\int_\Omega s d\mu =0<span class='inline'></span>

The definition of the integral of a non-negative function now implies that
<span class='inline'></span>\int_\Omega fd\mu =0<span class='inline'></span>

Conversely, suppose that the integral of the function <span class='inline'>f</span> is zero.  Let
<span class='inline'></span>A_n = \ x\in \Omega |f(x) >  1/n \<span class='inline'></span>

Then clearly
<span class='inline'></span>\frac1n \mu (A_n ) \leq \int_A_n fd\mu \leq \int_\Omega f d\mu =0<span class='inline'></span>
so <span class='inline'>\mu (A_n ) =0</span>.  But
<span class='inline'></span>\ x\in \Omega |f(x)  > 0 \ = \bigcup_n=1^\infty A_n<span class='inline'></span>

Thus <span class='inline'>\sigma</span>-additivity implies that the set of all points <span class='inline'>x\in \Omega</span> such that <span class='inline'>f(x)\neq 0</span> has measure zero.


Given two functions <span class='inline'>f,g\colon \Omega \rightarrow {\mathbb C}</span>, let us say that <span class='inline'>f</span> and <span class='inline'>g</span> are equal \em almost everywhere if they are equal outside of some set of measure zero.

<br><br><strong>Corollary 7.4</strong>
Let <span class='inline'>f,g\colon \Omega \rightarrow {\mathbb C}</span> be integrable functions that are equal almost everywhere.  Then
<span class='inline'></span>\int_\Omega f = \int_\Omega g<span class='inline'></span>
<strong>proof to be filled in!</strong>
<br><br>

<br><br><strong>Corollary 7.5</strong>
Let <span class='inline'>f\colon \Omega \rightarrow {\mathbb C}</span> be an integrable function.  Suppose that
<span class='inline'></span>\int_E f =0<span class='inline'></span>
whenever the subset <span class='inline'>E\subseteq \Omega</span> is measurable.  Then the function <span class='inline'>f</span> is equal to zero almost everywhere.
<br><br>

<br><i>Proof.</i>
Let us write
<span class='inline'></span>f(x) = u(x) + iv(x) = (u^+(x)- u^- (x)) + i(v^+(x) - v^-(x))<span class='inline'></span>
where the functions <span class='inline'>u</span> and <span class='inline'>v</span> are real and integrable, and the functions <span class='inline'>u^\pm</span> and <span class='inline'>v^\pm</span> are integrable and non-negative.

Let
<span class='inline'></span>E = \ x\in \Omega |u(x)\geq 0 \<span class='inline'></span>
Then
<span class='inline'></span>\Re \left( \int_E f \right) = \int_E u^+ =0<span class='inline'></span>

By the above theorem, it follows that <span class='inline'>u^+ =0</span> except on a null set.  Similarly, it follows that <span class='inline'>u^- =0</span> except on a null set.  Since the union of two null sets is also a null set, we have shown that <span class='inline'>u=0</span> almost everywhere.

A similar argument tells us that <span class='inline'>v=0</span> almost everywhere.  We conclude that <span class='inline'>f=0</span> almost everywhere.


</p><h1>8 The Riesz Representation Theorem</h1><p>

Before we are ready to state the Riesz representation theorem, we need some terminology from point-set topology.

<br><br><strong>Definition 8.1</strong>
Let <span class='inline'>X</span> be a topological space.  Then we define the \em support of a continuous function <span class='inline'>f\colon X\rightarrow {\mathbb C}</span> to be the closure
<span class='inline'></span>\operatornamesupp (f):= \overline \ x\in X |f(x)\neq 0 \ <span class='inline'></span>
<br><br>

We write <span class='inline'>C_c (X)</span> to denote the set of all continuous compactly supported functions <span class='inline'>f\colon X\rightarrow {\mathbb C}</span>.  The set <span class='inline'>C_c (X)</span> is a vector space under the operations of pointwise addition and scalar multiplication.

<br><br><strong>Definition 8.2</strong>
A linear map <span class='inline'>\Lambda \colon C_c (X) \rightarrow {\mathbb C}</span> is said to be a \em positive functional if <span class='inline'>\Lambda (f) \geq 0</span> whenever <span class='inline'>f\geq 0</span>.
<br><br>

Let <span class='inline'>X</span> be a topological space equipped with a Borel measure <span class='inline'>\mu</span> such that <span class='inline'>\mu (K)  < \infty</span> whenever <span class='inline'>K\subseteq X</span> is a compact subspace.  Then the integration map
<span class='inline'></span>f\mapsto \int_X f<span class='inline'></span>
defines a positive linear functional.

The Riesz representation theorem is essentially a converse of the above observation.

<br><br><strong>Theorem 8.3</strong>
Let <span class='inline'>X</span> be a locally compact Hausdorff space, and let <span class='inline'>\Lambda \colon C_c (X) \rightarrow {\mathbb C}</span> be a positive linear functional.

Then the set <span class='inline'>X</span> has a <span class='inline'>\sigma</span>-algebra <span class='inline'>\Omega</span> containing all Borel sets, and a unique measure <span class='inline'>\mu</span> on <span class='inline'>\Omega</span> such that
<span class='inline'></span>\Lambda (f) = \int_X fd\mu<span class='inline'></span>
whenever <span class='inline'>f\in C_c (X)</span>.
<br><br>

The proof of this theorem is in a series of lemmas; the proof is quite long.  Before we begin the proof, let us note a theorem from general topology which we shall need.

<br><br><strong>Theorem 8.4</strong> 
Let <span class='inline'>X</span> be a locally compact Hausdorff space, and let <span class='inline'>{\mathcal U} = \{ U_\alpha |\alpha \in A \}</span> be an open cover of the space <span class='inline'>X</span>.  Then there is a \em partition of unity subordinate to the cover <span class='inline'>\mathcal U</span>, that is to say a set of continuous functions <span class='inline'>u_\alpha \colon X\rightarrow [0,1]</span> such that <span class='inline'>\operatorname{supp} u_\alpha \subseteq U_\alpha</span> and
<span class='inline'></span>\sum_\alpha \in A u_\alpha (x) =1<span class='inline'></span>
whenever <span class='inline'>x\in X</span>.
<strong>proof to be filled in!</strong>
<br><br>

The following corollary is known as \em Urysohn's lemma.

<br><br><strong>Corollary 8.5</strong>
Let <span class='inline'>X</span> be a locally compact Hausdorff space, and let <span class='inline'>K\subseteq X</span> be a compact set, and let <span class='inline'>U</span> be an open set containing <span class='inline'>K</span>.  Then there is a continuous function <span class='inline'>f\colon X\rightarrow [0,1]</span>
such that
<span class='inline'></span>\chi_K(x) \leq f(x) \leq \chi_U (x)<span class='inline'></span>
<br><br>

<br><i>Proof.</i>
The collection <span class='inline'>\{ U, X\backslash K \}</span> is an open cover of the space <span class='inline'>X</span>.  There is therefore a partition of unity <span class='inline'>\{ f,g\}</span> subordinate to this open cover.

The definition of a partition of unity gives us the required inequality for the function <span class='inline'>f</span>.


We now begin our proof of the Riesz representation theorem with the definition of the measure we are looking for.

<br><br><strong>Definition 8.6</strong>
Let <span class='inline'>\Lambda \colon C_c (X) \rightarrow {\mathbb C}</span> be a positive linear functional.  Let <span class='inline'>U\subseteq X</span> be open.  Then we define
<span class='inline'></span>\mu (U):= \sup \ \Lambda f |f\leq \chi_U \<span class='inline'></span>

In general, for a subset, <span class='inline'>E\subset X</span>, we define
<span class='inline'></span>\mu (E) = \inf \ \ \mu (U) |U \textrm open , E\subseteq U \<span class='inline'></span>
<br><br>

<br><br><strong>Proposition 8.7</strong>
Let <span class='inline'>f,g\in C_c (X)</span>, and let <span class='inline'>f\leq g</span>.  Then <span class='inline'>\Lambda f \leq \Lambda g</span>.
<br><br>

<br><i>Proof.</i>
Observe <span class='inline'>g-f \geq 0</span>.  The result follows from positivity and linearity of the function <span class='inline'>\Lambda</span>.


<br><br><strong>Corollary 8.8</strong>
Let <span class='inline'>A</span> and <span class='inline'>B</span> be subsets of the space <span class='inline'>X</span> where <span class='inline'>A\subseteq B</span>.  Then <span class='inline'>\mu (A)\leq \mu (B)</span>.
<strong>proof to be filled in!</strong>
<br><br>

Although we have defined a function <span class='inline'>\mu</span> for every subset of <span class='inline'>E</span>, the definition is only sensible for a certain <span class='inline'>\sigma</span>-algebra.

<br><br><strong>Definition 8.9</strong>
We define <span class='inline'>\Omega_F</span> to be the sollection of all subsets <span class='inline'>E\subseteq X</span> such that <span class='inline'>\mu (E) < \infty</span> and
<span class='inline'></span>\mu (E) = \sup \ \mu (K) |K\subseteq E, K \textrm compact \<span class='inline'></span>

We define <span class='inline'>\Omega</span> to be the collection of all subsets <span class='inline'>E\subseteq X</span> such that <span class='inline'>E\cap K \in \Omega_F</span> whenever <span class='inline'>K</span> is compact.
<br><br>

We need to prove that the set <span class='inline'>\Omega</span> is a <span class='inline'>\sigma</span>-algebra which contains all Borel sets; this statement is not obvious.

<br><br><strong>Proposition 8.10</strong> 
Let <span class='inline'>V\subseteq X</span> be an open subset such that <span class='inline'>\mu (V) < \infty</span>.  Then <span class='inline'>V\in \Omega_F</span>.
<br><br>

<br><i>Proof.</i>
Choose a number <span class='inline'>a <  \mu (V)</span>.  By the definition of <span class='inline'>\mu</span>, there is a function <span class='inline'>f\in C_c (X)</span> such that <span class='inline'>f\leq \chi_V</span> and <span class='inline'>a <  \Lambda f</span>.  Write <span class='inline'>K=\operatorname{supp} (f)</span>, and let <span class='inline'>W</span> be an open set that contains <span class='inline'>K</span>.  Then <span class='inline'>\Lambda f \leq \mu (W)</span>, so <span class='inline'>\Lambda f \leq \mu (K)</span>, using the above proposition and corollary, and the definition of the function <span class='inline'>\mu</span>.

Thus <span class='inline'>K\subseteq V</span> and <span class='inline'>\mu (K)  > a</span>.  It follows that
<span class='inline'></span>\mu (V) = \sup \ \mu (K) |K\subseteq E, K \textrm compact \<span class='inline'></span>
and we are done.



<br><br><strong>Proposition 8.11</strong>
Let <span class='inline'>U_1 , \ldots , U_N\subseteq X</span> be open sets.  Then 
<span class='inline'>\mu (U_1\cup \cdots \cup U_N) \leq \mu (U_1)+ \cdots +\mu (U_N)</span>.
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>N=2</span>.  Choose a function <span class='inline'>g\in C_c (X)</span> such that <span class='inline'>g\leq \chi_{U_1\cup U_2}</span>.  By theorem 8.4 there are functions <span class='inline'>u_1 , u_2\in C_c (X)</span> such that <span class='inline'>u_1\leq \chi_{U_1}</span>, <span class='inline'>u_2\leq \chi_{u_2}</span>, and <span class='inline'>u_1(x) + u_2 (x) =1</span> whenever <span class='inline'>x\in U_1\cup U_2</span>.  It follows that
<span class='inline'></span>u_1 g\leq \chi_U_1,u_2g \leq \chi_U_2 \qquad g=u_1 g + u_2 g<span class='inline'></span>
and therefore
<span class='inline'></span>\Lambda g = \Lambda (u_1 g) +\Lambda (u_2 g) \leq \mu (U_1) + \mu (U_2)<span class='inline'></span>

Since the above inequality holds for every function <span class='inline'>g\in C_c (X)</span> such that <span class='inline'>g\leq \chi_{U_1\cup U_2}</span>, the result follows from the definition of <span class='inline'>\mu</span> when <span class='inline'>N=2</span>.  The general result follows by induction.


<br><br><strong>Lemma 8.12</strong> 
Let <span class='inline'>E_1,E_2,E_3,\ldots</span> be subsets of the space <span class='inline'>X</span>.    Write
<span class='inline'></span>E = \bigcup_n=1^\infty E_n<span class='inline'></span>

Then
<span class='inline'></span>\mu (E) \leq \sum_n=1^\infty \mu (E_n)<span class='inline'></span>
<br><br>

<br><i>Proof.</i>
If <span class='inline'>\mu (E_n )=\infty</span> for some <span class='inline'>n</span>, then the result is obviously true.  Thus, let us suppose that <span class='inline'>\mu (E_n) < \infty</span> for all <span class='inline'>n</span>.  Choose <span class='inline'>\varepsilon  > 0</span>.  By definition of the function <span class='inline'>\mu</span>, there are open sets <span class='inline'>U_n \supseteq V_n</span> such that
<span class='inline'></span>\mu (V_n)  <  \mu (E_n) +2^-n \varepsilon<span class='inline'></span>
for all <span class='inline'>n</span>.

Let <span class='inline'>U = \bigcup_{n=1}^\infty U</span>, and choose <span class='inline'>f\in C_c (X)</span> such that <span class='inline'>f\leq \chi_U</span>.  The support of the function <span class='inline'>f</span> is covered by the collection of sets <span class='inline'>\{ U_n |n=1,2,3,\ldots \}</span>.  Since the function <span class='inline'>f</span> has compact support, it follows that it has a finite subcovering, and so 
<span class='inline'></span>f\leq \chi_U_1 \cup \cdots \cup U_N <span class='inline'></span>
for some <span class='inline'>N</span>.  By the above proposition, we see that
<span class='inline'></span>\Lambda f \leq \mu (U_1 \cup \cdots \cup U_N) \leq \mu(V_1 ) + \cdots + \mu (V_N) \leq \sum_n=1^\infty \mu (E_n) + \varepsilon<span class='inline'></span>

Since the above inueqality holds for every funtion <span class='inline'>f\subseteq \chi_U</span>, and <span class='inline'>E\subseteq U</span>, we see that 
<span class='inline'></span>\mu (E) \leq \sum_n=1^\infty \mu (E_n) +\varepsilon<span class='inline'></span>

But this inequality holds whenever <span class='inline'>\varepsilon  > 0</span>, so the result follows.


<br><br><strong>Proposition 8.13</strong>
Let <span class='inline'>K\subseteq X</span> be compact.  Then <span class='inline'>\mu (K)\leq \Lambda f</span> whenever <span class='inline'>f\geq \chi_K</span>, and <span class='inline'>K\in \Omega_F</span>.
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>0 < a < 1</span>, and choose <span class='inline'>f\in C_c (X)</span> such that <span class='inline'>f\geq \chi_K</span>.  Write
<span class='inline'></span>V_a = \ x\in X |f(x) > a \<span class='inline'></span>

Then <span class='inline'>K\subseteq V_a</span>, and <span class='inline'>ag\leq f</span> whenever <span class='inline'>f\leq \chi_{V_a}</span>.  Therefore
<span class='inline'></span>\mu (K) \leq \mu (V_a ) = \sup \ \Lambda g | g\leq \chi_V_a \ \leq a^-1\Lambda f<span class='inline'></span>

Since this inequaltity holds whenever <span class='inline'>0 < a < 1</span>, it follows that <span class='inline'>\mu (K)\leq \Lambda f</span>.  It follows that <span class='inline'>\mu (K) <  \infty</span>, and so <span class='inline'>K\in \Omega_F</span>.


<br><br><strong>Lemma 8.14</strong> 
Let <span class='inline'>K\subseteq X</span> be compact.  Then
<span class='inline'></span>\mu (K) =\inf \ \Lambda f |\chi_K \leq f \<span class='inline'></span>
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>\varepsilon  > 0</span>.  Then there is an open set <span class='inline'>U\supseteq K</span> such that <span class='inline'>\mu (U)  <  \mu (K) +\varepsilon</span>.  By Urysohn's lemma there is a continuous function <span class='inline'>f\colon [0,1]\rightarrow X</span> such that <span class='inline'>\chi_K \leq f \leq \chi_U</span>.  It follows that
<span class='inline'></span>\Lambda f\leq \mu(U)  <  \mu (K) +\varepsilon<span class='inline'></span>

The result follows from the above inequality combined with the previous proposition.


<br><br><strong>Proposition 8.15</strong> 
Let <span class='inline'>K_1,\ldots K_N</span> be disjoint compact sets.  Then
<span class='inline'></span>\mu (K_1 \cup \cdots \cup K_N) \leq \mu (K_1 ) + \cdots + \mu (K_N)<span class='inline'></span>
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>N=2</span>.  We can find an open set <span class='inline'>U</span> such that <span class='inline'>U\supseteq K_1</span> and <span class='inline'>U\cap K_2 = \emptyset</span>.  It follows by Urysohn's lemma that we can find a compactly supported function <span class='inline'>u\colon X\rightarrow [0,1]</span> such that <span class='inline'>u(x)=1</span> whenever <span class='inline'>x\in K_1</span>, and <span class='inline'>u(x) =0</span> whenever <span class='inline'>x\in K_2</span>.

Let <span class='inline'>\varepsilon  > 0</span>.  By lemma 8.14 there is a function <span class='inline'>g\in C_c (X)</span> such that
<span class='inline'></span>\chi_K_1 \cup K_2\leq g \qquad \Lambda g \leq \mu (K_1 + K_2) +\varepsilon<span class='inline'></span>

Observe that
<span class='inline'></span>\chi_K_1 \leq fg \qquad \chi_K_2 \leq (1-f)g<span class='inline'></span>

Hence
<span class='inline'></span>\mu (K_1 ) + \mu (K_2) \leq \Lambda (fg) + \Lambda (g-fg) \leq \mu (K_1 \cup K_2 ) + \varepsilon<span class='inline'></span>

Since the above inequality holds whenever <span class='inline'>\varepsilon  > 0</span>, the desired result follows when <span class='inline'>N=2</span>.  The general result follows by induction.


<br><br><strong>Lemma 8.16</strong> 
Let <span class='inline'>E_1,E_2,E_3,\ldots</span> be pairwise disjoint members of the collection <span class='inline'>\Omega_F</span>.  Write
<span class='inline'></span>E = \bigcup_n=1^\infty E_n<span class='inline'></span>

Then
<span class='inline'></span>\mu (E) = \sum_n=1^\infty \mu (E_n)<span class='inline'></span>

Further, if <span class='inline'>\mu (E)  < \infty</span>, then <span class='inline'>E\in \Omega_F</span>.
<br><br>

<br><i>Proof.</i>
Observe that the result follows from lemma 8.12 when <span class='inline'>\mu (E)=\infty</span>.  Let us therefore assume that <span class='inline'>\mu (E) < \infty</span>.  Choose <span class='inline'>\varepsilon  > 0</span>.  Since <span class='inline'>E_n\in \Omega_F</span>, we can find a compact set <span class='inline'>K_n \subseteq E_n</span> such that
<span class='inline'></span>\mu (K_n ) >  \mu (E_n ) - 2^-n \varepsilon<span class='inline'></span>
for each <span class='inline'>n</span>.  Let <span class='inline'>H_N = K_1 \cup \cdots \cup K_N</span>.  Then by the above propositiion:
<span class='inline'></span>\mu E) \geq \mu (H_N) = \sum_n=1^N \mu (K_n)  >  \sum_n=1^N \mu (E_n) - \varepsilon<span class='inline'></span>

Since the above inequality holds whenever <span class='inline'>\varepsilon  > 0</span>, combining it with the inequality in lemma 8.12, we see that
<span class='inline'></span>\mu (E) = \sum_n=1^\infty \mu (E_n)<span class='inline'></span>

Now, if <span class='inline'>\mu (E) < \infty</span>, and <span class='inline'>\varepsilon  > 0</span>, then we can find <span class='inline'>N</span> such that
<span class='inline'></span>\mu (E) \leq \sum_n=1^N \mu (E_n) + \varepsilon<span class='inline'></span>

It follows that <span class='inline'>\mu (E)\leq \mu (H_N) +2\varepsilon</span>, and so <span class='inline'>E\in \Omega_F</span>.


<br><br><strong>Proposition 8.17</strong> 
Let <span class='inline'>E\subseteq \Omega_F</span>, and let <span class='inline'>\varepsilon  > 0</span>.  Then there is a compact set <span class='inline'>K</span> and an open set <span class='inline'>V</span> such that <span class='inline'>K\subseteq E\subseteq V</span>, and <span class='inline'>\mu (V\backslash K) < \varepsilon</span>.
<br><br>

<br><i>Proof.</i>
by definition of the collection <span class='inline'>\Omega_F</span>, we can find a compact set <span class='inline'>K\subseteq E</span> and an open set <span class='inline'>U\supseteq E</span> such that
<span class='inline'></span>\mu (V) - \frac\varepsilon2  <  \mu (E)  <  \mu(K) + \frac\varepsilon2<span class='inline'></span>

By lemma 8.10, we see that <span class='inline'>V\backslash K \in \Omega_F</span>.  By lemma 8.16, we see
<span class='inline'></span>\mu (K) + \mu (U\backslash K) = \mu (U)  <  \mu (K) +\varepsilon<span class='inline'></span>
and we are done.


<br><br><strong>Proposition 8.18</strong>
Let <span class='inline'>A,B\in \Omega_F</span>.  Then the sets <span class='inline'>A\backslash B</span>, <span class='inline'>A\cup B</span>, and <span class='inline'>A\cap B</span> belong to the collection <span class='inline'>\Omega_F</span>.
<br><br>

<br><i>Proof.</i>
By the above proposition, there are compact sets <span class='inline'>K</span> and <span class='inline'>K'</span>, and open sets <span class='inline'>U</span> and <span class='inline'>U'</span> such that
<span class='inline'></span>K\subseteq A\subseteq U \qquad K'\subseteq B\subseteq U'<span class='inline'></span>
and
<span class='inline'></span>\mu (U\backslash K) <  \varepsilon \qquad \mu (U'\backslash K')  < \varepsilon<span class='inline'></span>

Observe
<span class='inline'></span>A\backslash B \subseteq U\backslash K' \subseteq U\backslash K \cup K\backslash U'\cup U'\backslash K'<span class='inline'></span>

Hence by lemme 8.12:
<span class='inline'></span>\mu (A\backslash B) \subseteq \mu (K\backslash V') +2\varepsilon<span class='inline'></span>

Further, the set <span class='inline'>K\backslash V'</span> is compact, so the above inequality tells us that <span class='inline'>A\backslash B \in \Omega_F</span>.

But <span class='inline'>A\cup B = (A\backslash B)\cup B</span>, so <span class='inline'>A\cup B \in \Omega_F</span> by lemma 8.16.  Finally, <span class='inline'>A\cap B = A\backslash (A\backslash B)</span>, so <span class='inline'>A\cap B\in \Omega_F</span> by the above calculation.


We are now nearly done, and can prove a slightly less technical result.

<br><br><strong>Theorem 8.19</strong>
The set <span class='inline'>\Omega</span> is a <span class='inline'>\sigma</span>-algebra containing all Borel sets.
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>K\subseteq X</span> be compact.  If <span class='inline'>A\in \Omega</span>, then <span class='inline'>X\backslash A \cap K = K \backslash (A\cap K)</span>, so <span class='inline'>X\backslash A \cap K\in \Omega_F</span>  by the above proposition, and <span class='inline'>X\backslash A\in \Omega</span>.

Suppose that
<span class='inline'></span>A = \bigcup_n=1^\infty A_n \qquad A_n \in \Omega<span class='inline'></span>

Let <span class='inline'>B_1 = A_1 \cap K</span>, and
<span class='inline'></span>B_n = (A_n \cap K) \backslash (B_1 \cup \cdots \cup B_n) \qquad n\geq 2<span class='inline'></span>

Then the collection <span class='inline'>\{ B_n |n=1,2,\ldots \}</span> is a pairwise disjoint, and <span class='inline'>B_n \in \Omega_F</span> for all <span class='inline'>n</span> by the above lemma.  But <span class='inline'>A\cap K =\bigcup_{n=1}^\infty B_n</span>, so <span class='inline'>A\cap K \in \Omega_F</span> by lemma 8.16.  It follows that <span class='inline'>A\in \Omega</span>.

We have proved that the collection <span class='inline'>\Omega</span> is a <span class='inline'>\sigma</span>-algebra.  If <span class='inline'>C\subseteq X</span> is a closed subset, then the intersection <span class='inline'>K\cap C</span> is compact.  Thus <span class='inline'>C\cap K \in \Omega_F</span>, and so <span class='inline'>C\in \Omega</span>.  Thus every closed set belongs to the collection <span class='inline'>\Omega</span>.  It follows that the <span class='inline'>\sigma</span>-algebra <span class='inline'>\Omega</span> contains all Borel sets.


<br><br><strong>Lemma 8.20</strong> 
<span class='inline'></span>\Omega_F = \ E\in \Omega |\mu (E) < \infty \<span class='inline'></span>
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>E\in \Omega_F</span>.  Then by lemmas 8.14 and 8.16, we see <span class='inline'>E\cap K \in \Omega_F</span> whenever <span class='inline'>K\subseteq X</span> is compact.  Then <span class='inline'>E\in \Omega</span>.  By definition of the set <span class='inline'>\Omega_F</span>, <span class='inline'>\mu (E) < \infty</span>.

Conversely, suppose that <span class='inline'>E\in \Omega</span> and <span class='inline'>\mu (E) < \infty</span>.  Let <span class='inline'>\varepsilon  > 0</span>.  We can certainly find an open set <span class='inline'>U\supseteq E</span> such that <span class='inline'>\mu (E) < \infty</span>.  By propositions 8.10 and 8.17, there is a compact set <span class='inline'>K\subseteq U</span> such that <span class='inline'>\mu (U\backslash K) < \varepsilon</span>.

We know that <span class='inline'>E\cap K\in \Omega_F</span>.  There is therefore a compact set <span class='inline'>H\subseteq E\cap K</span> such that
<span class='inline'></span>\mu (E\cap K)  <  \mu (H) +\varepsilon<span class='inline'></span>

But <span class='inline'>E\subseteq (E\cap K) \cup (U\backslash K)</span>.  Therefore
<span class='inline'></span>\mu (E)\subseteq \mu (E\cap K) + \mu (V\backslash K)  <  \mu (H)+\varepsilon<span class='inline'></span>
and we see that <span class='inline'>E\in \Omega_F</span>.


We can now prove our main result.

<br><br><strong>Theorem 8.21</strong>
The function <span class='inline'>\mu</span> is a measure on the <span class='inline'>\sigma</span>-algebra <span class='inline'>\Omega</span>.  It is the unique measure with the property
<span class='inline'></span>\Lambda f = \int_X f(x)d\mu (x)<span class='inline'></span>
for all <span class='inline'>f\in C_c (X)</span>.
<br><br>

<br><i>Proof.</i>
It follows immediately that <span class='inline'>\mu</span> is a measure from lemmas 8.16 and 8.20.  Our next step is to prove the inequality
<span class='inline'></span>\Lambda f \leq \int_X f(x)d\mu (x)<span class='inline'></span>
for every real-valued compactly supported function <span class='inline'>f</span>.  To do this, let <span class='inline'>K = \operatorname{supp} (f)</span>, and choose <span class='inline'>a,b\in {\mathbb R}</span> such that <span class='inline'>f[K]\subseteq [a,b]</span>.  Let <span class='inline'>\varepsilon  > 0</span>, and choose <span class='inline'>y_0 ,\ldots ,y_N</span> such that
<span class='inline'></span>a=y_0  <  \cdots  <  y_N \qquad y_n - y_n-1  < \varepsilon \textrm for all n<span class='inline'></span>

We can form Borel sets
<span class='inline'></span>E_n := \ x\in X | y_n-1  <  f(x) \leq y_n \<span class='inline'></span>

The sets <span class='inline'>E_n</span> are pairwise disjoint with union <span class='inline'>K</span>.  We can find open sets <span class='inline'>U_n \supseteq E_n</span> such that
<span class='inline'></span>\mu (U_k )  <  \mu (E_k ) + \frac\varepsilonn \qquad f(x)  <  y_n + \varepsilon<span class='inline'></span>
whenever <span class='inline'>x\in U_n</span>.

By theorem 8.4, we can choose a partition of unity <span class='inline'>\{ u_1 , \ldots , u_N \}</span> subordinate to the open cover <span class='inline'>\{ U_1 ,\ldots , U_N \}</span>.  It follows that
<span class='inline'></span>f = \sum_n=1^N u_n f<span class='inline'></span>
and by lemma 8.14
<span class='inline'></span>\mu (K) \leq \Lambda \left( \sum_n=1^N u_n \right) = \sum_n=1^N \Lambda (u_n)<span class='inline'></span>

But by construction <span class='inline'>u_nf \leq (y+n + \varepsilon )u_n</span>, and <span class='inline'>y_n - \varepsilon <  f(x)</span> for all <span class='inline'>x\in E_n</span>, so
<span class='inline'></span>\Lambda f \leq \sum_n=1^N (y_k + \varepsilon) \Lambda (u_n) = \sum_n=1^N (|a|+ y_k + \varepsilon) \Lambda (u_n) - |a| \sum_n=1^N \Lambda (u_n)<span class='inline'></span>
and
<span class='inline'></span>\Lambda f \leq \sum_n=1^N (|a|+ y_k + \varepsilon) (\mu (E_n) + \varepsilon /n ) - |a| \mu (K)<span class='inline'></span>

Multiplying out, we see that
<span class='inline'></span>\Lambda f \leq \sum_n=1^N (y_n - \varepsilon )\mu (E_n) + 2\varepsilon \mu (K) \frac\varepsilonn \sum_n=1^N (|a| + y_n + \varepsilon )<span class='inline'></span>
so by construction of the integral
<span class='inline'></span>\Lambda f \leq \int_X fd\mu + \varepsilon (2\mu (K) + |a| +b +\varepsilon )<span class='inline'></span>

Since the above inequality must hold for every choice of <span class='inline'>\varepsilon  > 0</span>, we see that
<span class='inline'></span>\Lambda f \leq \int_X f(x)d\mu (x)<span class='inline'></span>
as required.

Now, if we replace the function <span class='inline'>f</span> by the function <span class='inline'>-f</span>, we see that
<span class='inline'></span>-\Lambda f \leq -\int_X f(x)d\mu (x)<span class='inline'></span>

Combining the above two inequalities, we have the equation
<span class='inline'></span>\Lambda f = \int_X f(x)d\mu (x)<span class='inline'></span>
for every real-valued compactly supported function <span class='inline'>f</span>.  The proof of the above equation for complex-valued functions follows by splitting such a function into real and imaginary parts, and using linearity.

All that remains is to show uniqueness.  Let <span class='inline'>\mu'</span> be a measure such that the eqation
<span class='inline'></span>\Lambda f = \int_X f(x)d\mu' (x)<span class='inline'></span>
holds for every compactly supported function <span class='inline'>f</span>.  Let <span class='inline'>K</span> be a compact set.  By theorem 8.4, given an open set <span class='inline'>U\supseteq K</span>, there is a compactly supported function <span class='inline'>g</span> such that <span class='inline'>\chi_K \leq g\leq \chi_U</span>.  Hence
<span class='inline'></span>\mu' (K) \leq \int_X f d\mu' \leq \mu' (U)<span class='inline'></span>
and
<span class='inline'></span>\mu'(U) = \sup \ \Lambda f |f\leq \chi_U \ = \mu (U)<span class='inline'></span>

It follows that <span class='inline'>\mu (B)= \mu' (B)</span> whenever <span class='inline'>B</span> is a Borel set, and we are done.




</p><h1>9 Integration of Continuous Functions</h1><p>

We would like to use the Riesz representation theorem to define a measure on the real line <span class='inline'>\mathbb R</span> that gives the usual integral expected from elementary calculus.  To apply the Reisz representation theorem, we need a sensible definition of the integral of a continuous compactly supported function.

Let us consider a continuous function <span class='inline'>f\colon [a,b]\rightarrow {\mathbb R}</span>.  Let <span class='inline'>n</span> be a positive integer.  Then the interval <span class='inline'>[a,b]</span> can be divided into <span class='inline'>S^n</span> equal-sized pieces:
<span class='inline'></span>a <  a+ 2^-n(b-a)  <  a+ 2(2^-n)(b-a)  <  \cdots  <  a+ (2^n -1)(2^-n)(b-a)  <  b<span class='inline'></span>

Let us define
<span class='inline'></span>\mu_n,r  = \inf \ f(x) |a+r2^-n(b-a) \leq f(x)  <  a+ (r+1)2^-n(b-a)<span class='inline'></span>
and
<span class='inline'></span>I_n (f) = \sum_r=0^2^n -1 2^-n(b-a) \mu_n,r<span class='inline'></span>

The following observations are clear.

\beginitemize

\item The sequence <span class='inline'>(I_n (f))</span> is monotonically increasing

\item Since the interval <span class='inline'>[a,b]</span> is compact, and the function <span class='inline'>f</span> is continuous, there is a constant <span class='inline'>C</span> such that <span class='inline'>f(x)\leq C</span> for all <span class='inline'>x\in [a,b]</span>.  Hence <span class='inline'>I_n (f) \leq C(b-a)</span> for all <span class='inline'>n</span>.

\enditemize

It follows that we have a well-defined limit
<span class='inline'></span>\Lambda (f) := \lim_n\rightarrow \infty I_n (f)<span class='inline'></span>

We would like to extend the definition of the function <span class='inline'>\Lambda</span>.  There are two stages to this extension.

\beginitemize

\item Let <span class='inline'>f\colon [a,b]\rightarrow {\mathbb C}</span> be a continuous function.  Write <span class='inline'>f(x) = u(x) + iv(x)</span>, where <span class='inline'>u,v\colon [a,b]\rightarrow {\mathbb R}</span>, and define
<span class='inline'></span>\Lambda (f) = \Lambda (u) + i \Lambda (v)<span class='inline'></span>

\item Let <span class='inline'>f\in C_c ({\mathbb R})</span>.  Let <span class='inline'>[a,b]\supseteq \operatorname{supp} (f)</span>.  Then we define 
<span class='inline'></span>\Lambda (f) = \Lambda (f|_[a,b])<span class='inline'></span>

\enditemize

The following result is straightforward to check.

<br><br><strong>Proposition 9.1</strong>
The map <span class='inline'>\Lambda</span> is a positive linear functional on the space <span class='inline'>C_c ({\mathbb R})</span>.
<strong>proof to be filled in!</strong>
<br><br>

<br><br><strong>Definition 9.2</strong>
Let <span class='inline'>f\in C_c ({\mathbb R})</span>.  Then the number <span class='inline'>\Lambda (f)</span> is called the \em Riemann integral of <span class='inline'>f</span>.
<br><br>

</p><h1>10 The Lebesgue Measure on <span class='inline'>\mathbb R</span></h1><p>

<br><br><strong>Definition 10.1</strong>
Let <span class='inline'>\Lambda \colon C_c ({\mathbb R})\rightarrow {\mathbb C}</span> be the Riemann integral.  Then the \em Lebesgue measure on <span class='inline'>\mathbb R</span> is the unique measure such that
<span class='inline'></span>\int_\mathbb R fd\mu = \Lambda (f)<span class='inline'></span>
whenever <span class='inline'>f\in C_c ({\mathbb R})</span>.
<br><br>

By the Riesz representation, the Lebesgue measure exists and is unique on the collection of all Borel sets.  The integral of a Borel measurable function with respect to the Lebesgue measure is termed the \em Lebesgue integral.  We will normally write
<span class='inline'></span>\int_a^b fd\mu := \int_\mathbb R f\chi_(a,b)d\mu<span class='inline'></span>

<br><br><strong>Proposition 10.2</strong>
Let <span class='inline'>a < b</span> be real numbers.  Then <span class='inline'>\mu (a,b) = b-a</span>.
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>[c,d]\subseteq (a,b)</span> be a compact interval.  By Urysohn's lemma, there is a function <span class='inline'>f\in C_c ({\mathbb R})</span> such that <span class='inline'>\chi_{[c,d]} \leq f \leq \chi_{(a,b)}</span>.

By definition of the Riemann integral:
<span class='inline'></span>d-c \leq \int_\mathbb R f \leq b-a<span class='inline'></span>

Let <span class='inline'>c\rightarrow a</span> and <span class='inline'>d\rightarrow b</span>.  Then <span class='inline'>f\rightarrow \chi_{(a,b)}</span> and by the dominated convergence theroem, 
<span class='inline'></span>\int_\mathbb R f \rightarrow \mu (a,b)<span class='inline'></span>

It follows that <span class='inline'>\mu (a,b) = b-a</span>, and we are done.


A similar computation tells us that
<span class='inline'></span>\mu [a,b] = \mu [a,b) = \mu (a,b] = b-a<span class='inline'></span>
whenever <span class='inline'>a < b</span>.

The next fundamental property of the Lebesgue measure follows from a topological property of the real line, which we will state without proof.

<br><br><strong>Proposition 10.3</strong>
Every open subset of the real line <span class='inline'>\mathbb R</span> is a countable disjoint union of open intervals.
<strong>proof to be filled in!</strong>
<br><br>

<br><br><strong>Corollary 10.4</strong> 
Let <span class='inline'>E\subseteq {\mathbb R}</span> be a Borel set.  Then <span class='inline'>\mu (X+E) = \mu (E)</span> whenever <span class='inline'>x\in {\mathbb R}</span>.
<strong>proof to be filled in!</strong>
<br><br>

We conclude with a general characterisation of sets of measure zero, or \em null sets.

<br><br><strong>Theorem 10.5</strong>
Let <span class='inline'>E\subseteq {\mathbb R}</span> be a set such that every subset of <span class='inline'>A</span> is measurable.  Then <span class='inline'>\mu (A) =0</span>.
<br><br>

<br><i>Proof.</i>
The set <span class='inline'>\mathbb R</span> is an Abelian group under the operation of addition, and the set <span class='inline'>\mathbb Q</span> is a subgroup.  Let <span class='inline'>E</span> be a set of real numbers containing precisely one element of each coset <span class='inline'>x+ {\mathbb Q} \in {\mathbb R}/{\mathbb Q}</span>.

We claim:

\beginitemize

\item <span class='inline'>(r+E)\cap (s+E) = \emptyset</span> whenever <span class='inline'>r,s\in {\mathbb Q}</span>, <span class='inline'>r\neq s</span>.

\item Let <span class='inline'>x\in {\mathbb R}</span>.  Then we can find an element <span class='inline'>r\in {\mathbb Q}</span> such that <span class='inline'>x\in r+E</span>.

\enditemize

To see the first claim, suppose that <span class='inline'>x\in (r+E)\cap (s+E)</span>, where <span class='inline'>r,s\in {\mathbb Q}</span>.  Then there are elements <span class='inline'>y,z\in E</span> such that <span class='inline'>r+y = s+z</span>, and so <span class='inline'>y-z\in {\mathbb Q}</span>.  But the definition of the set <span class='inline'>E</span> means that <span class='inline'>r=s</span>.

As for the second claim, let <span class='inline'>x\in {\mathbb R}</span>.  Construction of the set <span class='inline'>E</span> means that we can find a point <span class='inline'>y\in E</span> such that <span class='inline'>x-y \in {\mathbb Q}</span>.  But <span class='inline'>x = y + (x-y)</span> so the claim is established.

We now use the above to claims to prove the theorem.  Let <span class='inline'>t\in {\mathbb Q}</span>, and define <span class='inline'>A_t := A\cap (t+E)</span>.  The set <span class='inline'>A_t</span> is measurable since it is a subset of the set <span class='inline'>A</span>.  Consider a compact subset <span class='inline'>K\subseteq A_t</span>, and let
<span class='inline'></span>H = \bigcup_r\in \mathbb Q\cap [0,1] (r+K)<span class='inline'></span>

Then the set <span class='inline'>H</span> is bounded and measurable, so <span class='inline'>\mu (H) < \infty</span>.  The first of the above claims tells us that the sets <span class='inline'>r+K</span> are pair-wise disjoint, so
<span class='inline'></span>\mu (H) = \sum_r\in \mathbb Q\cap [0,1] \mu (r+K) = \sum_r\in \mathbb Q\cap [0,1] \mu (K)<span class='inline'></span>
by corollary 10.4.  It follows that <span class='inline'>\mu (K)=0</span> whenever <span class='inline'>K\subseteq A_t</span> is compact.

So <span class='inline'>\mu (A_t) =0</span>.  But
<span class='inline'></span>A = \bigcup_t\in \mathbb Q A_t<span class='inline'></span>
and it follows that <span class='inline'>\mu (A)=0</span>.


<br><br><strong>Corollary 10.6</strong>
Any countable subset of the space <span class='inline'>{\mathbb R}</span> has measure zero.
<strong>proof to be filled in!</strong>
<br><br>

<br><br><strong>Corollary 10.7</strong>
There are non-measurable subsets of the space <span class='inline'>\mathbb R</span>.
<strong>proof to be filled in!</strong>
<br><br>

</p><h1>11 The Fundamental Theorem of Calculus</h1><p>

By convention, when <span class='inline'>a < b</span> are real numbers, and <span class='inline'>\mu</span> is the Lebesgue measure on the space <span class='inline'>\mathbb R</span>, we simplfy our notation slightly and write just
<span class='inline'></span>\int_a^b f(x)dx := \int_a^b fd\mu<span class='inline'></span>

If <span class='inline'>b < a</span>, we write
<span class='inline'></span>\int_a^b f(x)dx := - \int_b^a f(x)dx<span class='inline'></span>

Linearity of the integral gives us the equation
<span class='inline'></span>\int_a^b f(x)dx = \int_a^c f(x)dx + \int_c^b f(x)dx<span class='inline'></span>
whenever <span class='inline'>a,b,c\in {\mathbb R}</span>.

This new notation is convenient when integating a concrete function given by some definite formula.

In this section we will focus on one major result, which is of absolutely vital importance when trying to calculate integrals.  This result is termed the em fundamental theorem of calculus.

<br><br><strong>Theorem 11.1</strong>
Let <span class='inline'>f\colon [a,b] \rightarrow {\mathbb C}</span> be a continuous function.  Define a function <span class='inline'>F\colon [a,b]\rightarrow {\mathbb C}</span> by the formula
<span class='inline'></span>F(x) = \int_a^x f(y)dy<span class='inline'></span>

Then the function <span class='inline'>F</span> is differentiable on the open interval <span class='inline'>(a,b)</span>, and has a one-sided derivative at the end-points <span class='inline'>a</span> and <span class='inline'>b</span>.  In all cases, the derivative is given by the formula
<span class='inline'></span>F'(x) = f(x)<span class='inline'></span>
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>\varepsilon  > 0</span>, and let <span class='inline'>x\in [a,b]</span>.  Since the function <span class='inline'>f</span> is continuous, we can choose <span class='inline'>\delta  > 0</span> such that <span class='inline'>|f(x+h) -f(x)|  < \varepsilon</span> whenever <span class='inline'>|h| < \delta</span> and <span class='inline'>x+h\in [a,b]</span>.  

Let <span class='inline'>x\in [a,b]</span>, and <span class='inline'>x+h\in [a,b]</span>.  Observe:
<span class='inline'></span>F(x+h)- F(x)= \int_x^h+h f(y)dy<span class='inline'></span>
and
<span class='inline'></span>hf(x) = f(x)\mu (x,x+h) = \int_x^x+h f(x)dy<span class='inline'></span>

Suppose that <span class='inline'>|h| < \delta</span>.  Then <span class='inline'>|f(y)-f(x)|  <  \varepsilon</span> whenever <span class='inline'>y\in [x,x+h]</span>, and so:
<span class='inline'></span>\left| \int_x^x+h f(y)-f(x)dy \right| \leq \int_x^x+h |f(y) -f(x)|dy \leq \varepsilon |h|<span class='inline'></span>

Thus:
<span class='inline'></span>|F(x+h) -F(x) - hf(x)| \leq \varepsilon |h|<span class='inline'></span>
whenver <span class='inline'>|h| < \delta</span>.  It follows that the function <span class='inline'>F</span> is differentiable, and <span class='inline'>F'(x) =f(x)</span> as claimed.


In actual fact, the more useful form of the fundmantal theorem of calculus is a variation of the above formula.

<br><br><strong>Corollary 11.2</strong>
Let <span class='inline'>F\colon [a,b]\rightarrow {\mathbb C}</span> be a function with a continuous derivative <span class='inline'>f</span>.  Then
<span class='inline'></span>\int_a^b f(x)dx = F(b)-F(a)<span class='inline'></span>
<br><br>

<br><i>Proof.</i>
Define
<span class='inline'></span>F_0 (x) = \int_a^x f(y)dy<span class='inline'></span>

Then by the above version of the fundamental theorem of calculus, <span class='inline'>F_0'(x) = f(x)</span> whenever <span class='inline'>x\in [a,b]</span>.  Hence <span class='inline'>F_0'(x) = F'(x)</span> whenever <span class='inline'>x\in [a,b]</span>, so there is a constant <span class='inline'>C</span> such that <span class='inline'>F_0(x) = F(x) +C</span> for all <span class='inline'>x\in [a,b]</span>.

We know that <span class='inline'>F_0 (a)=0</span>.  Therefore <span class='inline'>C=-F(a)</span>.  We see that
<span class='inline'></span>int_a^b f(x)dx = F_0 (b) = F(b) - F(a)<span class='inline'></span> 
as claimed.


The various integration formulae, such as integration by parts and the change of variable formula, come from the fundamental theorem of calculus along with the corresponding formulae for differentives, such as the derivative of a product and the derivative of a composition.

</p><h1>12 Product Measures</h1><p>

Let <span class='inline'>\Omega_1</span> and <span class='inline'>\Omega_2</span> be measure spaces, with measures <span class='inline'>\mu_1</span> and <span class='inline'>\mu_2</span> on <span class='inline'>\sigma</span>-algebras <span class='inline'>{\mathcal M}_1</span> and <span class='inline'>{\mathcal M}_2</span> respectively.

<br><br><strong>Definition 12.1</strong>
We call a subset of the form <span class='inline'>A\times B\subseteq X\times Y</span>, where <span class='inline'>A\in {\mathcal M}_1</span> and <span class='inline'>B\in {\mathcal M}_2</span> a \em measurable rectangle.  A finite union of measurable rectangles is called an \em elementary set.

We write <span class='inline'>{\mathcal M}_{12}</span> to denote the smallest <span class='inline'>\sigma</span>-algebra in the set <span class='inline'>\Omega_1\times \Omega_2</span> that contains every measurable rectangle.
<br><br>

We want to define a measure on the <span class='inline'>\sigma</span>-algebra <span class='inline'>{\mathcal M}_{12}</span>.  Before we can do this, we need some technical constructions.

<br><br><strong>Definition 12.2</strong>
Let <span class='inline'>\mathcal C</span> be a collection of subsets of some set.  Suppose that the following two conditions hold:

\beginitemize

\item Let <span class='inline'>(A_n)</span> be a sequence of sets in the collection <span class='inline'>\mathcal C</span> such that <span class='inline'>A_n\subseteq A_{n+1}</span> for all <span class='inline'>n</span>.  Then <span class='inline'>\bigcup_{n=1}^\infty A_n \in {\mathcal C}</span>.

\item Let <span class='inline'>(B_n)</span> be a sequence of sets in the collection <span class='inline'>\mathcal C</span> such that <span class='inline'>B_n\supseteq B_{n+1}</span> for all <span class='inline'>n</span>.  Then <span class='inline'>\bigcup_{n=1}^\infty B_n \in {\mathcal C}</span>.

\enditemize

Then we call the collection <span class='inline'>\mathcal C</span> a \em monotone class.
<br><br>

The proof of the following lemma is elementary, but rather abstract.  We omit it.

<br><br><strong>Lemma 12.3</strong> 
The <span class='inline'>\sigma</span>-algebra <span class='inline'>{\mathcal M}_{12}</span> is the smallest monotone class in the product <span class='inline'>\Omega_1 \times \Omega_2</span> which contains all elementary sets.
<strong>proof to be filled in!</strong>
<br><br>

Given a subset <span class='inline'>E\subseteq \Omega_1 \times \Omega_2</span>, and points <span class='inline'>x\in Omega_1</span> and <span class='inline'>y\in \Omega_2</span>, let us write
<span class='inline'></span>E_x = \ y\in \Omega_2 |(x,y)\in E \ \qquad E^y = \ x\in \Omega_1 |(x,y)\in E \<span class='inline'></span>

<br><br><strong>Proposition 12.4</strong>
Let <span class='inline'>E\in {\mathcal M}_{12}</span>.  Then <span class='inline'>E_xin {\mathcal M}_1</span> and <span class='inline'>E^y\in {\mathcal M}_2</span> whenever <span class='inline'>x\in \Omega_1</span> and <span class='inline'>y\in \Omega_2</span>.
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>x\in \Omega_1</span>.  Let <span class='inline'>\mathcal M</span> be the collection of all elements <span class='inline'>E\in \Omega_1 \times \Omega_2</span> such that <span class='inline'>E_x\in \Omega_2</span>.  It is straightforward to check that <span class='inline'>\mathcal M</span> is a <span class='inline'>\sigma</span>-algebra that contains every measurable rectangle.  Therefore <span class='inline'>{\mathcal M}_{12}\subseteq {\mathcal M}</span>, and we see that <span class='inline'>E_x\in {\mathcal M}_2</span> for every measurable set <span class='inline'>E\subseteq \Omega_1\times \Omega_2</span> and point <span class='inline'>x\in \Omega_2</span>.

The corresponding statement concerning sets of the form <span class='inline'>E^y</span> is proved in the same way.


<br><br><strong>Corollary 12.5</strong> 
Let <span class='inline'>X</span> be a topological space, and let <span class='inline'>f\colon \Omega_1 \times \Omega_2 \rightarrow X</span> be a measurable function.  Choose points <span class='inline'>x\in \Omega_1</span> and <span class='inline'>y\in \Omega_2</span>.  Then the functions
<span class='inline'></span>f(x,-) \colon \Omega_2 \rightarrow X \qquad f(-,y) \colon \Omega_1 \rightarrow X<span class='inline'></span>
are measurable.
<strong>proof to be filled in!</strong>
<br><br>

<br><br><strong>Definition 12.6</strong>
A measure space <span class='inline'>\Omega</span> is called \em <span class='inline'>\sigma</span>-finite if it is a countable union of spaces of finite measure.
<br><br>

<br><br><strong>Example 12.7</strong>
The space <span class='inline'>\mathbb R</span>, equipped with the standard Lebesgue measure, is <span class='inline'>\sigma</span>-finite.
<br><br>

The following result lets us define measures on products of <span class='inline'>\sigma</span>-finite measure spaces.

<br><br><strong>Theorem 12.8</strong> 
Let <span class='inline'>\Omega_1</span> and <span class='inline'>\Omega_2</span> be <span class='inline'>\sigma</span>-finite measure spaces.  Let <span class='inline'>E\subseteq \Omega_1\times \Omega_2</span> be a measurable subset.  Then we can define measurable functions <span class='inline'>f\colon \Omega_1\rightarrow [0,\infty]</span> and <span class='inline'>g\colon \Omega_1\rightarrow [0,\infty]</span> by the formulae
<span class='inline'></span>f_E(x) = \mu_2 (E_x) \qquad g_E(y) = \mu_1 (E^y)<span class='inline'></span>
respectively.  Further,
<span class='inline'></span>\int_\Omega_1 f_E = \int_\Omega_2 g_E<span class='inline'></span>
<br><br>

<br><i>Proof.</i>
Measurability of the functions <span class='inline'>f_E</span> and <span class='inline'>g_E</span> associated as above to a measurable set <span class='inline'>E\subseteq X\times Y</span> follows from the above proposition and corollary; all that remains it to prove the main equation.

Let <span class='inline'>{\mathcal M}</span> be the set of all measurable subsets <span class='inline'>E\subseteq \Omega_1 \times \Omega_2</span> such that the equation
<span class='inline'></span>\int_\Omega_1 f_E = \int_\Omega_2 g_E<span class='inline'></span>
holds.

Let <span class='inline'>E=A\times B</span> be a measurable rectangle.  Then <span class='inline'>f_E = \mu_2 (B)\chi_A</span> and <span class='inline'>g_E = \mu_1 (A)\chi_B</span>.  It follows that
<span class='inline'></span>\int_\Omega_1 f_E = \int_A \mu_2 (B) = \mu_1 (A) \mu_2 (B) \qquad \int_\Omega_1 g_E = \int_B \mu_1 (A) = \mu_1 (A) \mu_2 (B)<span class='inline'></span>
so <span class='inline'>E\in {\mathcal M}</span>.

Let <span class='inline'>(E_n)</span> be a sequence of sets in the collection <span class='inline'>\mathcal M</span> such that <span class='inline'>E_n\subseteq E_{n+1}</span> for all <span class='inline'>n</span>.  Write
<span class='inline'></span>E= \bigcup_n=1^\infty E_n<span class='inline'></span>

Then the sequences of functions <span class='inline'>(f_{E_n})</span> and <span class='inline'>(g_{E_n})</span> are monotonic increasing, with limits <span class='inline'>f_E</span> and <span class='inline'>g_E</span> respectively.  We know that <span class='inline'>E_n \in {\mathcal M}</span> for all <span class='inline'>n</span>, so that the equation
<span class='inline'></span>\int_\Omega_1 f_E_n = \int_\Omega_2 g_E_n<span class='inline'></span>
holds for all <span class='inline'>n</span>.  The monotone convergence theorem gives us the equation
<span class='inline'></span>\int_\Omega_1 f_E = \int_\Omega_2 g_E<span class='inline'></span>
and so tells us that <span class='inline'>E\in {\mathcal M}</span>.

As a consequence of the above calculation, we can easily show that the union of a discrete sequence of measurable sets in the set <span class='inline'>\mathcal M</span> also belongs to the set <span class='inline'>\mathcal M</span>.  Let <span class='inline'>(E_n)</span> be a sequence of sets in the collection <span class='inline'>\mathcal M</span> such that <span class='inline'>E_1\subseteq A\times B</span>, where <span class='inline'>\mu_1 (A) < \infty</span>, <span class='inline'>\mu_2 (B) < \infty</span>, and <span class='inline'>E_n\supseteq E_{n+1}</span> for all <span class='inline'>n</span>.  Write
<span class='inline'></span>E= \bigcup_n=1^\infty E_n<span class='inline'></span>

Then an argument similar to the above one, only using the dominated convergence theorem rather than the monotone convergence theorem, tells us that the set <span class='inline'>E</span> belongs to the collection <span class='inline'>\mathcal M</span>.

Now, let <span class='inline'>\Omega_1 = \cup_{n=1}^\infty \Omega_1^{(n)}</span> and <span class='inline'>\Omega_2 = \cup_{n=1}^\infty \Omega_2^{(n)}</span>, where <span class='inline'>\mu_1 (\Omega_1^{(m)})  < \infty</span> and <span class='inline'>\mu_2 (\Omega_2^{(n)})  < \infty</span> for all <span class='inline'>m,n\in {\mathbb N}</span>.  Given a set <span class='inline'>E\subseteq \Omega_1\times \Omega_2</span>, let us write
<span class='inline'></span>E_mn = E \cap (\Omega_1^(m) \times \Omega_2^(n)<span class='inline'></span>

Let <span class='inline'>{\mathcal C}</span> be the collection of all measurable sets <span class='inline'>E\subseteq \Omega_1 \times \Omega_2</span> such that <span class='inline'>E_{mn}\in {\mathcal M}</span> for all natural numbers <span class='inline'>m</span> and <span class='inline'>n</span>.  Then the above calculations tell us that the collection <span class='inline'>\mathcal C</span> is a monotone class that contains every elementary rectangle.  It follows from lemma 12.3 <span class='inline'>{\mathcal M}_{12}\subseteq {\mathcal C}</span>, and we are done.


To paraphrase the above theorem, the equation
<span class='inline'></span>\int_\Omega_1 \left( \int_\Omega_2  \chi_E (x,y) d\mu_2 (y) \right) d\mu_1 (x)= \int_\Omega_2 \left( \int_\Omega_1 \chi_E (x,y) d\mu_1 (x) \right) d\mu_2 (y)<span class='inline'></span> 
holds for every measurable set <span class='inline'>E\subseteq \Omega_1 \times \Omega_2</span>.

<br><br><strong>Definition 12.9</strong>
Let <span class='inline'>\Omega_1</span> and <span class='inline'>\Omega_2</span> be <span class='inline'>\sigma</span>-finite measure sets.  Then we define a measure <span class='inline'>\mu</span> on the product <span class='inline'>\Omega_1 \times \Omega_2</span> by writing
<span class='inline'></span>\mu (E) := \int_\Omega_1 \left( \int_\Omega_2  \chi_E (x,y) d\mu_2 (y) \right) d\mu_1 (x)= \int_\Omega_2 \left( \int_\Omega_1 \chi_E (x,y) d\mu_1 (x) \right) d\mu_2 (y)<span class='inline'></span> 
whenever the set <span class='inline'>E\subseteq \Omega_1 \times \Omega_2</span> is measurable.
<br><br>

It is easy to check that the above definition satisfies the axioms required of a measure.  As a special case of the above definition, we can now define a Lebesgue measure on the space <span class='inline'>{\mathbb R}^n</span> by viewing it as a product of copies of the space <span class='inline'>\mathbb R</span>.  This measure is defined on every Borel set, and the measure of the <span class='inline'>n</span>-dimensional cuboid
<span class='inline'></span>[a_1 , b_1] \times \cdots \times [a_n , b_n]<span class='inline'></span>
is the product
<span class='inline'></span>(b_1 - a_1)(b_2-a_2) \cdots (b_n-a_n)<span class='inline'></span>
 
</p><h1>13 Fubini's Theorem</h1><p>

In the previous section, we saw how to define measures on products of <span class='inline'>\sigma</span>-finite measure spaces.  We can therefore integrate on such spaces.  The purpose of this section is two state two results on the integrability of such functions, and how they are integrated.   These results are usually put together, and referred to in one piece as \em Fubini's theorem.

<br><br><strong>Theorem 13.1</strong>
Let <span class='inline'>\Omega_1</span> and <span class='inline'>\Omega_2</span> be <span class='inline'>\sigma</span>-finite measure spaces, and let <span class='inline'>f\colon \Omega_1 \times \Omega_2 \rightarrow {\mathbb C}</span> be an integrable function.  Then the functions <span class='inline'>f(x,-)</span> and <span class='inline'>f(-,y)</span> are integrable almost everywhere, and the functions
<span class='inline'></span>x\mapsto \int_\Omega_2 f(x,y) d\mu_2 (y) \qquad y\mapsto \int_\Omega_2 f(x,y) d\mu_2 (y)<span class='inline'></span>
are integrable.  Moreover,
<span class='inline'></span>\int_\Omega_1 \times \Omega_2 f(x,y) d\mu (x,y)
=\int_\Omega_1 \left( \int_\Omega_2  f (x,y) d\mu_2 (y) \right) d\mu_1 (x)= \int_\Omega_2 \left( \int_\Omega_1 f (x,y) d\mu_1 (x) \right) d\mu_2 (y)<span class='inline'></span> 
<br><br>

<br><i>Proof.</i>
Let <span class='inline'>s\colon \Omega_1 \times \Omega_2 \rightarrow {\mathbb C}</span> be a simple function.  Then the functions <span class='inline'>s(x,-)</span> and <span class='inline'>s(-,y)</span> are integrable almost everywhere, the functions
<span class='inline'></span>x\mapsto \int_\Omega_2 s(x,y) d\mu_2 (y) \qquad y\mapsto \int_\Omega_2 s(x,y) d\mu_2 (y)<span class='inline'></span>
are integrable, and the equation
<span class='inline'></span>\int_\Omega_1 \times \Omega_2 s(x,y) d\mu (x,y)
=\int_\Omega_1 \left( \int_\Omega_2  s (x,y) d\mu_2 (y) \right) d\mu_1 (x)= \int_\Omega_2 \left( \int_\Omega_1 s (x,y) d\mu_1 (x) \right) d\mu_2 (y)<span class='inline'></span> 
holds by theorem 12.8 and the definition of the product measure.

Now, suppose that <span class='inline'>f(x,y)\geq 0</span> for all points <span class='inline'>(x,y)\in \Omega_1 \times \Omega_2</span>.  Since the function <span class='inline'>f</span> is measurable, by proposition 4.2 there is a monotonically increasing sequence, <span class='inline'>(s_n)</span>, of simple functions, with point-wise limit <span class='inline'>f</span>.  The result therefore follows in this case by the monotone convergence theorem.

By splitting a real-valued function into positive and negative parts, we see that the result holds for all real-valued functions.  We can deduce the result for complex-valued functions by splitting such a function into real and imaginary parts.


For the above theorem to be useful, we would like a criterion for a function <span class='inline'>f\colon \Omega_1 \times \Omega_2 \rightarrow {\mathbb C}</span> to be integrable.  Fortunately, such a condition forms the second half of Fubini's theorem, which is also sometimes referred to as Tonelli's theorem.

<br><br><strong>Theorem 13.2</strong>
Let <span class='inline'>\Omega_1</span> and <span class='inline'>\Omega_2</span> be <span class='inline'>\sigma</span>-finite measure spaces, and let <span class='inline'>f\colon \Omega_1 \times \Omega_2 \rightarrow {\mathbb C}</span> be an integrable function.  Suppose that
<span class='inline'></span>\int_\Omega_1 \left( \int_\Omega_2  |f (x,y)| d\mu_2 (y) \right) d\mu_1 (x)  < \infty<span class='inline'></span>
or
<span class='inline'></span>\int_\Omega_2 \left( \int_\Omega_1 |f (x,y)| d\mu_1 (x) \right) d\mu_2 (y) <  \infty<span class='inline'></span> 
Then the function <span class='inline'>f\colon \Omega_1\times \Omega_2 \rightarrow {\mathbb C}</span> is integrable.
<br><br>

<br><i>Proof.</i>
The result is obvious if the function <span class='inline'>f</span> is simple.  A similar argument to the proof of Fubini's theorem gives us the result in general.


Combining the two theorems in this section (ie: the two halves of Fubini's theorem), we have the following handy result on swapping the order of integration.

<br><br><strong>Corollary 13.3</strong>
Let <span class='inline'>\Omega_1</span> and <span class='inline'>\Omega_2</span> be <span class='inline'>\sigma</span>-finite measure spaces, and let <span class='inline'>f\colon \Omega_1 \times \Omega_2 \rightarrow {\mathbb C}</span> be an integrable function.  Suppose that
<span class='inline'></span>\int_\Omega_1 \left( \int_\Omega_2  |f (x,y)| d\mu_2 (y) \right) d\mu_1 (x)  < \infty<span class='inline'></span>

Then
<span class='inline'></span>\int_\Omega_2 \left( \int_\Omega_1 f (x,y) d\mu_1 (x) \right) d\mu_2 (y) <  \infty = \int_\Omega_1 \left( \int_\Omega_2  f (x,y) d\mu_2 (y) \right) d\mu_1 (x)  < \infty<span class='inline'></span>
<strong>proof to be filled in!</strong>
<br><br>







\partFunctional Analysis
\chapterTopological Vector Spaces


</p><h1>14 Topological division rings and fields</h1><p>


<br><br><strong>14.1</strong> Vector spaces with a compatible topology can not only defined for vector spaces over the ground fields 
<span class='inline'>\mathbb{R}</span> and <span class='inline'>\mathbb{C}</span> but also over fields <span class='inline'>\mathbb{K}</span> carrying an absolute value
<span class='inline'>|\cdot | : \mathbb{K} \to \mathbb{R}_{\geq 0}</span>. This endows the ground field with a topology which will be needed in the
definition of a topological vector space. We therefore give here a brief introduction to topological division
rings and fields first.

<br><br><strong>Definition 14.2</strong>
  Let <span class='inline'>R</span> be a division ring. By an <i>absolute value</i> on <span class='inline'>R</span> one understands a map <span class='inline'> |\cdot | : R \to \mathbb{R}_{\geq 0}</span>
  such that the following axioms hold true.
  </p><ol class='enumeration'>
  <li value=' (VDR1)'> 
  
     The function <span class='inline'>| \cdot |</span> is multiplicative that is 
     <br><br><span class='display'> |xy| = |x|  \, | y| \quad \text{for all } x,y \in R . </span><br>
  </li><li value=' (VDR2)'> 
   
    The triangle inequality is satisfied which means that 
    <br><br><span class='display'> |x + y| \leq  |x| +  | y| \quad  \text{for all } x,y \in R . </span><br>
  </li><li value=' (VDR3)'>
   
  For all <span class='inline'>x \in R</span> the relation <span class='inline'>|x|=0</span> holds true if and only if <span class='inline'>x=0</span>. 
  </li></ol><p>
  A division ring or field endowed with an absolute value is called a <i>valued division ring</i> 
  respectively a <i>valued field</i>. 
  An absolute value <span class='inline'>|\cdot|</span> on a division ring <span class='inline'>R</span> and the corresponding valued
  division ring <span class='inline'>(R,|\cdot|)</span> are called <i>non-archimedean</i> if 
  the <i>strong triangle inequality</i> is satisfied that is if
  </p><ol class='enumeration'>
  \setcounterenumi3
  <li value=' (VDR1)'> 
    <span class='inline'> |x + y| \leq  \max \{ |x| , | y| \} </span> for all <span class='inline'>x,y \in R</span>.
  </li></ol><p>
  Otherwise <span class='inline'>|\cdot|</span> and <span class='inline'>(R,|\cdot|)</span> are called <i>archimedean</i>.
<br><br>


<br><br><strong>Lemma 14.3</strong>
  Let <span class='inline'>(R,|\cdot|)</span> be a valued division ring. Then
  
  </p><ol class='enumeration'>

  <li value='(I)'>
     <span class='inline'>|1|=1</span>,
   </li><li value='(II)'>
     <span class='inline'>|-x| =|x|</span> for all <span class='inline'>x\in R</span>, and
  </li><li value='(III)'>
     <span class='inline'>\big| |x| - |y| \big| \leq |x - y|   \leq  |x| + |y|</span> for all <span class='inline'>x,y\in R</span>.
  
  </li></ol><p>

<br><br>

<br><i>Proof.</i>
  (I) holds true since <span class='inline'>|1| = |1^2| = |1|^2</span> and <span class='inline'>|1| \neq 0</span> by <span class='inline'>1 \neq 0</span>.
  To verify (II) it suffices to show that <span class='inline'>|-1| =1</span>. But that holds true
  since <span class='inline'>|-1|^2 = | (-1)^2| = 1</span> and <span class='inline'>|-1| \geq 0</span>.
  The last claim follows by
  <br><br><span class='display'>
  - |x-y| = |x| - (|y-x| +|x|) \leq |x| - |y| \leq  |x-y| + |y | - |y| = |x-y| 
  </span><br>
  and
  <br><br><span class='display'>
    |x - y|  = | x + (-y)|  \leq  |x| + |-y| = |x| + |y| .
  </span><br>


<br><br><strong>Examples 14.4</strong>

  </p><ol class='enumeration'>

<li value='(a) '>
  Obviously, the <i>standard absolute values</i>
  <br><br><span class='display'> 
    |\cdot |_\infty : \mathbb{Q}, \mathbb{R}\to \mathbb{R}_{\geq 0}, \: x \mapsto
    \begin{cases}
      x & \text{if } x\geq 0\\
      -x & \text{if } x <  0
    \end{cases}
  \quad\text{and}\quad
    |\cdot |_\infty : \mathbb{C}\to \mathbb{R}_{\geq 0}, \: z \mapsto \sqrt{z \overline{z}}
  </span><br>
  are absolute values on the fields <span class='inline'>\mathbb{Q}</span>, <span class='inline'>\mathbb{R}</span> and <span class='inline'>\mathbb{C}</span>, respectively. These absolute values are all archimedean
  since <span class='inline'>|1+ 1|_\infty = 2  >  1</span>. Unless mentioned differently, we always assume 
  <span class='inline'>\mathbb{Q}</span>, <span class='inline'>\mathbb{R}</span> and <span class='inline'>\mathbb{C}</span> to be equipped with the standard absolute values. If no confusion can arise we usually
  write <span class='inline'>|\cdot|</span> instead of <span class='inline'>|\cdot |_\infty</span>.
</li><li value='(b) '>
  The <i>standard absolute value</i> on the quaternions
  <br><br><span class='display'>
     |\cdot |_\infty : \H \to \mathbb{R}_{\geq 0} , \: q = a + b \,\mathfrak{i} + c\,\mathfrak{j} + d \,\mathfrak{k} \mapsto \sqrt{\overline{q}q} = \sqrt{a^2 +b^2+ c^2 + d^2} , 
  </span><br>
  where <span class='inline'>a,b,c,d</span> are real, is an archimedean absolute value. Usually it is briefly denoted <span class='inline'>|\cdot|</span>.   
</li><li value='(c) '> 
  For every division ring <span class='inline'>R</span> the map 
  <br><br><span class='display'> |\cdot| :R \to \mathbb{R}, \: x \mapsto
    \begin{cases}
    0 & \text{if } x=0 ,\\
    1 & \text{else} 
  \end{cases}
  </span><br>
  is a non-archimedean absolute value. It is called the <i>trivial absolute value</i> on <span class='inline'>R</span>.
</li><li value='(d) '>
  An absolute value  <span class='inline'>|\cdot|:\mathbb{F} \to\mathbb{R}_{\geq 0}</span> defined on a finite field <span class='inline'>\mathbb{F}</span> has to be trivial.
  To see this observe that for each <span class='inline'>x\in \mathbb{K}^\times</span> there
  exists an <span class='inline'>n\in \mathbb{N}</span> such that <span class='inline'>x^n =1</span>. This entails  <span class='inline'>|x|^n=1</span>, hence <span class='inline'>|x|=1</span>
  for all <span class='inline'>x\in \mathbb{K}^\times</span>. So <span class='inline'>|\cdot|</span> is trivial.
</li><li value='(e) '> 
  The field of formal Laurent power series <span class='inline'>\mathbb{K} ((X))</span> over a field <span class='inline'>\mathbb{K}</span> can be equipped
  with an absolute value as follows. Choose <span class='inline'>0 < \varepsilon  <  1</span>
  and define the absolute value <span class='inline'>\left| \sum_{k\in \mathbb{Z}} a_k X^k\right| </span> of an element
  <span class='inline'>\sum_{n\in \mathbb{Z}} a_n X^n\in \mathbb{K} ((X)) </span> as <span class='inline'>\varepsilon^n</span>, where <span class='inline'>n</span> is the minimal integer such that <span class='inline'>a_n\neq 0</span>.  
</li><li value='(f) '>
  Let <span class='inline'>p</span> be prime number. For every integer <span class='inline'>m\neq 0</span> let <span class='inline'>\nu_p(m)</span> be the exponent of <span class='inline'>p</span> in the prime factor decomposition of <span class='inline'>m</span>
  that is <span class='inline'>m = p^{\nu_p(n)}n</span> where <span class='inline'>n</span> is relatively prime to <span class='inline'>p</span>.
  For <span class='inline'>m \in \mathbb{Z}</span> and <span class='inline'>n\in \mathbb{N}_{ >  0}</span> one defines the <i><span class='inline'>p</span>-adic absolute value</i> of the rational number <span class='inline'>x = \frac mn</span> by
  <br><br><span class='display'>
    \left| x \right|_p =
    \begin{cases}
      0 & \text{if } m=0 ,\\
      p^{-\nu_p(m) +\nu_p(n)} & \text{else}. 
    \end{cases}
  </span><br>
  Note that <span class='inline'> \left| x \right|_p</span> does not depend on the particular representation of <span class='inline'>x</span> as the quotient of integers <span class='inline'>m</span> and <span class='inline'>n</span>.
  By definition it is immediately clear that the <span class='inline'>p</span>-adic absolute value is an absolute value on <span class='inline'>\mathbb{Q}</span> indeed. 
  It is non-archimedean.

  </li></ol><p>

<br><br>

<br><br><strong>Proposition 14.5</strong>
  A valued division ring <span class='inline'>(R,|\cdot|)</span> is non-archimedean if and only if the image of <span class='inline'>\mathbb{Z}</span> under
  the canonical map  <span class='inline'>\mathbb{Z}\to R</span> is bounded. 
<br><br>

<br><i>Proof.</i>
  Assume that <span class='inline'>(R,|\cdot|)</span> is a non-archimedean valued division ring.
  Then, <span class='inline'>|0 \cdot 1| = |0|= 0 </span> and, under the assumption that <span class='inline'>|(n-1)\cdot 1|\leq 1</span> for some <span class='inline'>n\in \mathbb{N}_{ >  0}</span>,
  <span class='inline'>|n\cdot 1| = | (n-1)\cdot 1 + 1 | = \max \{ |(n-1)\cdot 1| , 1 \} = 1</span>.
  Hence by induction and since <span class='inline'>|-1| =1</span> one obtains that <span class='inline'>|n\cdot 1|\leq 1</span> for all <span class='inline'>n\in \mathbb{Z}</span>,
  and the image of <span class='inline'>\mathbb{Z}</span> in <span class='inline'>R</span> is bounded.

  To show the converse assume that the image of <span class='inline'>\mathbb{Z}</span> in <span class='inline'>R</span> is bounded by some constant <span class='inline'>C > 0</span>. Then, for all <span class='inline'>x,y\in R</span>
  and <span class='inline'>n\in \mathbb{N}_{ >  0}</span> by the binomial formula and the triangle inequality
  <br><br><span class='display'>
    |x+y|^n =\left|\sum_{k=0}^n {n \choose k} x^k y^{n-k} \right|
    \leq (n+1) \,C \max \{|x|,|y|\}^n .
  </span><br>
  Taking the <span class='inline'>n</span>-th root gives <span class='inline'>|x+y|\leq \big( (n+1)C\big)^{1/n} \max \{|x|,|y|\}</span> which after passing to the limit <span class='inline'>n\to\infty</span>
  entails  <span class='inline'>|x+y| \leq \max \{|x|,|y|\}</span> since <span class='inline'>\lim\limits_{n\to\infty} \big( (n+1)C\big)^{1/n} = 1</span>. Hence
  <span class='inline'>(R,|\cdot|)</span> is non-archimedean. 


<br><br><strong>Proposition 14.6</strong>
  Let <span class='inline'>|\cdot|</span> be an absolute value on the division ring <span class='inline'>R</span>. Then for every <span class='inline'>\tau > 0</span> with <span class='inline'>\tau\leq 1</span> the
  map <span class='inline'>|\cdot|^\tau: R\to\mathbb{R}_{\geq 0}</span> is an absolute value on <span class='inline'>R</span> as well.
  It is archimedean if and only if <span class='inline'>|\cdot|</span> is archimedean. 
<br><br>

<br><i>Proof.</i>
  To prove that <span class='inline'>|\cdot|^\tau</span> is an absolute value it suffices to show that <span class='inline'>(a+b)^\tau \leq a^\tau + b^\tau</span>
  for all <span class='inline'>a,b\geq 0</span>. Without loss of generality we may assume <span class='inline'>a \geq b > 0</span>. By dividing through <span class='inline'>b^\tau</span>
  one sees that the claim is equivalent to <span class='inline'>(t +1 )^\tau \leq t^\tau + 1</span> for all <span class='inline'>t\geq 1</span>.
  For <span class='inline'>t=1</span> this is certainly true. The derivative of the function
  <span class='inline'>h : {[ 1,\infty \rtsbrak}  \to\mathbb{R}</span>, <span class='inline'>t\mapsto (t +1 )^\tau - t^\tau</span> now is
  given by <span class='inline'>h'(t) = \tau \big( (t +1 )^{\tau-1} - t^{\tau-1} \big)</span> which is negative
  since <span class='inline'>\tau-1\leq 0</span> and <span class='inline'>1+ t  >  t\geq 1</span>. Hence <span class='inline'>h</span> is monotone decreasing
  and <span class='inline'>(t +1 )^\tau - t^\tau \leq  1</span> for all <span class='inline'>t\geq 1</span>.

  Since <span class='inline'> {\ltsbrak 0,\infty \rtsbrak}  \to \mathbb{R}</span>, <span class='inline'>t\mapsto t^\tau</span> is strictly increasing  and unbounded,
  the image of <span class='inline'>\mathbb{Z}</span> in <span class='inline'>R</span> is unbounded with respect to    <span class='inline'>|\cdot|</span>  if and only if
  it is with respect to <span class='inline'>|\cdot|^\tau</span>.  


<br><br><strong>14.7</strong> An absolute value <span class='inline'> |\cdot | : R \to \mathbb{R}_{\geq 0}</span> on a division ring <span class='inline'>R</span> induces the metric
<span class='inline'>d : R \times R \to \mathbb{R}_{\geq 0}</span>, <span class='inline'>(x,y) \mapsto |x-y|</span> which then gives 
rise to a topology on <span class='inline'>R</span>. This topology has the following properties:
</p><ol class='enumeration'>
  <li value=' (TDR1)'>
     Addition <span class='inline'>+ : R \times R \to R</span> is continuous.
  </li><li value=' (TDR2)'> 
     Multiplication <span class='inline'>\cdot : R \times R \to R</span> is 
     continuous. 
  </li><li value=' (TDR3)'> 
    Inversion <span class='inline'>(\:\cdot\:)^{-1}:R^\times \to R^\times </span> is continuous, where <span class='inline'>R^\times</span> denotes the
    set of units in <span class='inline'>R</span> i.e.~<span class='inline'>R^\times = R \setminus \{ 0\}</span>. 
</li></ol><p>

<br><i>Proof.</i>
   Addition is continuous since  for all <span class='inline'>a,b,x,y \in R</span> by the triangle inequality
   <br><br><span class='display'> d ( x + y , a+ b ) = | x + y -( a+ b)| \leq | x-a| + | y-b| = d(x,a) + d(y,b).</span><br> 
   Actually, this even shows  that addition is Lipschitz continuous. 
   Now fix <span class='inline'>a,b \in R</span> and let <span class='inline'>C = \max \{ |a|,|b| \} + 1</span>. Then for all <span class='inline'>x,y \in R</span> 
   with <span class='inline'>d(y,b)  <   1</span>
   <br><br><span class='display'> d ( x \cdot y , a \cdot b ) = | (x \cdot y - a \cdot y) + (a \cdot y - a \cdot b)| 
   \leq | x-a| \, |y|  + |a| \, | y-b| \leq C \big(  d(x,a) + d(y,b) \big) .</span><br> 
   Hence multiplication is continuous.
   Finally, fix <span class='inline'>a \in R^\times</span> and let <span class='inline'>x \in R^\times </span> with <span class='inline'>d(x,a)  <   \frac{|a|}{2}</span>. Then 
   <span class='inline'>|x| \geq |a| - d(x,a)  >  \frac{|a|}{2}  > 0</span> and
   <br><br><span class='display'> d \left( x^{-1} , a^{-1} \right) =  \left|  x^{-1} - a^{-1} \right| = \left|  x^{-1} \cdot a^{-1} \right| 
   \, | x-a | = \frac{1}{|x| \, |a|} d( x,a )  <   \frac{2}{|a|^2} d( x,a )  .</span><br> 
   So inversion is also continuous.


<br><br><strong>Definition 14.8</strong>
 A division ring or field <span class='inline'>R</span> which is equipped with a topology so that 
  (TDR1),
  (TDR2) and
  (TDR3) are satisfied is called a
 <i>topological division ring</i> or a <i>topological field</i>, respectively.
<br><br> 

<br><br><strong>Lemma 14.9</strong>
  If <span class='inline'>|\cdot|</span> is a non-trivial absolute value on the division ring <span class='inline'>R</span>, then there exists an element
  <span class='inline'>t\in R^\times</span> such that the sequence <span class='inline'>(t^n)_{n\in\mathbb{N}}</span> converges to <span class='inline'>0</span>. Furthermore in this case
  every <span class='inline'>0</span>-neighborhood in <span class='inline'>R</span> contains infinitely many elements.
<br><br>
<br><i>Proof.</i>
  By non-triviality of <span class='inline'>|\cdot|</span> there exists <span class='inline'>t\in R^\times</span> such that <span class='inline'>|t|\neq 1</span>. By possibly
  passing to <span class='inline'>t^{-1}</span> we can assume <span class='inline'>|t| < 1</span>. Since then <span class='inline'>\lim\limits_{n\to\infty} |t|^n =0</span>,
  the sequence <span class='inline'>(t^n)_{n\in\mathbb{N}}</span> converges to <span class='inline'>0</span>.  This implies in particular that 
  for every <span class='inline'>\varepsilon  > 0</span> the open ball <span class='inline'>\mathbb{B} (0,\varepsilon) =\{t \in R \mid |t|  <  \varepsilon \}</span>
  contains infinitely many elements. So the lemma is proved. 




<br><br><strong>Definition 14.10</strong>
  Two absolute values <span class='inline'>|\cdot|</span> and <span class='inline'>|\cdot|^\prime</span> on a division ring <span class='inline'>R</span> are called <i>equivalent</i>
  if they induce the same topology on <span class='inline'>R</span>. 
<br><br>

<br><br><strong>Theorem 14.11</strong>
  Let <span class='inline'>|\cdot|</span> and <span class='inline'>|\cdot|^\prime</span> be two absolute values on the division ring <span class='inline'>R</span>.
  Then they are equivalent if and only if there exists <span class='inline'>e > 0</span> such that <span class='inline'>|\cdot|^\prime =|\cdot|^\tau</span>.
  In particular the trivial absolute value is the only one inducing the discrete topology on <span class='inline'>R</span>. 
<br><br>

<br><i>Proof.</i>
  Let us first show the following proposition.
  </p><ol class='enumeration'>
  <li value='( A)'> 
    If <span class='inline'>|\cdot|</span> and <span class='inline'>|\cdot|^\prime</span> are equivalent, then  the relation <span class='inline'>|x| <  1</span> holds true for <span class='inline'>x \in R^\times</span>
    if and only if <span class='inline'>|x|^\prime <  1</span>. 
  </li></ol><p>
  Since <span class='inline'>\left| x^{-1}\right| =\frac{1}{|x|}</span> and <span class='inline'>\left| x^{-1}\right|^\prime =\frac{1}{|x|^\prime}</span>
  for all <span class='inline'>x \in R^\times</span>, ref_error
  implies that <span class='inline'>|x| >  1</span> if and only if <span class='inline'>|x|^\prime >  1</span> and that  <span class='inline'>|x|= 1</span> if and only if <span class='inline'>|x|^\prime = 1</span>.
  To verify claim ref_error assume now that <span class='inline'>0  <  |x| <  1</span>.
  Then  <span class='inline'>\lim\limits_{n\to\infty}|x^n|=0</span>, hence <span class='inline'>(x^n)_{n\in\mathbb{N}}</span> converges to <span class='inline'>0</span>. By assumption,
  <span class='inline'>\lim\limits_{n\to\infty}|x^n|^\prime=0</span> then holds as well which implies that <span class='inline'>|x|^\prime < 1</span>.
  By switching  <span class='inline'>|\cdot|</span> and <span class='inline'>|\cdot|^\prime</span>  the converse holds true, so
  ref_error is proved.
  

  Next we show that <span class='inline'>|\cdot|</span> is trivial  if and only if the induced topology on <span class='inline'>R</span> is discrete.
  Namely, if  <span class='inline'>|\cdot|</span> is non-trivial, then there exists <span class='inline'>x\in R^\times</span> such  that  <span class='inline'>|x| \neq 1</span>. After
  possibly passing to <span class='inline'>\frac 1x</span> we can achieve that  <span class='inline'>|x|  <  1</span>. So <span class='inline'>\lim\limits_{n\to\infty}|x^n|=0</span>, which
  means that <span class='inline'>(x^n)_{n\in\mathbb{N}}</span> is a sequence of non-zero elements of <span class='inline'>R</span> converging to <span class='inline'>0</span>. But this implies that
  the singleton <span class='inline'>\{ 0\}</span> is not  open in the topology induced by <span class='inline'>|\cdot|</span>, hence this topology is non-discrete. 
  Since obviously the trivial absolute value induces the discrete topology on <span class='inline'>R</span> the second claim of the theorem is
  proved.
  
  Now assume that <span class='inline'>|\cdot|^\prime =|\cdot|^\tau</span> for some <span class='inline'>\tau > 0</span>. Then a subset <span class='inline'>B \subset R</span> is a metric
  open ball with respect to <span class='inline'>|\cdot|</span> if and only if it is one with respect to <span class='inline'>|\cdot|^\prime</span>
  since for <span class='inline'>x \in R</span> and <span class='inline'>\varepsilon  > 0</span>
  <br><br><span class='display'>
  
    \big\{ y \in R \bigm\vert |y -x|  <  \varepsilon \big\}  = \big\{ y \in R \bigm\vert |y-x|^\prime  <  \varepsilon^\tau \big\}
    \text{ and } </span><br><br><span class='display'>
    \big\{ y \in R \bigm\vert |y- x|^\prime  <  \varepsilon \big\}  = \big\{ y \in R \bigm\vert |y-x|  <  \varepsilon^{1/\tau} \big\} .
  
  </span><br>
  Hence the open sets with respect to the metric defined by <span class='inline'>|\cdot|</span> coincide with those defined by <span class='inline'>|\cdot|^\prime</span> and
  the two absolute values  are equivalent.

  Let us finally show the other direction and assume that <span class='inline'>|\cdot|</span> and <span class='inline'>|\cdot|^\prime</span> are equivalent.
  By the already proven second claim of the theorem we can restrict to the case where the induced topology is non-discrete
  which means to the case where both  <span class='inline'>|\cdot|</span> and <span class='inline'>|\cdot|^\prime</span> are non-trivial.
  We show that there exists <span class='inline'>\tau  > 0</span> such that <span class='inline'>|x|^\prime =  |x|^\tau </span> for all <span class='inline'>x\in R^\times</span> with <span class='inline'> |x| >  1</span>.
  This is sufficient, since if <span class='inline'> |x|= 1</span>, then <span class='inline'>|x|^\prime =  1 = |x|^\sigma </span> for any <span class='inline'>\sigma  > 0</span> 
  by ref_error, and since if <span class='inline'>x\in R^\times</span> with <span class='inline'> |x| <  1</span> then
  <span class='inline'> |x^{-1}|  >  1</span> and
  <br><br><span class='display'>
     |x|^\prime = \frac{1}{\left|x^{-1}\right|^\prime} = \frac{1}{\left|x^{-1}\right|^\tau} = |x|^\tau .
  </span><br>
  The existence of a <span class='inline'>\tau  > 0</span> with the claimed property is equivalent to the function
  <br><br><span class='display'>
       R^\times \to \mathbb{R},\: x \mapsto \frac{\ln |x|^\prime}{\ln |x|}
  </span><br>
  being constant. Assume that that is not the case. Then there exist <span class='inline'>x,y \in R^\times</span>
  with <span class='inline'>|x|,|y| > 1</span> such that
  <span class='inline'>\frac{\ln |x|^\prime}{\ln |x|} \neq \frac{\ln |y|^\prime}{\ln |y|}</span>. By possibly switching <span class='inline'>x</span> and <span class='inline'>y</span> we
  can assume  <span class='inline'>\frac{\ln |x|^\prime}{\ln |x|}  <  \frac{\ln |y|^\prime}{\ln |y|}</span>.
  But that implies <span class='inline'>\frac{\ln |x|^\prime}{\ln |y|^\prime}  <  \frac{\ln |x|}{\ln |y|}</span> since the logarithms are positive
  by assumptions on <span class='inline'>x</span> and <span class='inline'>y</span> and ref_error. Hence there exists a
  rational number <span class='inline'>\frac pq</span> with <span class='inline'>p,q \in \mathbb{N}_{ >  0}</span> such that
  <br><br><span class='display'>
   \frac{\ln |x|^\prime}{\ln |y|^\prime}  <  \frac pq  <  \frac{\ln |x|}{\ln |y|} . 
  </span><br>
  Then <span class='inline'>|x^q|^\prime  <   |y^p|^\prime</span> and <span class='inline'>|y^p|  <   |x^q|</span> which entails
  <br><br><span class='display'>
    \left| \frac{x^q}{y^p} \right|^\prime  <  1 \text{ and }
    \left| \frac{x^q}{y^p} \right|  >  1 .
  </span><br> 
  This contradicts ref_error and the theorem is proved.


<br><br><strong>Remarks 14.12</strong>
  
  </p><ol class='enumeration'>

  <li value='(a) '>
    By  Ostrowski's theorem <dt-cite key="ERROR"></dt-cite>[p.~276]OstLF, see also <dt-cite key="ERROR"></dt-cite>[Thm.~3.1.3]GouAN, every non-trivial absolute value
    on the field <span class='inline'>\mathbb{Q}</span> of rational numbers is either equivalent to the standard absolute value <span class='inline'>|\cdot|_\infty</span> or to a
    <span class='inline'>p</span>-adic absolute value <span class='inline'>|\cdot|_p</span>  for some prime number <span class='inline'>p</span>. Observe that for different primes <span class='inline'>p</span> and <span class='inline'>q</span> the
    absolute values <span class='inline'>|\cdot|_p</span> and <span class='inline'>|\cdot|_q</span> are not equivalent.
  </li><li value='(b) '>
    Another theorem of Ostrowski <dt-cite key="ERROR"></dt-cite>[p.~284]OstLF, sometimes called big Ostrowski's theorem, tells that for every archimedean
    valued field <span class='inline'>(\mathbb{K},|\cdot|)</span> there exists an embedding <span class='inline'>\iota :\mathbb{K} \hookrightarrow \mathbb{C}</span> into the field of complex numbers
    with its standard absolute value and a positive real number <span class='inline'>\tau\leq 1</span> such that
    <br><br><span class='display'>
         |x| =|\iota(x) |_\infty^\tau \quad \text{for all } x \in \mathbb{K} .
    </span><br>
    In particular this means that every complete archimedean valued field is isomorphic to either <span class='inline'>(\mathbb{R},|\cdot|_\infty^\tau)</span> or
    <span class='inline'>(\mathbb{C},|\cdot|_\infty^\tau)</span> for some positive <span class='inline'>\tau\leq 1</span>.
  </li><li value='(c) '>
    The <span class='inline'>p</span>-adic absolute values on <span class='inline'>\mathbb{Q}</span>  have extensions to <span class='inline'>\mathbb{R}</span> by <dt-cite key="ERROR"></dt-cite>[XII, \S4, Thm.~4.1]LanA3rd. 
    This is a highly non-obvious result. To prove it one has to check first that <span class='inline'>|\cdot|_p</span> can be extended to an absolute 
    value <span class='inline'>|\cdot|</span> on the field <span class='inline'>\Bbbk</span> of real numbers algebraic over <span class='inline'>\mathbb{Q}</span>. This extended absolute value is, 
    and that turns out to be crucial, again non-archimedean. 
    Now one observes that <span class='inline'>|\cdot|</span> can be extended to the polynomial ring <span class='inline'>\Bbbk [X]</span> by the <i>Gau\ss norm</i>
    <span class='inline'>|p(X)| = \max_{0\leq i \leq n} \{a_i\}</span> where <span class='inline'>p(X)= a_n X^n + \ldots + a_1 X + a_0 \in\Bbbk [X]</span>.
    The Gau\ss norm obviously extends to an absolute value on the fraction field <span class='inline'>\Bbbk(X)</span>.
    Again, this extension is non-archimedean. 
    Now one recalls that <span class='inline'>\mathbb{R}</span> is a purely transcendental field extension of <span class='inline'>\Bbbk</span> and uses a transfinite induction type
    argument involving the just constructed  Gau\ss norm to extend <span class='inline'>|\cdot|</span> from <span class='inline'>\mathbb{K}</span> to <span class='inline'>\mathbb{R}</span>.
    The thus obtained extension of the <span class='inline'>p</span>-adic absolute value to <span class='inline'>\mathbb{R}</span> is not unique. In its construction, the
    axiom of choice is used, so one can not even give an explicit formula for such an extension. 
  
  </li></ol><p>

<br><br>

</p><h1>15 The category of topological vector spaces</h1><p>


</p><h2>Vector space topologies</h2><p>\addcontentslinetocsubsectionVector space topologies
<br><br><strong>Definition 15.1</strong>
  
   Let <span class='inline'>R</span> be a topological division ring. 
   A topology <span class='inline'>\mathscr{T}</span> on  a vector space  <span class='inline'>\mathrm{E}</span>  over <span class='inline'>R</span> 
   is called a <i>vector space topology</i> if the following axioms hold true:
   </p><ol class='enumeration'>
   <li value=' (TVS1)'>
     Addition <span class='inline'>+ : \mathrm{E} \times \mathrm{E} \to \mathrm{E}</span> is continuous.
   </li><li value=' (TVS2)'> 
     Multiplication by scalars  <span class='inline'>\cdot : R \times \mathrm{E} \to \mathrm{E}</span> is 
     continuous.
</li></ol><p>
A vector space  <span class='inline'>\mathrm{E}</span> together with a vector space topology on it
is called a <i>topological vector space</i> (<i>over</i> <span class='inline'>R</span>), for short a \textt.v.s.
<br><br>

<br><br><strong>Remark 15.2</strong>
  Let us recall at this point some notation from linear algebra. Assume that <span class='inline'>\mathrm{V}</span> is
  a left vector space over the divison ring <span class='inline'>R</span>.
  If <span class='inline'>A,B\subset \mathrm{V}</span> are two non-empty subsets, then <span class='inline'>A+B</span> is
  the set of all <span class='inline'>v\in \mathrm{V}</span> for which there exist <span class='inline'>x\in A</span> and <span class='inline'>y\in B</span> such that
  <span class='inline'>v = x+y</span>. If <span class='inline'>A</span> or <span class='inline'>B</span> is empty, then <span class='inline'>A+B</span> is defined as the empty set.
  In case <span class='inline'>A</span> is a singleton that is if <span class='inline'>A =\{x\}</span>, then we often write <span class='inline'>x + B</span> instead of
  <span class='inline'>\{x\} +B</span>. If <span class='inline'>\mathscr{B} \subset \mathscr{P}(\mathrm{V})</span> is a non-empty set of subsets of <span class='inline'>\mathrm{V}</span>,
  then we denote by <span class='inline'>A + \mathscr{B}</span> and <span class='inline'>x + \mathscr{B}</span> the sets
  <span class='inline'>\{ A + B \in \mathscr{P}(\mathrm{V}) \mid  B \in  \mathscr{B}\} </span> and
  <span class='inline'>\{ x + B \in \mathscr{P}(\mathrm{V}) \mid  B \in  \mathscr{B}\} </span>, respectively.
  If <span class='inline'>\mathscr{A} \subset \mathscr{P}(\mathrm{V})</span>  is a  second non-empty set of subsets of <span class='inline'>\mathrm{V}</span>,
  then <span class='inline'>\mathscr{A} + \mathscr{B}</span> stands for the set of all sets of the form <span class='inline'>A+B</span>, where
  <span class='inline'>A\in \mathscr{A}</span> and <span class='inline'>B\in \mathscr{B}</span>. 
  
  In case <span class='inline'>C</span> is a subset of the ground ring <span class='inline'>R</span>, then <span class='inline'>C \cdot A</span> is defined as the set of all
  <span class='inline'>v\in \mathrm{V}</span> for which there exist
  <span class='inline'>c\in C</span> and <span class='inline'>x\in A</span> such that <span class='inline'>v =c \cdot x</span>. If <span class='inline'>C =\{c\}</span> we write <span class='inline'>c\cdot A</span>
  for <span class='inline'>\{c\} \cdot A</span>. Likewise, if <span class='inline'>A =\{x\}</span>, <span class='inline'>C\cdot x</span> stands for <span class='inline'>C\cdot\{x\}</span>.
  Analogously as for addition the sets <span class='inline'>\mathscr{C}\cdot A</span>, <span class='inline'>C\cdot \mathscr{A}</span>
  and <span class='inline'>\mathscr{C}\cdot \mathscr{A}</span> are defined when  
  <span class='inline'>\mathscr{C} \subset \mathscr{P}(R)</span> and <span class='inline'>\mathscr{A} \subset \mathscr{P}(\mathrm{V})</span>
  are non-empty. 
<br><br>

<br><br><strong>Proposition 15.3</strong>
  Let <span class='inline'>\mathrm{E}</span> be a \textt.v.s.~over a topological division ring <span class='inline'>R</span>.
  Then the following holds true:
  
  </p><ol class='enumeration'>

  <li value='(I)'>
    For every <span class='inline'>t\in R^\times</span> and <span class='inline'>w\in \mathrm{E}</span> the homothety
    <span class='inline'>\ell_{t,w} : \mathrm{E} \to \mathrm{E}</span>, <span class='inline'>v\mapsto tv +w</span> is a homeomorphism
    with inverse <span class='inline'>\ell_{t^{-1},-t^{-1}w}</span>.
   </li><li value='(II)'>
     Let <span class='inline'>w</span> be an element of <span class='inline'>\mathrm{E}</span> and <span class='inline'>t\in R^\times</span>. 
     A filter base <span class='inline'>\mathscr{B}</span> on <span class='inline'>\mathrm{E}</span> then is a filter base for the zero
     neighborhoods if and only if  <span class='inline'>w + t \mathscr{B}</span> is a filter base for the
     neighborhoods of <span class='inline'>w</span>.
   </li><li value='(III)'>
     If <span class='inline'>\mathscr{B}</span> is a filter base of the filter of zero neighborhoods, then 
     the closure of any non-empty <span class='inline'>A\subset \mathrm{E}</span>  is given by
     <br><br><span class='display'>
       \widebar{A} =\bigcap\limits_{U \in \mathscr{B}} A + U .
     </span><br>
   </li><li value='(IV)'>
     Let <span class='inline'>A\subset \mathrm{E}</span> be open and <span class='inline'>B\subset \mathrm{E}</span>. Then the set
     <span class='inline'>A+B</span> is open.
   </li><li value='(V)'>
     Let <span class='inline'>A, B \subset \mathrm{E}</span> be closed and assume that <span class='inline'>A</span> is quasi-compact
     that is that any filter on <span class='inline'>A</span> has a cluster point.
     Then the set <span class='inline'>A+B</span> is closed.
   </li><li value='(VI)'>
     The space  <span class='inline'>\mathrm{E}</span> is ref_error or, equivalently, each point of <span class='inline'>\mathrm{E}</span> possesses a
     neighborhood base consisting of closed subsets.
  
  </li></ol><p>
   
  <br><br>

<br><i>Proof.</i>
  
  </p><ol class='enumeration'>

  <li value='\itshape ad (\itshape I\hspace1pt). '>
    The homothety <span class='inline'>\ell_{t,w}</span> is continuous since addition and multiplication by a scalar
    are continuous maps on a \textt.v.s.Since for all <span class='inline'>v\in V</span> 
    <br><br><span class='display'> \tag{15.1}
      \nonumber
       \ell_{t^{-1},-t^{-1}w}\circ \ell_{t,w} (v) = t^{-1} (tv +w) - t^{-1}w = v, \text{ and}</span><br><br><span class='display'>
      \nonumber
       \ell_{t,w} \circ \ell_{t^{-1},-t^{-1}w} (v) = t (t^{-1}v  - t^{-1}w) + w = v
    </span><br><br>
    the homothety <span class='inline'>\ell_{t,w}</span>  is invertible, and its inverse is <span class='inline'>\ell_{t^{-1},-t^{-1}w}</span>.
  </li><li value='\itshape ad (\itshape II\hspace1pt). '>
    This follows since <span class='inline'>\ell_{t,w}</span> is a homeomorphism.   
  </li><li value='\itshape ad (\itshape III\hspace1pt). '>
     Let <span class='inline'>B = \bigcap\limits_{U \in \mathscr{B}} A + U</span>. Let <span class='inline'>v</span> be an element of the closure of <span class='inline'>A</span>.
     Then, for <span class='inline'>U \in \mathscr{B}</span>, there exists an element <span class='inline'>a \in A \cap v - U</span> by (II)
     and since <span class='inline'>-U</span> is a zero neighborhood. Hence <span class='inline'>v \in a + U</span>, and <span class='inline'>\widebar{A} \subset B</span> follows.
     Now let <span class='inline'>v \in B</span> and <span class='inline'>V</span> be a neighborhood of <span class='inline'>v</span>. Then there exists <span class='inline'>U\in \mathscr{B}</span> such that 
     <span class='inline'>v -U \subset V</span>. By definition of <span class='inline'>B</span> there exists an element <span class='inline'>a\in A</span> such that <span class='inline'>v \in a + U</span>.
     Hence <span class='inline'>a \in v - U \subset V</span> which implies that <span class='inline'>v \in \widebar{A}</span>.
     So <span class='inline'>B \subset \widebar{A}</span>. 
  </li><li value='\itshape ad (\itshape IV\hspace1pt). '>
    The set <span class='inline'>A+B</span> is either empty or coincides with the union <span class='inline'>\bigcup_{v\in B} v + A</span>.
    In the latter case, each of the sets  <span class='inline'>v+ A</span> is non-empty and
    open by continuity of addition. So <span class='inline'>A+B</span> is open under the assumptions made.
  </li><li value='\itshape ad (\itshape V\hspace1pt). '>
    We can assume that <span class='inline'>A</span> and <span class='inline'>B</span> are non-empty because the claim is trivial otherwise.
    Assume that <span class='inline'>A+B</span> is not closed. Then there exists an element <span class='inline'>v \in \mathrm{E} \setminus (A+B) </span>
    such that each neighborhood of <span class='inline'>v</span> meets <span class='inline'>A+B</span>. This means in particular that
    the restriction of the neighborhood filter <span class='inline'>\mathscr{U}</span> of <span class='inline'>v</span> to <span class='inline'>A+B</span> is a filter base.
    Consequently, <span class='inline'>(- B + \mathscr{U})\cap A</span> is a filter base on <span class='inline'>A</span>, hence possesses an
    accummulation point <span class='inline'>x \in A</span>. For each neighborhood <span class='inline'>V \in \mathscr{U}</span> the point <span class='inline'>x</span> is then
    contained in the closure of <span class='inline'>-B +V</span>. Hence, by (III),
    <span class='inline'>x</span> is contained in <span class='inline'>v -B + U + U</span> for every zero neighborhood <span class='inline'>U</span>.
    Since by continuity of addition <span class='inline'>U + U</span> runs through a base of zero neighborhoods when
    <span class='inline'>U</span> runs through the zero neighborhoods,
    <span class='inline'>x \in v - \widebar{B} = v -B</span> follows. Since <span class='inline'>x \in A</span> this contradicts the assumption
    <span class='inline'>v \in A+B</span> and <span class='inline'>A+B</span> has to be closed.
  </li><li value='\itshape ad (\itshape VI\hspace1pt). '>
    Let <span class='inline'>v \in \mathrm{E}</span>, <span class='inline'>A\subset \mathrm{E}</span> closed, and assume <span class='inline'>v \notin A</span>.
    Choose an open neighborhood <span class='inline'>V</span> of <span class='inline'>v</span> such that <span class='inline'>V \cap A = \emptyset</span>. Then there
    exists an open zero neighborhood <span class='inline'>U</span> such that <span class='inline'>v + U + U \subset V</span>. By possibly passing to
    <span class='inline'>U \cap (-U)</span> we can assume that <span class='inline'>U = -U</span>. Now <span class='inline'>v+U</span> is an open neighborhood of <span class='inline'>v</span>
    and <span class='inline'>A+U</span> one of <span class='inline'>A</span>. These neighborhoods are disjoint because if the intersection
    <span class='inline'>v+U \cap A+U</span> is non-empty, then there exists an element <span class='inline'>w \in v+U + U\cap A</span> since
    <span class='inline'>-U =U</span>. This contradicts  <span class='inline'>V \cap A = \emptyset</span>, so   <span class='inline'>v+U</span> and <span class='inline'>A+U</span> are disjoint neighborhoods
    of <span class='inline'>v</span> and <span class='inline'>A</span>, respectively. Hence <span class='inline'>\mathrm{E}</span> satisfies ref_error.
  
  </li></ol><p>



<br><br><strong>Definition 15.4</strong>
  A subset <span class='inline'>C</span> of a  vector space  <span class='inline'>\mathrm{E}</span>  over a valued division ring <span class='inline'>(R,|\cdot|)</span> is called
  
  </p><ol class='enumeration'>

  <li value='(I)'>
    <i>symmetric</i> if <span class='inline'>-v \in C</span> for all <span class='inline'>v\in C</span>,
  </li><li value='(II)'>
    <i>circled</i> or <i>balanced</i> if <span class='inline'>tv \in C</span> for all <span class='inline'>v\in C</span> and <span class='inline'>t\in R</span> with <span class='inline'>|t| \leq 1</span>.
  
  </li></ol><p>

<br><br>

<br><br><strong>Remark 15.5</strong>
  Symmetry of a subset of a vector space of a division ring is even defined when the underlying division
  ring does not carry an absolute value. 
<br><br>

<br><br><strong>Lemma 15.6</strong>

  Let <span class='inline'>C</span> be a subset of a topological vector space <span class='inline'>\mathrm{E}</span> over a
  valued division ring <span class='inline'>(R,|\cdot|)</span> and <span class='inline'>r\in R</span>.
  
  </p><ol class='enumeration'>

  <li value='(I)'>  
    If <span class='inline'>C</span> is symmetric, then the closure <span class='inline'>\widebar{C}</span> and the interior <span class='inline'>\mathring{C}</span> are symmetric.  
  </li><li value='(II)'>    
    If <span class='inline'>C</span> is circled, then the closure <span class='inline'>\widebar{C}</span> and  the union <span class='inline'>\mathring{C} \cup\{0\}</span> are circled.
  </li><li value='(III)'>  
    The set <span class='inline'>rC</span> is symmetric (respectively circled) if <span class='inline'>C</span> has that property.  
  
  </li></ol><p>

<br><br>

<br><i>Proof.</i>
  Without loss of generality we can assume <span class='inline'>C \neq \emptyset</span>.
  Claim (I) then follows immediately since multiplication
  by <span class='inline'>-1</span> is a homeomorphism. 
  To prove  claim (II) assume that <span class='inline'>C</span> is circled. 
  Let <span class='inline'>t\in R</span> with <span class='inline'>|t|\leq 1</span>. Assume <span class='inline'>v \in \widebar{C}</span> and consider <span class='inline'>tv</span>. We have to show
  that <span class='inline'>tv \in \widebar{C}</span>. If <span class='inline'>t=0</span> then <span class='inline'>tv =0\in C \subset \widebar{C}</span> since <span class='inline'>C</span> is circled.
  So we can assume <span class='inline'>t\neq 0</span> and need to show that for every neighborhood <span class='inline'>V</span> of <span class='inline'>tv</span> the intersection
  <span class='inline'>C\cap V</span> is non-empty. Since <span class='inline'>|t| > 0</span>, the homothety <span class='inline'>\ell_t:\mathrm{E}\to \mathrm{E}</span>, <span class='inline'>w\mapsto tw</span> is a
  homeomorphism with inverse
  <span class='inline'>\ell_{t^{-1}}</span>. Hence <span class='inline'>t^{-1}V</span> is a neighborhood of <span class='inline'>v</span>. Since <span class='inline'>v</span> lies in the closure of <span class='inline'>C</span> 
  there exists an element <span class='inline'>w\in C\cap t^{-1}V</span>. Hence <span class='inline'>tw \in C \cap V</span> by assumption on <span class='inline'>C</span>
  and <span class='inline'>\widebar{C}</span> is circled.

  If <span class='inline'>v \in \mathring{C}\cup\{0\}</span> then <span class='inline'>0 = 0 \cdot v \in \mathring{C}\cup\{0\}</span>. It remains to show that
  <span class='inline'>tv \in \mathring{C}\cup\{0\}</span> for <span class='inline'>t\in R</span> with <span class='inline'>0  <  |t|\leq 1</span> and <span class='inline'>v \in \mathring{C} \setminus \{ 0\}</span>.
  Under this assumption the homothety <span class='inline'>\ell_t</span> is a homeomorphism, so <span class='inline'>t \mathring{C}</span> is an open subset
  of <span class='inline'>C</span> since <span class='inline'>C</span> is circled. Hence <span class='inline'>t v \in t \mathring{C} \subset \mathring{C}</span>, and  <span class='inline'>\mathring{C}\cup\{0\}</span>
  is circled as well.

  Claim (III) follows immediately from the observation that
  for  <span class='inline'>v\in C</span> and <span class='inline'>t\in R</span> the relation <span class='inline'>trv \in rC</span> holds true if <span class='inline'>tv \in C</span>. 


<br><br><strong>Proposition and Definition 15.7</strong>
  The intersection of a non-empty family <span class='inline'>(C_i)_{i\in I}</span> of symmetric (respectively circled) subsets <span class='inline'>C_i \subset \mathrm{E}</span>, <span class='inline'>i\in I</span>
  of a topological vector space <span class='inline'>\mathrm{E}</span>  valued division ring <span class='inline'>(R,|\cdot|)</span>
  is symmetric (respectively circled).
  In particular, if <span class='inline'>A \subset \mathrm{E}</span> is a subset, then the sets
  <br><br><span class='display'>
    \operatorname{Sym} A = \bigcap\limits_{A \subset B \subset \mathrm{E} \atop {B \text{ is symmetric}} }  B \quad \text{and} \quad
    \operatorname{Circ} A = \bigcap\limits_{A \subset B \subset \mathrm{E} \atop {B \text{ is circled}} }  B 
  </span><br>
  are symmetric and circled, respectively.   They have the property that
  <span class='inline'>\operatorname{Sym} A</span> is the smallest symmetric and <span class='inline'>\operatorname{Circ} A</span> the smallest circled subsets of <span class='inline'>\mathrm{E}</span> containing <span class='inline'>A</span>.
  They are called the <i>symmetric</i> and the <i>circled hull</i> of <span class='inline'>A</span>, respectively.
  Analogously,
  <br><br><span class='display'>
    \widebar{\operatorname{Sym}}\, A = \bigcap\limits_{A \subset B =\widebar{B} \subset \mathrm{E} \atop {B \text{ is symmetric}} }  B \quad \text{and} \quad
    \overline{\operatorname{Circ}}\, A = \bigcap\limits_{A \subset B  =\widebar{B}  \subset \mathrm{E} \atop {B \text{ is circled}} }  B 
  </span><br>
  are called the <i>closed symmetric</i> and the <i>closed circled hull</i> of <span class='inline'>A</span>, respectively.
  They have the property that <span class='inline'>\widebar{\operatorname{Sym}}\, A</span> is the smallest closed symmetric and <span class='inline'>\overline{\operatorname{Circ}}\, A</span> the smallest closed
  circled subset of <span class='inline'>\mathrm{E}</span> containing <span class='inline'>A</span>.
<br><br>
<br><i>Proof.</i>
  Note first that all the hulls in the proposition are well-defined since <span class='inline'>\mathrm{E}</span> is
  closed and circled. 
  Let <span class='inline'>C</span> denote the intersection of the family <span class='inline'>(C_i)_{i\in I}</span>. Assume that for some <span class='inline'>t\in R</span> with <span class='inline'>|t|\leq 1</span>
  the inclusion <span class='inline'>tC_i \subset C</span> holds true for all  <span class='inline'>i\in I</span>. Then <span class='inline'>tC \subset C</span>, hence if all
  <span class='inline'>C_i</span> are symmetric (respectively circled), so is <span class='inline'>C</span>.
  This observation now entails that <span class='inline'>\operatorname{Sym} A</span> is symmetric, <span class='inline'>\operatorname{Circ}</span> is circled, <span class='inline'>\widebar{\operatorname{Sym}}\, A</span> is closed
  and symmetric, and finally that <span class='inline'>\overline{\operatorname{Circ}}\, A</span> is closed and circled. Moreover, all those sets contain <span class='inline'>A</span>.
  The minimality properties of these sets are clear by construction.  


<br><br><strong>Remark 15.8</strong>
  Observe that by the proposition <span class='inline'>A</span> is symmetric if and only if <span class='inline'>\operatorname{Sym} A = A</span> and
  circled if and only if <span class='inline'>\operatorname{Circ} A = A</span>. Analogously,
  <span class='inline'>\widebar{\operatorname{Sym}}\, A = A</span> if and only if <span class='inline'>A</span> is closed symmetric and
  <span class='inline'>\overline{\operatorname{Circ}}\, A = A</span> if and only if <span class='inline'>A</span> is closed and circled. 
<br><br>


<br><br><strong>Lemma 15.9</strong>
  Let <span class='inline'>\mathrm{E}</span> be a topological vector space over the valued division ring <span class='inline'>(R,|\cdot|)</span>
  and <span class='inline'>A \subset \mathrm{E}</span> non-empty. Then
  <br><br><span class='display'>
    \operatorname{Sym} A = A \cup -A  \quad \text{and} \quad \operatorname{Circ} A = \bigcup_{t\in R, \: |t|\leq 1} t A .
  </span><br>
  For the closed hulls one has  
  <br><br><span class='display'>
    \widebar{\operatorname{Sym}}\, A = \overline{\operatorname{Sym} A} \quad \text{and} \quad \overline{\operatorname{Circ}}\, A = \overline{\operatorname{Circ} A} .
  </span><br>
<br><br>

<br><i>Proof.</i>
  Since <span class='inline'>A \cup -A</span> is symmetric by definition, contains <span class='inline'>A</span>, and is contained in
  <span class='inline'>\operatorname{Sym} A</span>, the equality <span class='inline'>\operatorname{Sym} A = A \cup -A</span> holds true.
  Similarly, <span class='inline'>\bigcup_{t\in R, \: |t|\leq 1} t A</span> is circled by definition, contains <span class='inline'>A</span>, and is contained
  in <span class='inline'>\operatorname{Circ} A</span> by definition of the circled hull. Hence <span class='inline'> \operatorname{Circ} A = \bigcup_{t\in R, \: |t|\leq 1} t A </span>.
  The remainder of the claim follows from \Crefthm:closure-interior-circled-set-circled.


<br><br><strong>Definition 15.10</strong>
  Assume that <span class='inline'>B,C</span> are subsets of a vector space <span class='inline'>\mathrm{E}</span> over the valued division ring
  <span class='inline'>(R,|\cdot|)</span>. Then one says that 
  
  </p><ol class='enumeration'>

  <li value='(I)'>
   <span class='inline'>C</span>  <i>absorbes</i> <span class='inline'>B</span> if  there exists a real number <span class='inline'>r \in \mathbb{R}_{\geq 0}</span> 
   such that <span class='inline'>B \subset tC</span> for all <span class='inline'>t\in R</span> with <span class='inline'>|t| \geq r</span>,
  </li><li value='(II)'>
   <span class='inline'>C</span> is  <i>absorbing</i> or <i>absorbent</i> 
   if <span class='inline'>C</span> absorbes every one-point set of <span class='inline'>\mathrm{E}</span> that is if for every 
   <span class='inline'>v\in \mathrm{E}</span> there exists <span class='inline'>r \in \mathbb{R}_{\geq 0}</span> such that 
   <span class='inline'>v \in tC</span> for all <span class='inline'>t\in R</span> with <span class='inline'>|t| \geq r</span>.
 
  </li></ol><p>

 
  If the vector space <span class='inline'>\mathrm{E}</span> carries in addition a vector space topology, then one says that
  
  </p><ol class='enumeration'>

  \setcounterenumi2  
  <li value='(I)'>
    the subset <span class='inline'>B \subset \mathrm{E}</span> is <i>bounded</i> if it is absorbed by
    every zero neighborhood. 
  
  </li></ol><p>

<br><br>

<br><br><strong>Proposition 15.11</strong>
  The filter of zero neighborhoods of a topological vector space <span class='inline'>\mathrm{E}</span> over
  <span class='inline'>(R,|\cdot|)</span> has a filter base <span class='inline'>\mathscr{B}</span> with the following properties:
  
  </p><ol class='enumeration'>

  <li value='(I)'>
    For each <span class='inline'>V \in \mathscr{B}</span> there exists <span class='inline'>U\in\mathscr{B}</span> such that <span class='inline'>U+U \subset V</span>.
  </li><li value='(II)'>
    Every element <span class='inline'>V\in \mathscr{B}</span> is circled and absorbing.
  </li><li value='(III)'>
    There exists an element <span class='inline'>t\in R^\times</span> with <span class='inline'>0 <  |t|  <  1</span> such that <span class='inline'>V\in \mathscr{B}</span> implies
    <span class='inline'>tV \in \mathscr{B}</span>. 
  
  </li></ol><p>

  Conversely, if  <span class='inline'>\mathscr{B}</span> is a filter base on an <span class='inline'>R</span>-vector space <span class='inline'>\mathrm{E}</span> such that 
  ref_error to ref_error
  hold true, then there exists a unique vector space topology on <span class='inline'>\mathrm{E}</span>  such that <span class='inline'>\mathscr{B}</span> is a neighborhood base
  at the origin.  In case the ground ring <span class='inline'>R</span> is archimedean, a filter base on <span class='inline'>\mathrm{E}</span> which satisfies
  ref_error and ref_error
  already induces a unique vector space topology having <span class='inline'>\mathscr{B}</span> as a neighborhood base
  at <span class='inline'>0</span>.
<br><br>

<br><i>Proof.</i>
  Assume that <span class='inline'>\mathrm{E}</span> is a  \textt.v.s. Let <span class='inline'>\mathscr{B}</span> be the set of circled neighborhoods of <span class='inline'>0</span>. We show first that
  <span class='inline'>\mathscr{B}</span> is a base of the filter <span class='inline'>\mathscr{U}_0</span> of zero neighborhoods. Let <span class='inline'>W \in \mathscr{U}_0</span>. 
  By Axiom  (TVS2) there exists an <span class='inline'>\varepsilon  > 0</span> and an open
  zero neighborhood <span class='inline'>U</span> such that <span class='inline'>tU \subset W</span> for all <span class='inline'>t\in R</span> with <span class='inline'>|t| < \varepsilon</span>.
  Then <span class='inline'>V = \bigcup\limits_{t\in R^\times \:\&\: |t| < \varepsilon} tU </span> is a zero neighborhood since
  by \Crefthm:zero-neighborhood-topological-division-ring-infinite the set of <span class='inline'>t\in R^\times</span>
  with <span class='inline'>|t| < \varepsilon</span> is non-empty. By construction <span class='inline'>V</span> is contained in <span class='inline'>W</span> and circled, so <span class='inline'>V \in \mathscr{B}</span>.
  Hence <span class='inline'>\mathscr{B}</span> is a filter base of <span class='inline'>\mathscr{U}_0</span>.

  Next recall that  there exists <span class='inline'>t\in R^\times</span> with <span class='inline'>0 < |t| < 1</span> since the absolute value <span class='inline'>|\cdot|</span> is non-trivial.
  Let <span class='inline'>V\in \mathscr{B}</span>. Then <span class='inline'>sV\subset V</span> for all <span class='inline'>s\in R</span> with <span class='inline'>|s|\leq 1</span> which entails <span class='inline'>stV \subset tV</span> for all
  such <span class='inline'>s</span>. Hence <span class='inline'>tV</span> is circled and an element of <span class='inline'>\mathscr{B}</span> as well. This proves
  (III).
  Since addition on <span class='inline'>\mathrm{E}</span> is continuous, there exist for given <span class='inline'>V\in \mathscr{B}</span> open neighborhoods
  <span class='inline'>U_1,U_2</span> of the origin such that <span class='inline'>U_1+U_2\subset V</span>. Choose <span class='inline'>U\in \mathscr{B}</span> such that <span class='inline'>U \subset U_1 \cap U_2</span>.
  Then <span class='inline'>U + U \subset V</span> and (I) is proved.
  To show that any <span class='inline'>V\in\mathscr{B}</span> is absorbing let <span class='inline'>v\in \mathrm{E}</span>. By continuity of scalar multiplication
  there exists <span class='inline'>\varepsilon  > 0</span>  such that <span class='inline'>tv \in V </span> for all <span class='inline'>t\in R</span> with <span class='inline'>|t| < \varepsilon</span>.
  By \Crefthm:basic-properties-sets-maps-topological-vector-spaces (I)
  this entails <span class='inline'>v \in tV </span> for all <span class='inline'>t\in R</span> with <span class='inline'>|t| > \varepsilon</span> and <span class='inline'>V</span> is absorbing. 

  Now assume that <span class='inline'>\mathrm{E}</span> is an <span class='inline'>R</span>-vector space and that <span class='inline'>\mathscr{B}</span> is a filter base that satisfies
  (I), (II) and,
  if <span class='inline'>|\cdot|</span> is non-archimedean, (III).
  Since <span class='inline'>\mathscr{B}</span> consists of non-empty circled sets, <span class='inline'>0\in V</span> for all <span class='inline'>V\in\mathscr{B}</span>. Let
  <span class='inline'>\mathscr{T} \subset \mathscr{P}(\mathrm{E})</span> be the set of all <span class='inline'>U\subset \mathrm{E}</span> such that
  for each <span class='inline'>v\in U</span> there exists <span class='inline'>V\in \mathscr{B}</span> with <span class='inline'>v+V \subset U</span>. By definition and since <span class='inline'>\mathscr{B}</span> is a
  filter base, <span class='inline'>\mathscr{T}</span> is a topology on <span class='inline'>\mathrm{E}</span>. We show that <span class='inline'>\mathscr{B}</span> is a base of the filter
  <span class='inline'>\mathscr{U}_0</span> of zero neighborhoods. By definition of <span class='inline'>\mathscr{T}</span> there exists for each <span class='inline'>U \in \mathscr{U}_0</span>
  a <span class='inline'>V\in \mathscr{B}</span> such that <span class='inline'>V\subset U</span>. So it remains to show that each <span class='inline'>V\in \mathscr{B}</span> is a zero neighborhood.
  To this end let <span class='inline'>U</span> be the set of all <span class='inline'>v\in V</span> for which there exists
  a <span class='inline'>W\in \mathscr{B}</span> with <span class='inline'>v + W \subset V</span>. Since <span class='inline'>0 +V \subset V</span> one has <span class='inline'>0\in U</span>. The relation 
  <span class='inline'>U \subset V</span> holds because  <span class='inline'>0\in W</span> for all <span class='inline'>W\in \mathscr{B}</span>.  Now let <span class='inline'>v \in U</span>.
  By (I) there exists <span class='inline'>W^\prime</span> such that 
  <span class='inline'>v + W^\prime + W^\prime \subset V</span> which entails <span class='inline'>v + W^\prime \subset U</span>. Hence <span class='inline'>U\in\mathscr{T}</span>
  and <span class='inline'>V</span> is a zero neighborhood. 
  Next we verify that <span class='inline'>\mathscr{T}</span> is a vector space topology. We start with continuity of addition.   
  Let <span class='inline'>W</span> be an open neighborhood of <span class='inline'>v+w</span>, where <span class='inline'>v,w\in \mathrm{E}</span>. Then there exists <span class='inline'>V\in \mathscr{B}</span> such that
  <span class='inline'>v+w + V \subset W</span>. Choose <span class='inline'>U\in \mathscr{B} </span> such that <span class='inline'>U+U \subset V</span>. Then  
  <span class='inline'>v+U</span> and <span class='inline'>w +U</span> are neighborhoods of <span class='inline'>v</span> and <span class='inline'>w</span>, respectively, and <span class='inline'>(v+U) + (w +U) \subset v+w +V\subset W</span>.
  So addition is continuous. We continue with scalar multiplication. Let <span class='inline'>W</span> be an open neighborhood of <span class='inline'>rv</span>,
  where <span class='inline'>r\in R</span> and <span class='inline'>v\in \mathrm{E}</span>. Then there exists <span class='inline'>V \in \mathscr{B} </span> such that <span class='inline'>rv + V + V \subset W</span>.
  Since <span class='inline'>V</span> is absorbing by (II) there exists <span class='inline'>\varepsilon  > 0</span> such that
  <span class='inline'> (s-r)v \in V</span> for all <span class='inline'>s\in R</span> with  <span class='inline'>|s-r|  <  \varepsilon</span>. Now if <span class='inline'>|\cdot|</span> is non-archimedean
  choose <span class='inline'>t\in R^\times</span> according to (III), 
  and put <span class='inline'>V_n = t^n V</span> for all <span class='inline'>n\in\mathbb{N}</span>.
  In the archimedean case let <span class='inline'>t = \frac 12</span> and use (I) to construct
  recursively a sequence <span class='inline'>(V_n)_{n\in \mathbb{N} }</span> of elements of <span class='inline'>\mathscr{B}</span> such that
  <span class='inline'>2^nV_n = V_n + \ldots + V_n \subset V</span>, where the sum has <span class='inline'>2^n</span> summands. In either of these cases, choose 
  <span class='inline'>N\in \mathbb{N}</span> large enough so that <span class='inline'>|t|^N  <  \frac{1}{|r| + \varepsilon}</span>. Then <span class='inline'>V_N \in \mathscr{B}</span>
  and <span class='inline'>v + V_N</span> is a neighborhood of <span class='inline'>v</span>. Moreover, for <span class='inline'>w \in v + V_N</span> there exists an element
  <span class='inline'>x\in V</span> such that <span class='inline'>w-v = t^N x</span>. Then the relation
  <span class='inline'>s (w-v) = s t^N x \in V </span> holds whenever <span class='inline'>|s-r|  <  \varepsilon</span> since <span class='inline'>V_N</span> is circled. Hence for such <span class='inline'>w</span> and <span class='inline'>s</span>
  <br><br><span class='display'>
     sw = rv + s (w-v) + (s-r)v \in  rv + V + V \subset W . 
  </span><br>
  This means that scalar multiplication is continuous, and the proof is finished. 


</p><h2>Morphisms of topological vector spaces</h2><p>\addcontentslinetocsubsectionMorphisms of topological vector spaces
<br><br><strong>Definition 15.12</strong>
  By a <i>morphism</i> of topological vector spaces over the topological division
  ring <span class='inline'>R</span>  one understands  a continuous <span class='inline'>R</span>-linear map <span class='inline'>f:\mathrm{E} \to\mathrm{F}</span>
  between two topological vector spaces <span class='inline'>\mathrm{E}</span> and <span class='inline'>\mathrm{F}</span>
  over <span class='inline'>R</span>. The space of morphisms between <span class='inline'>\mathrm{E}</span> and <span class='inline'>\mathrm{F}</span> will be denoted
  <span class='inline'>\operatorname{Hom}\nolimits_{R\text{-}\mathsf{TVS}} (\mathrm{E},\mathrm{F})</span> or just
  <span class='inline'>\operatorname{Hom}\nolimits_R (\mathrm{E},\mathrm{F})</span> or <span class='inline'>\operatorname{Hom}\nolimits (\mathrm{E},\mathrm{F})</span>
  if now confusion can arrise. 
<br><br>

<br><br><strong>Theorem 15.13</strong>
  The topological vector spaces over a topological division ring <span class='inline'>R</span> as objects together 
  with their morphisms form an additive category which we denote by  <span class='inline'>R\text{-}\mathsf{TVS}</span>.
  More precisely, <span class='inline'>R\text{-}\mathsf{TVS}</span> is a category enriched over the category of
  <span class='inline'>R</span>-vector spaces where addition and scalar multiplication on the hom-spaces
  <span class='inline'>\operatorname{Hom}\nolimits (\mathrm{E},\mathrm{F})</span>  are given by
  <br><br><span class='display'> \tag{15.2}
  \nonumber  
    +:\:\operatorname{Hom}\nolimits (\mathrm{E},\mathrm{F}) \times \operatorname{Hom}\nolimits (\mathrm{E},\mathrm{F}) \to \operatorname{Hom}\nolimits (\mathrm{E},\mathrm{F}),\:
        (f,g) \mapsto f+g = \left(\mathrm{E} \ni v \mapsto f(v)+g(v)\in \mathrm{F}\right), </span><br><br><span class='display'> \nonumber
    \cdot:\:R  \times \operatorname{Hom}\nolimits (\mathrm{E},\mathrm{F}) \to \operatorname{Hom}\nolimits (\mathrm{E},\mathrm{F}),\:
        (r,f) \mapsto r \cdot f = \left(\mathrm{E} \ni v \mapsto r \cdot f(v) \in \mathrm{F}\right) .
  </span><br><br>
<br><br>

<br><i>Proof.</i>
  Observe first that the identity map <span class='inline'>\mathrm{id}_\mathrm{E}</span> on a topological vector space <span class='inline'>\mathrm{E}</span>
  is linear and continuous and so is the composition <span class='inline'>g\circ f</span> of two
  morphisms of topological vector spaces <span class='inline'>f:\mathrm{E} \to\mathrm{F}</span> and
  <span class='inline'>g:\mathrm{F} \to\mathrm{G}</span>. Hence topological vector spaces over <span class='inline'>R</span> together with linear
  and continuous maps between them form a category.

  Next check that the hom-space <span class='inline'>\operatorname{Hom}\nolimits (\mathrm{E},\mathrm{F})</span> is an abelian group.
  Associativity and commutativity of addition
  follow from the respective properties on <span class='inline'>\mathrm{F}</span>. The zero element is the constant map
  <span class='inline'>\mathrm{E} \to\mathrm{F}</span>, <span class='inline'>v \mapsto 0</span> and the inverse of a morphism <span class='inline'>f:\mathrm{E} \to\mathrm{F}</span>
  is given by <span class='inline'>-f:\mathrm{E} \to\mathrm{F}</span>,  <span class='inline'>v \mapsto -f(v)</span>.
  Similarly one checks that multiplication by scalars on <span class='inline'>\operatorname{Hom}\nolimits (\mathrm{E},\mathrm{F})</span> is associative
  and distributes from the left and from the right over addition since scalar multiplication on
  <span class='inline'>\mathrm{F}</span> has these properties. Finally, the unit of <span class='inline'>R</span> acts as identity on
  <span class='inline'>\operatorname{Hom}\nolimits (\mathrm{E},\mathrm{F})</span> since it does so  on  <span class='inline'>\mathrm{F}</span>. Hence <span class='inline'>\operatorname{Hom}\nolimits (\mathrm{E},\mathrm{F})</span>
  carries the structure of an <span class='inline'>R</span> left vector space.

  Composition of morphisms
  <span class='inline'>\operatorname{Hom}\nolimits (\mathrm{E},\mathrm{F}) \times \operatorname{Hom}\nolimits (\mathrm{F},\mathrm{G}) \to \operatorname{Hom}\nolimits (\mathrm{E},\mathrm{G})</span>,
  <span class='inline'>(f,g)\to g \circ f </span> is an <span class='inline'>R</span>-bilinear map as the following equalities for 
  <span class='inline'>f,f_1,f_2\in \operatorname{Hom}\nolimits (\mathrm{E},\mathrm{F})</span>, <span class='inline'>g,g_1,g_2 \in \operatorname{Hom}\nolimits (\mathrm{F},\mathrm{G})</span>,
  <span class='inline'>r\in R</span>, and <span class='inline'>v\in \mathrm{E}</span> show:
  <br><br><span class='display'> \tag{15.3}
    \nonumber
    (f \circ (g_1+g_2)) (v) = f( (g_1+g_2) (v) ) = f( g_1(v) +g_2(v) ) = </span><br><br><span class='display'> \nonumber
     \quad = f\circ g_1(v) + f\circ g_2(v) =  (f\circ g_1+ f\circ g_2) (v), </span><br><br><span class='display'> \nonumber
    (f \circ (r g)) (v) = f( (rg) (v) ) = f(r g(v))  = r f( g(v)) =  (r(f\circ g)) (v),  </span><br><br><span class='display'> \nonumber
    ((f_1+f_2) \circ g) (v) = (f_1+f_2) ( g (v)) = f_1(g(v)) + f_2 (g(v)) = </span><br><br><span class='display'> \nonumber
     \quad = f_1\circ g(v) + f_2\circ g(v) =  (f_1\circ g+ f_2\circ g) (v), </span><br><br><span class='display'> \nonumber
    ((rf) \circ g) (v) = (rf)( g (v)) = r (f(g(v)))  = r (f \circ g (v)) =  (r(f\circ g)) (v) .
  </span><br><br>
  Hence <span class='inline'>R\text{-}\mathsf{TVS}</span> is a category enriched over the category of <span class='inline'>R</span>-vector spaces.
  In particular,  <span class='inline'>R\text{-}\mathsf{TVS}</span> then is an additive category. 


<br><br><strong>Example 15.14</strong>
  For every \textt.v.s.~<span class='inline'>\mathrm{E}</span> and non-zero element <span class='inline'>t</span> of the ground ring <span class='inline'>R</span> the
  map <span class='inline'>\ell_t :\mathrm{E} \to \mathrm{E}</span>, <span class='inline'>v \mapsto tv</span> is an isomorphism of topological vector spaces
  by \Crefthm:basic-properties-sets-maps-topological-vector-spaces (I).
<br><br>

<br><br><strong>Proposition and Definition 15.15</strong>
  A linear map <span class='inline'>f: \mathrm{E} \to \mathrm{F}</span> between topological
  vector spaces over a valued division ring <span class='inline'>(R,|\cdot|)</span>
  maps symmetric sets to symmetric sets and  circled sets to circled sets.
  If in addition <span class='inline'>f</span> is continuous, then <span class='inline'>f</span> is <i>bounded</i> that means
  it  maps bounded subsets of <span class='inline'>\mathrm{E}</span> to bounded subsets of
  <span class='inline'>\mathrm{F}</span>.   
<br><br>

<br><i>Proof.</i>
  Since by linearity <span class='inline'>f(tv) = t f(v)</span> for all <span class='inline'>v\in \mathrm{E}</span> and <span class='inline'>t\in R</span>,
  <span class='inline'>f (C)</span> is symmetric (respectively circled) if the subset <span class='inline'>C\subset \mathrm{E}</span> is.

  To verify the second claim let <span class='inline'>B\subset \mathrm{E}</span> be bounded and
  <span class='inline'>V\subset \mathrm{F}</span> a zero neighborhood. Then <span class='inline'>f^{-1} (V)</span> is a zero neighborhood
  in <span class='inline'>\mathrm{E}</span> by continuity of <span class='inline'>f</span>. Hence there exists an <span class='inline'>r\in \mathbb{R}_{\geq 0}</span>
  such that <span class='inline'>B \subset tf^{-1} (V)  </span> for all <span class='inline'>t\in R</span> with <span class='inline'>|t|\geq r</span>. By linearity
  of <span class='inline'>f</span> one obtains <span class='inline'>f(B) \subset tV</span> for all such <span class='inline'>t</span>, so <span class='inline'>f</span> is bounded. 


<br><br><strong>Remark 15.16</strong>
  By the proposition continuity of a linear map between topological vector spaces
  implies the map to be bounded. As we will see later in this monograph,
  the converse does in general not hold true unless the underlying
  topological vector spaces are for example normable. 
<br><br>

</p><h2>Normed real division algebras and local convexity</h2><p>\addcontentslinetocsubsectionNormed real division algebras and local convexity

<br><br><strong>15.17</strong>
We give valued division rings <span class='inline'>(R,|\cdot|)</span> which carry the structure of an <span class='inline'>\mathbb{R}</span>-algebra such that
for all <span class='inline'>r\in \mathbb{R}</span> and <span class='inline'>x\in R</span>
<br><br><span class='display'>
         | rx | = |r|_\infty\cdot |x| 
</span><br>
a particular name and call them  <i>normed real division algebras</i>. Since <span class='inline'>\mathbb{R}</span> with its standard absolute value
is archimedean, so is every normed real division algebra. By the Frobenius theorem, <dt-cite key="FroLSBF"></dt-cite>,
there exist only three finite dimensional real division algebras,
namely the field of real numbers <span class='inline'>\mathbb{R}</span>, the field of complex numbers <span class='inline'>\mathbb{C}</span>, and the quaternions <span class='inline'>\H</span>. 

<br><br><strong>Definition 15.18</strong>
  Under the assumption that <span class='inline'>R</span> is a normed real division algebra one calls a subset <span class='inline'>C\subset \mathrm{E}</span> of an <span class='inline'>R</span>-vector space
  
  </p><ol class='enumeration'>

  <li value='(I)'>
    <i>convex</i> if <span class='inline'>tv + (1-t)w \in C</span> for all <span class='inline'>v,w \in C</span> and <span class='inline'>t \in \mathbb{K}</span> with <span class='inline'>0\leq t \leq 1</span>,
  </li><li value='(II)'>
    <i>absolutely convex</i> if <span class='inline'>tv + sw \in C</span> for all <span class='inline'>v,w \in C</span> and <span class='inline'>t,s \in R</span> such that
     <span class='inline'>|t|+|s|\leq 1</span>, 
  </li><li value='(III)'> 
     a <i>cone</i> if <span class='inline'>tv \in C</span> for all <span class='inline'>v\in C</span> and <span class='inline'>t \in \mathbb{K}</span> with <span class='inline'>0\leq t \leq 1</span>. 
  
  </li></ol><p>

<br><br>

<br><br><strong>Lemma 15.19</strong>
  Let <span class='inline'>R</span> be a normed real division algebra. A subset <span class='inline'>C</span> of an
  <span class='inline'>R</span>-vector space <span class='inline'>\mathrm{E}</span> then is  absolutely convex if and only
  if it is circled and convex.  
<br><br>

<br><i>Proof.</i>
   The claim is trivial when <span class='inline'>C=\emptyset</span>, so we  assume that <span class='inline'>C</span> is nonempty. 

   Let <span class='inline'>C</span> be absolutely convex. Since <span class='inline'>C</span> contains at least one element <span class='inline'>v</span> 
   one has <span class='inline'>0 = 0 \cdot v + 0 \cdot v \in C</span>. Hence 
   <span class='inline'> tv =  (1-|t|) \cdot 0  + t v \in C</span> for all <span class='inline'>v\in C</span> and <span class='inline'>t\in R</span> with <span class='inline'>|t|\leq 1</span>.
   So <span class='inline'>C</span> is circled. By definition of absolute convexity <span class='inline'>C</span> is convex.

   If <span class='inline'>C</span> is circled and convex, then it contains with elements <span class='inline'>v,w</span> also <span class='inline'>t v + s w</span> 
   if <span class='inline'>|t| + |s|\leq 1</span>. To see this observe first that <span class='inline'>\tau v \in C</span> and <span class='inline'>\sigma w \in C</span>  
   where the elements <span class='inline'>\tau,\sigma \in R </span> have been chosen so that 
   <span class='inline'>|\tau|=|\sigma|=1</span>, <span class='inline'>t = |t|  \cdot\tau</span> and <span class='inline'>s = |s|  \cdot\sigma</span>. Now if <span class='inline'>|t| + |s| =0</span>, then
   <span class='inline'>t v + s w = 0 \in C</span> since <span class='inline'>C</span> is circled. If <span class='inline'>|t| + |s|  >  0</span>, then
   <br><br><span class='display'>
    t v + s w = 
    (|t| + |s|) \left( \frac{|t|}{|t|+|s|} \tau v  +  \frac{|s|}{|t|+|s|} \sigma w\right) \in C
   </span><br>
   since <span class='inline'>C</span> is convex and circled. Hence <span class='inline'>C</span> is absolutely convex.


<br><br><strong>Lemma 15.20</strong>
  A linear map <span class='inline'>f:\mathrm{E} \to \mathrm{F}</span> between vector spaces over a normed
  real divison algebra <span class='inline'>R</span> maps convex sets to convex sets,
  absolutely convex sets to absolutely convex sets, and cones to cones.
<br><br>

<br><i>Proof.</i>
  This an immediate consequence of the linearity of <span class='inline'>f</span>.


<br><br><strong>Lemma 15.21</strong>

  Let <span class='inline'>\mathrm{E}</span> be a \textt.v.s.~over a normed real division algebra <span class='inline'>R</span>, let <span class='inline'>C,D \subset \mathrm{E}</span> be convex 
  and <span class='inline'>r \in R</span>. Then the following holds true.
  
  </p><ol class='enumeration'>

  <li value='(I)'>
    The closure <span class='inline'>\widebar{C}</span> and the interior <span class='inline'>\mathring{C}</span> are convex.
  </li><li value='(II)'>
    The sets <span class='inline'>C + D</span> and <span class='inline'>rC</span> are convex.
  </li><li value='(III)'>
    If <span class='inline'>C</span> is absolutely convex, then so are <span class='inline'>\widebar{C}</span>  and <span class='inline'>\mathring{C}</span>.
  
  </li></ol><p>
 
<br><br>

<br><i>Proof.</i>
  We consider only the cases <span class='inline'>C,D\neq \emptyset</span> because otherwise the claim is trivial.
  
  </p><ol class='enumeration'>

  <li value='\itshape ad (\itshape I\hspace1pt). '>
    Let <span class='inline'>t\in  {\ltsbrak 0,1 \rtsbrak} </span>. Then <span class='inline'>t \widebar{C} + (1-t)\widebar{C} \subset \widebar{C} </span>
    by continuity of the map <span class='inline'>\mathrm{E} \times \mathrm{E} \to \mathrm{E}</span>, <span class='inline'>(v,w) \mapsto tv +(1-t)w</span>. 
    Hence <span class='inline'>\widebar{C}</span> is convex. Now let <span class='inline'>v,w</span> be points of the interior of <span class='inline'>C</span> and <span class='inline'> z =tv + (1-t)w</span>.
    Then <span class='inline'>z\in C</span>, and there exists a zero neighborhood <span class='inline'>U</span> such that <span class='inline'>v+U \subset C</span> and <span class='inline'>w+U\subset C</span>. 
    Let <span class='inline'>u\in U</span> and compute
    <br><br><span class='display'>
       z + u = tv + (1-t)w + tu + (1-t)u = t(v+u) +  (1-t)(w+u) .
    </span><br>
    Since both <span class='inline'>v+u</span> and <span class='inline'>w+u</span> are elements of <span class='inline'>C</span> so is <span class='inline'>z+u</span> by convexity of <span class='inline'>C</span>.
    Hence <span class='inline'>z +U \subset C</span> and <span class='inline'>z</span> lies in the interior of <span class='inline'>C</span>.  
  </li><li value='\itshape ad (\itshape II\hspace1pt). '>
    If <span class='inline'>v,w \in C</span>, <span class='inline'>x,y\in D</span> and <span class='inline'>t\in  {\ltsbrak 0,1 \rtsbrak} </span>, then by convexity of <span class='inline'>C</span> and <span class='inline'>D</span>
    <br><br><span class='display'>
       t(v+x) + (1-t) (w+y) = \big( tv +(1-t) w \big) +  \big( tx +(1-t) y  \big) \in C + D . 
    </span><br>
    Hence  <span class='inline'>C+D</span> is convex. Similarly,
    <br><br><span class='display'>
       t (rv) + (1-t) (rw) = r \big(  t v + (1-t) w \big) \in r C ,
    </span><br>
    so <span class='inline'>rC</span> is convex as well.
  </li><li value='\itshape ad (\itshape III\hspace1pt). '>
    Let <span class='inline'>C</span> be absolutely convex. If <span class='inline'>\mathring{C}\neq \emptyset</span>, then
    <span class='inline'>0\in \frac 12 \mathring{C} - \frac 12 \mathring{C} \subset C</span>, hence <span class='inline'>0 \in \mathring{C}</span>.
    By \Crefthm:closure-interior-circled-set-circled and (I)
    the claim now follows. 
  
  </li></ol><p>
 


<br><br><strong>Proposition and Definition 15.22</strong>
  The intersection of a non-empty family <span class='inline'>(C_i)_{i\in I}</span> of convex (respectively absolutely convex) subsets
  <span class='inline'>C_i \subset \mathrm{E}</span>, <span class='inline'>i\in I</span> of a topological vector space <span class='inline'>\mathrm{E}</span> over a normed real division algebra <span class='inline'>R</span>
  is convex (respectively absolutely convex).
  In particular, if <span class='inline'>A \subset \mathrm{E}</span> is a subset, then the sets
  <br><br><span class='display'>
    \operatorname{Conv} A = \bigcap\limits_{A \subset B \subset \mathrm{E} \atop {B \text{ is convex}} }  B \quad \text{and} \quad
    \operatorname{AConv} A = \bigcap\limits_{A \subset B \subset \mathrm{E} \atop {B \text{ is absolutely convex}} }  B
  </span><br>
  are convex and absolutely convex, respectively. The set <span class='inline'>\operatorname{Conv} A</span> is called the <i>convex hull</i> of <span class='inline'>A</span>
  and is the smallest convex set containing <span class='inline'>A</span>. Similarly, <span class='inline'>\operatorname{AConv} A</span> is the smallest absolutely convex set
  containing <span class='inline'>A</span>. It is called the  <i>absolutely convex hull</i> of <span class='inline'>A</span>.
  The <i>closed convex hull</i> <span class='inline'>\overline{\operatorname{Conv}}\, A</span> and the <i>closed absolutely convex hull</i> <span class='inline'>\overline{\operatorname{AConv}}\, A</span>
  of <span class='inline'>A</span> are defined by  
  <br><br><span class='display'>
    \overline{\operatorname{Conv}}\, A = \bigcap\limits_{A \subset B = \widebar{B} \subset \mathrm{E} \atop {B \text{ is convex}} }  B
    \quad \text{and} \quad
    \overline{\operatorname{AConv}}\, A = \bigcap\limits_{A \subset B = \widebar{B} \subset \mathrm{E} \atop {B \text{ is absolutely convex}} }  B .
  </span><br>
  These sets have the property that <span class='inline'>\overline{\operatorname{Conv}}\, A</span> is the smallest closed convex subset
  and <span class='inline'>\overline{\operatorname{AConv}}\, A</span> the smallest closed absolutely convex subset of <span class='inline'>\mathrm{E}</span> containing <span class='inline'>A</span>.
<br><br>

<br><i>Proof.</i>
  Let <span class='inline'>C</span> be the intersection <span class='inline'>\bigcap\limits_{i\in I} C_i</span> and assume that each <span class='inline'>C_i</span> is absolutely convex.
  Let <span class='inline'>v,w\in C</span> and <span class='inline'>s,t \in R</span>. Then <span class='inline'>v,w\in C_i</span>, hence  <span class='inline'>tv + sw \in C_i</span> for all <span class='inline'>i\in I</span>. Therefore
  <span class='inline'>tv +sw \in C</span> and <span class='inline'>C</span> is absolutely convex. This argument also shows that <span class='inline'>C</span> is convex if all <span class='inline'>C_i</span> are convex.
  The rest of the claim follows as in the proof  of \Crefthm:symmetric-circled-hulls.


<br><br><strong>Remark 15.23</strong>
  The proposition in particular entails that <span class='inline'>A</span> is convex if and only if <span class='inline'>\operatorname{Conv} A = A</span> and
  absolutely convex if and only if <span class='inline'>\operatorname{AConv} A = A</span>. Analogously,
  <span class='inline'>\overline{\operatorname{Conv}}\, A = A</span> if and only if <span class='inline'>A</span> is closed and convex,
  and <span class='inline'>\overline{\operatorname{AConv}}\, A = A</span> if and only if <span class='inline'>A</span> is closed and absolutely convex. 
<br><br>

<br><br><strong>Lemma 15.24</strong>
  Let <span class='inline'>A \subset \mathrm{E}</span> be a non-empty subset of a \textt.v.s.~<span class='inline'>\mathrm{E}</span>
  over a normed real division algebra <span class='inline'>R</span>. Then
  <br><br><span class='display'> \tag{15.4}
    
     \operatorname{Conv} A  = \left\{ \sum_{i=1}^k t_i v_i\in
    \mathrm{E} \bigm\vert k \in \mathbb{N}_{ >  0},\: v_1,\ldots v_k\in A,\: t_1\ldots ,t_k \in \mathbb{R}_{\geq 0}, \: \sum_{i=1}^k t_i = 1 \right\} 
      , </span><br><br><span class='display'>
    
     \operatorname{AConv} A  = \left\{ \sum_{i=1}^k t_i v_i\in
    \mathrm{E} \bigm\vert k \in \mathbb{N}_{ >  0},\: v_1,\ldots v_k\in A,\: t_1\ldots ,t_k \in R, \: \sum_{i=1}^k |t_i| \leq 1 \right\}
    .   
  </span><br><br>
  For the closed hulls one has  
  <br><br><span class='display'>
    \overline{\operatorname{Conv}}\, A = \overline{\operatorname{Conv} A} \quad \text{and} \quad \overline{\operatorname{AConv}}\, A = \overline{\operatorname{AConv} A} .
  </span><br>
  Finally, if <span class='inline'>A</span> is circled, then
  <br><br><span class='display'>
     \operatorname{AConv} A = \operatorname{Conv} A  .
  </span><br>
<br><br>

<br><i>Proof.</i>
  By definition, the right hand side of Eq.~\eqrefeq:convex-hull-expression is convex and contains <span class='inline'>A</span>,
  hence it contains <span class='inline'>\operatorname{Conv} A</span>. Conversely, one shows by induction on <span class='inline'>k\in \mathbb{N}_{ >  0}</span> and convexity of <span class='inline'>\operatorname{Conv} A</span>
  that each element of the form <span class='inline'>\sum_{i=1}^k t_i v_i</span> with <span class='inline'>v_1,\ldots , v_k\in A</span> and
  <span class='inline'>t_1,\ldots ,t_k \in \mathbb{R}_{\geq 0}</span>  such that <span class='inline'>\sum_{i=1}^k t_i = 1</span> is in  <span class='inline'>\operatorname{Conv} A</span>. This proves
  Eq.~\eqrefeq:convex-hull-expression.
  The proof of Eq.~\eqrefeq:absolutely-convex-hull-expression is similar. Observe that the right hand side of
  Eq.~\eqrefeq:absolutely-convex-hull-expression is absolutely convex and contains <span class='inline'>A</span>.
  Hence it contains <span class='inline'>\operatorname{AConv} A</span>. An argument using induction on <span class='inline'>k\in \mathbb{N}_{ >  0}</span> and absolute convexity of
  <span class='inline'>\operatorname{AConv} A</span> shows that each element of the form <span class='inline'>\sum_{i=1}^k t_i v_i</span> with <span class='inline'>v_1,\ldots v_k\in A</span> and
  <span class='inline'>t_1\ldots ,t_k \in R</span>  such that <span class='inline'>\sum_{i=1}^k |t_i| \leq 1</span> is in  <span class='inline'>\operatorname{Conv} A</span>.
  So Eq.~\eqrefeq:absolutely-convex-hull-expression holds true as well. 
  The claim about the closed hulls is a consequence of \Crefthm:closure-interior-convex-set-convex.
  For the proof of the last claim it suffices to show that <span class='inline'>\operatorname{Conv} A</span> is circled if <span class='inline'>A</span> is.
  To this end let <span class='inline'>v \in \operatorname{Conv} A</span>  and <span class='inline'>t\in R</span> with <span class='inline'>|t|\leq 1</span>. Then
  one can write <span class='inline'>v</span> in the form <span class='inline'>v = \sum_{i=1}^k t_i v_i</span> with
  <span class='inline'>v_1,\ldots, v_k\in A</span> and <span class='inline'>t_1, \ldots ,t_k \in \mathbb{R}_{\geq 0}</span>, where <span class='inline'>\sum_{i=1}^k t_i = 1</span>.
  Hence <span class='inline'>rv =  \sum_{i=1}^k t_i (rv_i)</span>, which is in <span class='inline'>\operatorname{Conv} A</span>, since <span class='inline'>rv_i\in A</span> for all <span class='inline'>i</span> because
  <span class='inline'>A</span> is circled. 


<br><br><strong>Lemma 15.25</strong>
  Let <span class='inline'>A \subset \mathrm{E}</span> be a non-empty subset of a \textt.v.s.~<span class='inline'>\mathrm{E}</span>
  over a normed real division algebra <span class='inline'>R</span>. 
  
  </p><ol class='enumeration'>

  <li value='(I)'>
    If <span class='inline'>A</span> is convex and <span class='inline'>t_1,\ldots, t_k\in \mathbb{R}_{\geq 0}</span> with <span class='inline'>k\in \mathbb{N}_{ >  0}</span>, then
    <br><br><span class='display'>
       \sum_{i=1}^k t_iA = \left( \sum_{i=1}^k t_i \right) A .
    </span><br>
  </li><li value='(II)'>
    If <span class='inline'>A</span> is absolutely convex and <span class='inline'>t_1,\ldots, t_k\in R</span> with <span class='inline'>k\in \mathbb{N}_{ >  0}</span>, then
    <br><br><span class='display'>
       \sum_{i=1}^k t_iA = \left( \sum_{i=1}^k |t_i| \right) A .
    </span><br>   
  
  </li></ol><p>

<br><br>

<br><i>Proof.</i>
  
  </p><ol class='enumeration'>

  <li value='\itshape ad (\itshape I\hspace1pt). '>
    Obviously <span class='inline'>\sum_{i=1}^k t_iA \supset \left( \sum_{i=1}^k t_i \right) A</span>. Let us show the converse  inclusion.
    Without loss of generality we can assume that <span class='inline'>t_i  >  0</span> for all <span class='inline'>i</span>. Then <span class='inline'>t = \sum_{i=1}^k t_i  > 0</span>,
    so, after division by <span class='inline'>t</span>, we can reduce the claim to showing that
    <span class='inline'>\sum_{i=1}^k t_iA \subset A</span> for <span class='inline'>t_1,\ldots , t_k\in \mathbb{R}_{ > 0}</span> such that <span class='inline'> \sum_{i=1}^k t_i =1</span>.
    But <span class='inline'>\sum_{i=1}^k t_iA \subset \operatorname{Conv} A = A</span> by
    \Crefthm:representation-convex-absolutely-convex-hulls-closures and convexity of <span class='inline'>A</span>. 
  Let <span class='inline'>A \subset \mathrm{E}</span> be a non-empty subset of a \textt.v.s.~<span class='inline'>\mathrm{E}</span>
  </li><li value='\itshape ad (\itshape II\hspace1pt). '>
    Since by absolute convexity <span class='inline'>t_i A = |t_i|A</span> for <span class='inline'>i=1,\ldots,k</span>, the claim follows by
    (I).
 \mbox 
  
  </li></ol><p>



<br><br><strong>Lemma 15.26</strong>
  Let <span class='inline'>\mathbb{K}</span> be one of the division rings <span class='inline'>\mathbb{C}</span> or <span class='inline'>\H</span> with their standard absolute values
  and let <span class='inline'>\mathrm{E}</span> be a vector space over <span class='inline'>\mathbb{K}</span>. Then a convex subset <span class='inline'>C\subset \mathrm{E}</span> is
  absorbent in <span class='inline'>\mathrm{E}</span> if and only if it is absorbent in the realification <span class='inline'>\mathrm{E}^\mathbb{R}</span>.
<br><br>

<br><i>Proof.</i>
  It suffices to show the non-trivial direction. So assume that <span class='inline'>C</span> is convex and absorbent in the
  realification <span class='inline'>\mathrm{E}^\mathbb{R}</span>. Denote by <span class='inline'>u_1,\ldots , u_n</span>  the standard basis of <span class='inline'>\mathbb{K}</span>
  over <span class='inline'>\mathbb{R}</span> with <span class='inline'>n=2</span> or <span class='inline'>n=4</span> depending on <span class='inline'>\mathbb{K}</span>. In particular this means <span class='inline'>u_1 =1</span>.
  For given <span class='inline'>v\in\mathrm{E}</span> there now exists <span class='inline'>r\in\mathbb{R}_{\geq 0}</span> such that
  <br><br><span class='display'>
    \pm \frac{1}{u_1} v , \ldots  , \pm \frac{1}{u_n} v \in tC \quad \text{for all } t\geq r .
  </span><br>   
  Without loss of generality we can assume <span class='inline'>r\geq 1</span>. Let <span class='inline'>z\in \mathbb{K}</span> with <span class='inline'>|z| \geq n r</span>. 
  Then the vectors
  <span class='inline'>c_1 = \operatorname{sgn} z_1\frac{n}{|z| \, u_1} v, \ldots , c_n = \operatorname{sgn} z_n\frac{n}{|z| \, u_n} v</span>
  are elements of <span class='inline'>C</span>. By convexity of <span class='inline'>C</span> and since <span class='inline'>0\in C</span> one has
  <span class='inline'> \frac{|z_1|}{|z|} c_1 , \ldots , \frac{|z_n|}{|z|} c_n  \in C</span>. Again by convexity one concludes
  <br><br><span class='display'>
    \frac{1}{z} v = \sum_{i=1}^n \frac{z_i}{|z|^2 \, u_i} v =
    \sum_{i=1}^n  \frac{|z_i|}{n |z|} c_i \in C . 
  </span><br>
  Hence <span class='inline'>C</span> is absorbing and the claim is proved.   


<br><br><strong>Definition 15.27</strong>
  A topological vector space <span class='inline'>\mathrm{E}</span> over a normed real division algebra <span class='inline'>R</span> for which
  Axiom \hyperref[axiom:tvs-local-convexity]LCVS below holds true is called a
  <i>locally convex topological vector space</i>, a <i>locally convex vector space</i> or shortly a
  <i>locally convex \textt.v.s.</i>
  </p><ol class='enumeration'>
    <li value='{(}{\sffamily LCVS}{)}\!'>
   
    The vector space topology on <span class='inline'>\mathrm{E}</span> is <i>locally convex</i> that is it has a base consisting of convex sets. 
  </li></ol><p>
<br><br>

<br><br><strong>Remark 15.28</strong>
  For better readability, we often say <i>locally convex topology</i> instead of <i>locally convex vector space topology</i>.
<br><br>

<br><br><strong>Proposition 15.29</strong>
  The locally convex topological vector spaces over a normed real division algebra <span class='inline'>R</span> together with the continuous
  linear maps between them form a full subcategory of the category <span class='inline'>R\text{-}\mathsf{TVS}</span> of topological
  <span class='inline'>R</span>-vector spaces. It is denoted <span class='inline'>R\text{-}\mathsf{LCVS}</span>.
<br><br>
<br><i>Proof.</i>
  This is clear by definition.


<br><br><strong>Proposition and Definition 15.30</strong>
  The filter of zero neighborhoods of a locally convex topological vector space <span class='inline'>\mathrm{E}</span> over a
  normed real divison algebra <span class='inline'>R</span> has a filter base <span class='inline'>\mathscr{B}</span> with the following properties:
  
  </p><ol class='enumeration'>

  <li value='(I)'>
    For each <span class='inline'>V \in \mathscr{B}</span> there exists <span class='inline'>U\in\mathscr{B}</span> such that <span class='inline'>U+U \subset V</span>.
  </li><li value='(II)'>
    Every element of <span class='inline'>\mathscr{B}</span> is a <i>barrel</i> that means is absolutely convex, closed and absorbing.
  </li><li value='(III)'>
    Let  <span class='inline'>t\in R^\times</span>. Then <span class='inline'>V\in \mathscr{B}</span> if and only if <span class='inline'>tV \in \mathscr{B}</span>. 
  
  </li></ol><p>

  Conversely, if  <span class='inline'>\mathscr{B}</span> is a filter base on an <span class='inline'>R</span>-vector space <span class='inline'>\mathrm{E}</span> such that
  ref_error holds true and such that each
  element of <span class='inline'>\mathscr{B}</span> is absolutely convex and absorbing, then there exists a unique locally
  convex vector space topology on <span class='inline'>\mathrm{E}</span>  such that <span class='inline'>\mathscr{B}</span> is a neighborhood base
  at the origin. One calls this topology the <i>locally convex topology generated by</i>  <span class='inline'>\mathscr{B}</span>.
<br><br>

<br><i>Proof.</i>
  Let <span class='inline'>\mathrm{E}</span> be a locally convex \textt.v.s.Let <span class='inline'>\mathscr{B}</span> be the collection of all barrels 
  which are at the same time zero neighborhoods. Let <span class='inline'>V</span> be an element of <span class='inline'>\mathscr{U}_0</span>,
  the filter of zero neighborhoods. Since <span class='inline'>\mathrm{E}</span> is \textsf(T3) by
  \Crefthm:basic-properties-sets-maps-topological-vector-spaces, there exists a closed
  zero neighborhood <span class='inline'>V_a</span> such that <span class='inline'>V_a \subset V </span>.  By local convexity of <span class='inline'>\mathrm{E}</span> there exists
  a convex zero neighborhood <span class='inline'>V_b</span> with <span class='inline'>V_b\subset V_a</span>. By
  \Crefthm:topological-vector-space-zero-neighborhood-filter-base-circled-absorbing there exists a circled
  zero neighborhood <span class='inline'>V_c</span> with <span class='inline'>V_c\subset V_b</span>.  The closed convex hull <span class='inline'>U = \overline{\operatorname{Conv}}\, V_c</span> then is 
  a barrel contained in <span class='inline'>V</span>. Since it is a zero neighborhood it is an element of <span class='inline'>\mathscr{B}</span>, and <span class='inline'>\mathscr{B}</span>
  is a filter base of <span class='inline'>\mathscr{U}_0</span>.
  
  To verify (I), let <span class='inline'>V \in \mathscr{B}</span> and observe that
  by continuity of addition there exist zero neighborhoods <span class='inline'>U_1</span> and <span class='inline'>U_2</span> such that <span class='inline'>U_1 + U_2 \subset V</span>.
  Choose <span class='inline'>U\in \mathscr{B} </span> such that <span class='inline'>U \subset U_1\cap U_2</span>. Then <span class='inline'>U + U \subset V</span>.

  Claim (III) holds true since multiplication
  by an element <span class='inline'>t\in R^\times</span> is a homeomorphism which preserves circled and convex sets.

  The remaining claim follows immediately from
  \Crefthm:topological-vector-space-zero-neighborhood-filter-base-circled-absorbing
  and the observation that a real division algebra is archimedean.


<br><br><strong>Corollary 15.31</strong>
  Let  <span class='inline'>\mathscr{S}</span> be a non-empty set of absolutely convex and absorbent subsets of an vector space <span class='inline'>\mathrm{E}</span>
  over a normed real divison algebra <span class='inline'>R</span>.
  Then the set
  <br><br><span class='display'>
    \mathscr{B} = \Big\{ t\, \bigcap\limits_{B\in\mathscr{F}} B \in\mathscr{P}(\mathrm{E}) \bigm\vert
    \mathscr{F}\subset \mathscr{S}\text{ finite, } \mathscr{F} \neq \emptyset \:\: \ \:\: t > 0 
    \Big\}
  </span><br>
  is a base of the filter of zero neighborhoods of a  locally convex topology
  <span class='inline'>\mathscr{T}</span> on <span class='inline'>\mathrm{E}</span>. This topology is uniquely determined by that property and the coarsets among all
  vector space topologies for which  <span class='inline'>\mathscr{S}</span> is a set of zero neighborhoods. The topology <span class='inline'>\mathscr{T}</span> is called the
  <i>locally convex topology generated</i> by <span class='inline'>\mathscr{S}</span>. 
<br><br>
</p><h1>16 Seminorms and gauge functionals</h1><p>

<br><br><strong>16.1</strong> Throughout the rest of this chapter the symbol <span class='inline'>\mathbb{K}</span> will always
stand for the field of real numbers <span class='inline'>\mathbb{R}</span>, the field of complex numbers <span class='inline'>\mathbb{C}</span> or the
division algebra of quaternions <span class='inline'>\H</span>. We assume these division algebras to be equipped
with their standard absolute values <span class='inline'>|\cdot |</span>.
Moreover, vector spaces are assumed to be defined over the ground field <span class='inline'>\mathbb{K}</span>
unless mentioned differently and are always assumed to be left vector spaces. 

</p><h2>Seminorms and induced vector space topologies</h2><p>\addcontentslinetocsubsectionSeminorms and induced vector space topologies
<br><br><strong>Definition 16.2</strong>
  By a <i>seminorm</i> on a vector space <span class='inline'>\mathrm{E}</span> one 
  understands a map <span class='inline'>p:\mathrm{E} \to \mathbb{R}</span> with the following properties:
  </p><ol class='enumeration'>
  \setcounterenumi-1  
  <li value=' (N1)'>
    The  map <span class='inline'>p</span> is <i>positive</i> that is <span class='inline'>p(v)\geq 0</span> for all <span class='inline'>v\in \mathrm{E}</span>.
  </li><li value=' (N2)'>
   
     The map <span class='inline'>p</span> is <i>absolutely homogeneous</i> that means
     <br><br><span class='display'>
       p(r v) = |r| \, p(v)  \quad \text{for all $v \in \mathrm{E}$ and $r\in \mathbb{K}$}.
     </span><br>
  </li><li value=' (N3)'>
   
     The map <span class='inline'>p</span> is <i>subadditive</i> or in other words satisfies the <i>triangle inequality</i> 
     <br><br><span class='display'> 
       p(v+w) \leq p(v) + p(w) \quad \text{for all $v,w \in \mathrm{E}$}.
     </span><br> 
  </li></ol><p>
  A seminorm is called a <i>norm</i> if in addition the following axiom is satisfied:
  </p><ol class='enumeration'>
  \setcounterenumi2
  <li value=' (N1)'>  
     For all <span class='inline'>v\in \mathrm{E}</span> the relation <span class='inline'>p(v) = 0</span> holds true if and only if <span class='inline'>v = 0</span>.
  </li></ol><p>
  A vector space <span class='inline'>\mathrm{E}</span> equipped with a norm 
  <span class='inline'>\| \cdot \| : \mathrm{E} \to \mathbb{R}_{\geq 0}</span> is called a <i>normed vector space</i>.
    <br><br>

<br><br><strong>16.3</strong>
 Let us introduce some useful further properties a map <span class='inline'>p:\mathrm{E} \to \mathbb{R}</span>
 can have.  One calls such a map <span class='inline'>p</span>
 </p><ol class='enumeration'>
 <li value=' (1)'>
   <i>positively homogeneous</i> if <span class='inline'>p (tv) = t\, p(v)</span> for all <span class='inline'>t\in \mathbb{R}_{ >  0}</span> and all <span class='inline'>v\in \mathrm{E}</span>,
 </li><li value=' (2)'>
   <i>sublinear</i> if <span class='inline'>p (tv + sw) \leq  t\, p(v) + s\, p(w)</span> for all <span class='inline'>t,s\in \mathbb{R}_{\geq 0}</span>
   and all <span class='inline'>v,w\in \mathrm{E}</span>, and 
 </li><li value=' (3)'>
   <i>convex</i> if <span class='inline'>p (tv + sw) \leq  t\, p(v) + s\, p(w)</span> for all <span class='inline'>t,s\in \mathbb{R}_{\geq 0}</span>
   with <span class='inline'>t+s=1</span> and all <span class='inline'>v,w\in \mathrm{E}</span>.
 </li></ol><p>

<br><br><strong>Lemma 16.4</strong>
   For a real-valued map <span class='inline'>p:\mathrm{E} \to \mathbb{R}</span> on a vectorspace <span class='inline'>\mathrm{E}</span> the following are equivalent:
   
  </p><ol class='enumeration'>

   <li value='(I)'>
     <span class='inline'>p</span> is sublinear.
   </li><li value='(II)'>
     <span class='inline'>p</span> is positively homogeneous and convex.
   </li><li value='(III)'>
     <span class='inline'>p</span> is positively homogeneous and subadditive. 
   
  </li></ol><p>

 <br><br>
 <br><i>Proof.</i>
   Let <span class='inline'>p</span> be sublinear. Then <span class='inline'>p</span> is subadditive by definition. Subadditivity implies
   <span class='inline'>p(0) \leq p(0) + p(0)</span>, hence <span class='inline'>p(0)\geq 0</span>. 
   By sublinearity
   <br><br><span class='display'> p(0) = p(0\cdot 0 + 0\cdot 0) \leq 0 \cdot p(0) +  0\cdot p(0) =  0 , </span><br>
   so <span class='inline'>p(0)=0</span>.  We show that <span class='inline'>p</span> is positively homogeneous.
   Applying sublinearity again one checks for <span class='inline'>v\in \mathrm{E}</span> and <span class='inline'>t\geq 0</span> that
   <br><br><span class='display'> p(tv)=p(tv+ 0\cdot 0) \leq t p(v) + 0 \cdot p(0)= tp(v) , </span><br>
   so <span class='inline'>p</span> is positively homogeneous and the implication
   (I) <span class='inline'>\implies</span> (III) follows.
 If <span class='inline'>p</span> is positively homogeneous and subadditive, then for <span class='inline'>v,w \in \mathrm{E}</span> and
 <span class='inline'>t,s >  0</span> with <span class='inline'>t +s =1</span>
 <br><br><span class='display'>
     p(tv +sw) \leq p(tv) + p(sw) \leq t p(v) + s p(w),
 </span><br>  
 so <span class='inline'>p</span> is convex. This gives the implication
 (III) <span class='inline'>\implies</span> (II). 
 If <span class='inline'>p</span> is positively homogeneous and convex, then one computes for <span class='inline'>v,w \in \mathrm{E}</span> and <span class='inline'>t,s\geq 0</span>
 with <span class='inline'>t+s  > 0</span>
 <br><br><span class='display'>
   p( tv +sw )  =    (t+s)\, p \left( \frac{t}{t+s} v+ \frac{s}{t+s} w \right) \leq
   (t+s) \left( \frac{t}{t+s} p(v) +  \frac{s}{t+s} p(w) \right) = t p(v)+ sp(w) .
 </span><br>
 Since <span class='inline'>p(0)=\lim\limits_{t\searrow 0} p(t0) = \lim\limits_{t\searrow 0} t\, p(0) = 0</span> by positive homogeneity,
 <span class='inline'>p</span> then has to be sublinear and one obtains the implication
 (II)  <span class='inline'>\implies</span> (I).

 
 
 <br><br><strong>Lemma 16.5</strong>
   Let <span class='inline'>p:\mathrm{E} \to \mathbb{R}</span> be a real-valued map defined on a vectorspace <span class='inline'>\mathrm{E}</span> over <span class='inline'>\mathbb{K}</span>.
   
  </p><ol class='enumeration'>

   <li value='(I)'>
     If <span class='inline'>p:\mathrm{E} \to \mathbb{R}</span> is   positively homogeneous, then <span class='inline'>p(0)=0</span>.
   </li><li value='(II)'>
     If <span class='inline'>p:\mathrm{E} \to \mathbb{R}</span> is subadditive, then <span class='inline'>p(0)\geq 0</span> and for all <span class='inline'>v,w\in \mathrm{E}</span>
     <br><br><span class='display'>
       |p(v)-p(w)| \leq \max \{ p(v-w),p(w-v) \} .
     </span><br>
   </li><li value='(III)'>
     If <span class='inline'>p:\mathrm{E} \to \mathbb{R}</span> is convex, then the sets
     <span class='inline'>\mathbb{B}_p (0,\varepsilon) := \{v\in \mathrm{E}\mid p(v)  <  \varepsilon\} </span> and
     <span class='inline'>\overline{\mathbb{B}}_p (0,\varepsilon) := \{v\in \mathrm{E}\mid p(v) \leq \varepsilon\}</span> are convex for all <span class='inline'>\varepsilon  > 0</span>.
   </li><li value='(IV)'>
     If <span class='inline'>p</span> is sublinear, then <span class='inline'>\mathbb{B}_p (0,\varepsilon)</span> and <span class='inline'>\overline{\mathbb{B}}_p (0,\varepsilon)</span> are convex and
     absorbent for all <span class='inline'>\varepsilon  > 0</span>.
   
  </li></ol><p>

 <br><br>
 <br><i>Proof.</i>
   
  </p><ol class='enumeration'>

   <li value='\itshape ad (\itshape I\hspace1pt). '>
     As already observed, <span class='inline'>p(0)=\lim\limits_{t\searrow 0} p(t0) = \lim\limits_{t\searrow 0} t\, p(0) = 0</span>.
   </li><li value='\itshape ad (\itshape II\hspace1pt). '>
    Note that by subadditivity
     <br><br><span class='display'>
       p(0)\leq p(0) + p(0), \quad  p(v) -p(w) \leq p(v-w), \quad \text{and} \quad
       p(w) -p(v) \leq p(w-v) .
     </span><br>
     This entails (II). 
   </li><li value='\itshape ad (\itshape III\hspace1pt). '>
     Let <span class='inline'>v,w\in \{v\in \mathrm{E}\mid p(v)  <  \varepsilon\}</span> and <span class='inline'>0\leq t \leq 1</span>. Then, by convexity of <span class='inline'>p</span>,
     <br><br><span class='display'>
         p\big(tv + (1-t)w\big) \leq t p(v) + (1-t) p(w) <  t\varepsilon + (1-t) \varepsilon = \varepsilon .
     </span><br>
     Hence <span class='inline'>tv + (1-t)w\in  \{v\in \mathrm{E}\mid p(v)  <  \varepsilon\} </span>.
     The proof for <span class='inline'>\{v\in \mathrm{E}\mid p(v) \leq \varepsilon\}</span> is analogous.
   </li><li value='\itshape ad (\itshape IV\hspace1pt). '>
     Convexity of the sets <span class='inline'>\mathbb{B}_p (0,\varepsilon)</span> and  <span class='inline'>\overline{\mathbb{B}}_p (0,\varepsilon)</span> holds by
     (III).
     Moreover, <span class='inline'>\mathbb{B}_p (0,\varepsilon) \subset \overline{\mathbb{B}}_p (0,\varepsilon)</span> by definition.
     Hence it suffices  by \Crefthm:real-absorbance-implies-arbsorbance-finite-dimensional-divison-algebra
     to show that <span class='inline'>\mathbb{B}_p (0,\varepsilon)</span> is absorbent in the realification <span class='inline'>\mathrm{E}^\mathbb{R}</span>. 
     Since <span class='inline'>p</span> is positively homogenous by \Crefthm:equivalent-characterizations-sublinearity and
     <span class='inline'>0\leq p(v) + p(-v)</span> for all <span class='inline'>v\in \mathrm{E}</span>, one concludes that for all <span class='inline'>t\in\mathbb{R}</span> and <span class='inline'>v\in \mathrm{E}</span>
     <br><br><span class='display'>
        |p(tv) | \leq |t|\max\{ p(v),p(-v) \} . 
     </span><br>
     Hence <span class='inline'>tv\in \mathbb{B}_p (0,\varepsilon)</span> if <span class='inline'>0  <  t  <  \frac{\varepsilon}{\max\{ p(v),p(-v) \} +1}</span>,
     and <span class='inline'>\mathbb{B}_p (0,\varepsilon)</span> is absorbent in <span class='inline'>\mathrm{E}^\mathbb{R}</span>.
   
  </li></ol><p>

 

<br><br><strong>Definition 16.6</strong>
  If <span class='inline'>p :\mathrm{E} \to \mathbb{R}</span> is a seminorm on a vector space <span class='inline'>\mathrm{E}</span>, we denote for every <span class='inline'>v \in \mathrm{E}</span>
  and <span class='inline'>\varepsilon  > 0</span>  by <span class='inline'>\mathbb{B}_p (v,\varepsilon)</span>   the  (<i>open</i>) <span class='inline'>\varepsilon</span>-<i>ball associated with</i> <span class='inline'>p</span> and
  <i>with center</i> <span class='inline'>v</span>  that is the set
  <br><br><span class='display'>
    \mathbb{B}_p (v,\varepsilon) = \big\{ w \in \mathrm{E} \bigm\vert p(w-v)  <  \varepsilon \big\} .
  </span><br>
  The  <i>closed</i> <span class='inline'>\varepsilon</span>-<i>ball associated with</i> <span class='inline'>p</span> and <i>with center</i> <span class='inline'>v</span>
  is defined as 
  <br><br><span class='display'>
    \overline{\mathbb{B}}_p (v,\varepsilon) = \big\{ w \in \mathrm{E} \bigm\vert p(w-v) \leq \varepsilon \big\} .
  </span><br>
  The positive number <span class='inline'>\varepsilon</span> is sometimes called the <i>radius</i> of the ball.
  When by the context it is clear which seminorm <span class='inline'>p</span> a ball is associated with 
  we often do not mention <span class='inline'>p</span> explicitely. This is in particular the case 
  when the underlying vector space is a normed vector space. 
  For the particular radius <span class='inline'>1</span> we denote the corresponding balls by 
  <span class='inline'>\mathbb{B}_p (v)</span> and  <span class='inline'>\overline{\mathbb{B}}_p (v)</span> and call them the <i>open</i> respectively <i>closed</i>
  <i>unit balls</i>.
  If <span class='inline'>P</span> is a finite set or a finite family of seminorms on <span class='inline'>\mathrm{E}</span> we define the 
  <i>open</i> and <i>closed</i> <span class='inline'>\varepsilon</span>-<i>multiballs with center</i> <span class='inline'>v</span> by 
  <br><br><span class='display'>
    \mathbb{B}_P (v,\varepsilon) =
    \big\{ w \in \mathrm{E}\bigm\vert p(w-v)  <  \varepsilon \text{ for all } p\in P\big\} 
  </span><br>
  and
   <br><br><span class='display'>
    \overline{\mathbb{B}}_P (v,\varepsilon) = \big\{ w \in \mathrm{E} \bigm\vert p(w-v) \leq \varepsilon 
    \text{ for all } p\in P \big\} ,
  </span><br>
  respectively.
<br><br>

<br><br><strong>Remark 16.7</strong>
  For convenience, we will also use the symbols <span class='inline'>\mathbb{B}_p (0,\varepsilon)</span> and <span class='inline'>\overline{\mathbb{B}}_p (0,\varepsilon)</span>
  to denote the sets <span class='inline'>\big\{ v \in \mathrm{E} \bigm\vert p(v)  <  \varepsilon \big\}</span>
  and <span class='inline'>\big\{ v \in \mathrm{E} \bigm\vert p(v) \leq \varepsilon \big\}</span>, respectively, when <span class='inline'>p:\mathrm{E} \to \mathbb{R}</span>
  is just a real-valued convex map on the vector space <span class='inline'>\mathrm{E}</span>. Note that for such a <span class='inline'>p</span> the
  set  <span class='inline'>\big\{ v \in \mathrm{E} \bigm\vert p(v)  <  0 \big\}</span> might be non-empty. But as we have shown in
  \Crefthm:properties-subadditive-convex-real-valued-maps-vector-space
  the sets <span class='inline'>\mathbb{B}_p (0,\varepsilon)</span> and <span class='inline'>\overline{\mathbb{B}}_p (0,\varepsilon)</span> associated to a convex <span class='inline'>p</span> share with the
  the balls associated to a seminorm several nice properties like convexity. 
<br><br>

<br><br><strong>Proposition 16.8</strong>
  Let <span class='inline'>\mathrm{E}</span> be a <span class='inline'>\mathbb{K}</span>-vector space, and <span class='inline'>P</span> a finite set of seminorms on <span class='inline'>\mathrm{E}</span>.
  Then, for every <span class='inline'>\varepsilon  > 0</span> and <span class='inline'>v\in \mathrm{E}</span>, the <span class='inline'>\varepsilon</span>-multiballs
  <span class='inline'>\mathbb{B}_P (v,\varepsilon)</span> and  <span class='inline'>\overline{\mathbb{B}}_P (v,\varepsilon)</span> are convex.
  The <span class='inline'>\varepsilon</span>-multiballs
  <span class='inline'>\mathbb{B}_P (0,\varepsilon)</span> and  <span class='inline'>\overline{\mathbb{B}}_P (0,\varepsilon)</span> are absolutely convex and absorbent. 
<br><br>
<br><i>Proof.</i>
  Axiom  (N2) immediately entails that <span class='inline'>\mathbb{B}_p (0,\varepsilon)</span> and  
  <span class='inline'>\overline{\mathbb{B}}_P (0,\varepsilon)</span> are circled. Axiom  (N3) 
  together with   (N2) entails that the sets 
  <span class='inline'>\mathbb{B}_p (v,\varepsilon)</span> and <span class='inline'>\overline{\mathbb{B}}_P (v,\varepsilon)</span> 
  are convex. Namely, if <span class='inline'>w_1, w_2 \in \mathbb{B}_p (v,\varepsilon)</span> 
  and <span class='inline'>t \in [0,1]</span>, then one has  for all seminorms <span class='inline'>p\in P</span>
  <br><br><span class='display'>
   p\left( tw_1 + (1-t) w_2 - v \right) \leq 
   t \,  p \left( w_1  - v \right) + (1-t) \, p \left(  w_2 - v \right)  <  
   t \, \varepsilon + (1-t) \, \varepsilon = \varepsilon 
  </span><br>
  and likewise <span class='inline'>p\left( tw_1 + (1-t) w_2 - v \right) \leq \varepsilon</span> for all
  <span class='inline'>w_1, w_2 \in \overline{\mathbb{B}}_P(v,\varepsilon)</span> and  <span class='inline'>p\in P</span>. 

  Now let <span class='inline'>v\in \mathrm{E}</span> and <span class='inline'>\varepsilon  > 0</span> be given. 
  Put <span class='inline'>t_p = \frac{p(v)+1}{\varepsilon}</span> for every <span class='inline'>p\in P</span> and <span class='inline'>t_0 = \max \{t_p\mid p\in P\}</span>. 
  Then one has for all <span class='inline'>t\in \mathbb{K}</span> with <span class='inline'>|t|\geq t_0</span> and for all <span class='inline'>p\in P</span>
  <br><br><span class='display'>
    p\left( \frac{1}{t} v \right) \leq \frac{\varepsilon}{p(v)+1} \, p(v)  <  \varepsilon ,
  </span><br> 
  hence <span class='inline'>v \in t \, \mathbb{B}_p (0,\varepsilon)</span>. So <span class='inline'>\mathbb{B}_p (0,\varepsilon)</span> is absorbing. 
  Since <span class='inline'>\overline{\mathbb{B}}_P (0,\varepsilon)</span>  contains the absorbing set <span class='inline'>\mathbb{B}_p (0,\varepsilon)</span>
  it is absorbing as well. 


<br><br><strong>Proposition and Definition 16.9</strong>
Assume to be given a set <span class='inline'>P</span> of seminorms on a vector space <span class='inline'>\mathrm{E}</span>.
Let <span class='inline'>\mathscr{F} (P)</span> be the collection of all finite subsets of <span class='inline'>P</span>. 
A topological base on <span class='inline'>\mathrm{E}</span> then is given by  
<br><br><span class='display'>
  \mathscr{B}_P = \big\{  \mathbb{B}_Q (v,\varepsilon)  \bigm\vert
  Q  \in \mathscr{F} (P) , \: v \in \mathrm{E} , \:  \varepsilon  > 0 \big\} . 
</span><br>
The topology generated by this base  is denoted <span class='inline'>\mathscr{T}_P</span> and called the topology 
<i>generated</i> or <i>defined</i> by <span class='inline'>P</span>. Moreover, <span class='inline'>\mathscr{T}_P</span> is a locally convex
vector space topology on <span class='inline'>\mathrm{E}</span>. 
<br><br>

<br><i>Proof.</i>
  We prove continuity of addition  first. Let <span class='inline'>v_1,v_2\in \mathrm{E}</span>, <span class='inline'>Q \in \mathscr{F} (P)</span>, and <span class='inline'>\varepsilon  > 0</span>.
  Since the triangle inequality holds for every seminorm in <span class='inline'>F</span>, one has
  <br><br><span class='display'>
    \mathbb{B}_Q \left(v_1,\frac\varepsilon 2\right) +   \mathbb{B}_Q \left(v_2,\frac\varepsilon 2\right)
    \subset \mathbb{B}_Q (v_1+v_2, \varepsilon) ,
  </span><br>
  which entails continuity of addition at each <span class='inline'>(v_1v_2) \in \mathrm{E} \times \mathrm{E}</span>.
  Next consider multiplication by scalars and let <span class='inline'>\lambda \in \mathbb{K}</span> and <span class='inline'>v\in \mathrm{E}</span>. 
  Again let <span class='inline'>Q= (p_j)_{j\in J} \in \mathscr{F} (P)</span> and <span class='inline'>\varepsilon  > 0</span>. 
  Let <span class='inline'>C_1 = \sup \{ p_j (v) \mid j \in J \} + 1</span> and <span class='inline'>C_2 = |\lambda| + 1</span> 
  and put <span class='inline'>\delta_1 = \min \{1,\frac{\varepsilon}{2 \, C_1}  \}</span>
  and <span class='inline'>\delta_2 = \frac{\varepsilon}{2 \, C_2}</span>.  
  Then one obtains by absolute homogeneity and subadditivity of each seminorm 
  <br><br><span class='display'>
    p_j ( \mu w -\lambda v) \leq | \mu | \, p_j( w-v) + | \mu -\lambda| \, p_j(v) \quad \text{for all } \lambda \in \mathbb{K} 
    \text{ and } w \in \mathrm{E}, 
  </span><br>
  hence
  <br><br><span class='display'>
    \mathbb{B} (\lambda,\delta_1 ) \cdot \mathbb{B}_Q (v,\delta_2) \subset
    \mathbb{B}_Q (\lambda \cdot v ,\varepsilon) ,
  </span><br>
  where <span class='inline'>\mathbb{B} (\lambda, \delta_1) = \{ \mu \in \mathbb{K} \mid |\mu -\lambda|  <  \delta_1\} </span>.
  This shows continuity of scalar multiplication at each <span class='inline'>(\lambda,v) \in \mathbb{K} \times \mathrm{E}</span>.

  Since each of the base elements <span class='inline'>\mathbb{B}_Q(v,\varepsilon) \in \mathscr{B}_P</span> is convex by 
  the preceding proposition, Axiom \hyperref[axiom:tvs-local-convexity]LCVS holds true as well
  and the topology <span class='inline'>\mathscr{T}_P</span> is locally convex. 


</p><h2>Gauge functionals and induced seminorms</h2><p>\addcontentslinetocsubsectionGauge functionals and induced seminorms
<br><br><strong>16.10</strong>
As we have seen, any vector space with a topology defined by a family of seminorms 
on it is a locally convex topological vector space. The converse also holds true. The fundamental notion
needed for the proof of this is the following.    

<br><br><strong>Definition 16.11</strong>
  Let  <span class='inline'>\mathrm{E}</span>  be a vector space and <span class='inline'>A \subset \mathrm{E}</span> absorbent. Then the map
  <br><br><span class='display'>
     p_A : \mathrm{E} \to \mathbb{R}_{\geq 0} , \: v \mapsto p_A (v)= \inf \big\{ t \in \mathbb{R}_{ >  0} \bigm\vert v \in t A \big\} 
  </span><br>
  is called the <i>gauge functional</i>, the <i>Minkowski functional</i> or the <i>Minkowski gauge</i> 
  of <span class='inline'>A</span>.  
<br><br>

<br><br><strong>Remark 16.12</strong>
  By definition of an absorbent set, <span class='inline'>\big\{ t \in \mathbb{R}_{ >  0} \bigm\vert v \in t A \big\}</span> is non-empty
  whenever <span class='inline'>A\subset \mathrm{E}</span> is absorbent. Hence <span class='inline'>p_A</span> is well-defined for such <span class='inline'>A</span>.  
<br><br>

<br><br><strong>Proposition 16.13</strong>
  The Minkowski gauge <span class='inline'>p_A :\mathrm{E} \to \mathbb{R}_{\geq 0}</span> of an absorbent subset <span class='inline'>A</span>
  of a vector space <span class='inline'>\mathrm{E}</span>  has the following properties.  
  
  </p><ol class='enumeration'>

  <li value='(I)'> 
    The gauge functional is positively homogeneous that is
    <span class='inline'>p_A (t v) = t\,  p_A(v)</span> for all <span class='inline'>t\in \mathbb{R}_{ >  0}</span> and all <span class='inline'>v\in \mathrm{E}</span>.
  </li><li value='(II)'>
     If <span class='inline'>A</span> is convex, then <span class='inline'>p_A</span> is subadditive and 
  <br><br><span class='display'>
    \mathbb{B}_p (v,1)= \bigcup_{0 <  t  <  1} tA \subset A \subset
    \bigcap_{1 <  t} tA = \overline{\mathbb{B}}_p (v,1)  .
  </span><br>
</li><li value='(III)'>
  If <span class='inline'>A</span> is absolutely convex, then <span class='inline'>p_A</span> is a seminorm on <span class='inline'>\mathrm{E}</span>.
  
  </li></ol><p>

<br><br>

<br><i>Proof.</i>
 If <span class='inline'>t > 0</span>, then <span class='inline'>tv \in sA</span> for some <span class='inline'>s > 0</span> if and only if <span class='inline'>v \in \frac st A</span>. 
 Hence <span class='inline'>\big\{ s \in \mathbb{R}_{ >  0} \bigm\vert t v \in s A \big\}</span> and <span class='inline'>t \big\{ s \in \mathbb{R}_{ >  0} \bigm\vert v \in s A \big\}</span>
 coincide for all  <span class='inline'>t >  0</span>, so (I) follows. 
 
 Assume that <span class='inline'>A</span> is convex. Let <span class='inline'>v,w\in \mathrm{E}</span> and <span class='inline'>\varepsilon  > 0</span>. Then there exist
 <span class='inline'>t > p_A(v)</span> and <span class='inline'>s  >  p_A(w)</span> such that 
 <span class='inline'>v \in tA</span>, <span class='inline'>w\in sA</span>, <span class='inline'>t  <  p_A(v) +\frac \varepsilon 2</span> and
 <span class='inline'>s  <  p_A(w) +\frac \varepsilon 2</span>. By convexity of <span class='inline'>A</span> and
 \Crefthm:weighted-sum-convex-absolutely-convex-sets,
 <span class='inline'>v+w \in tA+ sA = (t+s)A</span>.
 Hence <span class='inline'>p_A(v+w) \leq (t+s)  <  p_A(v) + p_A (w) + \varepsilon</span>.
 Since <span class='inline'>\varepsilon  > 0</span> was arbitrary, <span class='inline'>p_A(v+w) \leq  p_A(v) + p_A (w)</span> and <span class='inline'>p_A</span> is subadditive. 
 If <span class='inline'>v \in tA</span> for some <span class='inline'>t</span> with <span class='inline'>0  <  t < 1</span>, then <span class='inline'>p_A(v) \leq t  <  1</span> by definition.
 Conversely, if <span class='inline'>p_A(v)  <  1</span>, then there exists a <span class='inline'>t > 0</span> such that <span class='inline'>t < 1</span> and <span class='inline'>v \in tA</span>.
 Hence the equality <span class='inline'>\mathbb{B}_p (v,1) = \bigcup_{0 <  t  <  1} tA</span> follows.
 Since <span class='inline'>A</span> is absorbing, <span class='inline'>0</span> is an element of <span class='inline'>A</span>. By convexity of <span class='inline'>A</span>
 one therefore concludes <span class='inline'>tA = (1-t) \{ 0 \}  + tA \subset A</span> whenever <span class='inline'>0 <  t  <  1</span>.
 For <span class='inline'>t > 1</span> this shows <span class='inline'>\frac 1t A \subset A</span>, hence <span class='inline'>A \subset tA</span>.
 So the relation <span class='inline'>\bigcup_{0 <  t  <  1} tA \subset A \subset \bigcap_{1 <  t} tA</span> is proved.
 Now assume that <span class='inline'>v \in tA</span> for all <span class='inline'>t > 1</span>. Then <span class='inline'>p_A(v)\leq 1</span> by definition.
 If conversely <span class='inline'>p_A(v)\leq 1</span>, then there exists for each <span class='inline'>\varepsilon  > 0</span> an <span class='inline'>s\geq 0</span>
 such that <span class='inline'>p_A(v) \leq s</span>, <span class='inline'>v \in sA</span> and <span class='inline'>s  <  1 +\varepsilon</span>.
 Hence, for <span class='inline'>t\geq   1 +\varepsilon</span> by \Crefthm:weighted-sum-convex-absolutely-convex-sets
 and <span class='inline'>0\in A</span>,
 <br><br><span class='display'>
    v \in sA = s A + (t-s) \{0\} \subset s A + (t-s) A = tA . 
 </span><br>  
 Since <span class='inline'>\varepsilon  > 0</span> was arbitrary, <span class='inline'>v \in tA</span> for all <span class='inline'>t > 1</span> follows. So one obtains
 the equality <span class='inline'>\bigcap_{1 <  t} tA =  \overline{\mathbb{B}}_p (v,1)</span>,
 and (II) is proved. 
  
 To verify (III) recall that <span class='inline'>A</span> is circled whenever
 <span class='inline'>A</span> is absolutely convex. This entails for <span class='inline'>r\in \mathbb{K}</span>, <span class='inline'>v\in \mathrm{E}</span>
 and absolutely convex <span class='inline'>A</span>
 <br><br><span class='display'>
   p_A (rv)= \inf \big\{ t \in \mathbb{R}_{ >  0} \bigm\vert r v \in tA \big\} = 
   \inf \big\{ t \in \mathbb{R}_{ >  0} \bigm\vert |r|v \in t A \big\} = p_A (|r|v) = |r| p_A(v) ,
 </span><br>
 where for the last equality we have used (I).


<br><br><strong>Lemma 16.14</strong>
  Let  <span class='inline'>A</span> and <span class='inline'>B</span> be absorbent subsets of a vector space <span class='inline'>\mathrm{E}</span>. Then
  the following holds true.
  
  </p><ol class='enumeration'>

  <li value='(I)'>
    <span class='inline'>p_{tA}(v) =  p_A(t^{-1} v)</span> for all <span class='inline'>t\in \mathbb{K}^\times</span> and <span class='inline'>v\in \mathrm{E}</span>.
  </li><li value='(II)'>
    If <span class='inline'>B\subset A</span>, then <span class='inline'>p_A \leq p_B</span>.
  </li><li value='(III)'>
    If <span class='inline'>A</span> is convex, then <span class='inline'>v \in tA</span> for all <span class='inline'>v\in \mathrm{E}</span> and <span class='inline'>t  >  p_A(v)</span>. 
  </li><li value='(IV)'>
    If <span class='inline'>A</span> and <span class='inline'>B</span> are convex, then the intersection <span class='inline'>A\cap B</span> is absorbent and convex and
    <span class='inline'>p_{A\cap B} = \sup \{ p_A,p_B\}</span>, where <span class='inline'>\sup \{ p_A,p_B\} (v) = \sup \{ p_A (v) ,p_B (v) \}</span>
    for all  <span class='inline'>v\in \mathrm{E}</span>.  
  
  </li></ol><p>

<br><br>

<br><i>Proof.</i>
  
  </p><ol class='enumeration'>

  <li value='\itshape ad (\itshape I\hspace1pt). '>
    If <span class='inline'>t\in \mathbb{K}</span> is invertible, then <span class='inline'>v \in tA</span> if and only if <span class='inline'>t^{-1}v \in A</span>.
  </li><li value='\itshape ad (\itshape II\hspace1pt). '>
    Let <span class='inline'>v\in \mathrm{E}</span> and <span class='inline'>\varepsilon  > 0</span>. Then there exists <span class='inline'>t</span> with
    <span class='inline'>p_B(v) \leq t  <  p_B(v) + \varepsilon</span> such that <span class='inline'>v \in tB</span>. By <span class='inline'>B\subset A</span> this implies
    <span class='inline'>v \in tA</span>, hence <span class='inline'>p_A(v) \leq t  <  p_B(v) + \varepsilon</span>. Since <span class='inline'>\varepsilon  > 0</span>
    was arbitrary, the estimate <span class='inline'>p_A \leq p_B</span> follows.
  </li><li value='\itshape ad (\itshape III\hspace1pt). '>
    By definition of the Minkowski gauge there exists <span class='inline'>s \in \mathbb{R}</span> such that <span class='inline'>p_A(v) <  s  < t</span> and  <span class='inline'>v \in sA</span>.
    By convexity of <span class='inline'>A</span> one concludes <span class='inline'>\frac st v = \frac st v + \left( 1 - \frac st \right) \cdot 0 \in sA</span>, hence
    <span class='inline'>v \in tA</span>.  
  </li><li value='\itshape ad (\itshape IV\hspace1pt). '>
    The intersection of convex sets is convex, so <span class='inline'>A\cap B</span> is convex.
    Let <span class='inline'>v\in \mathrm{E}</span> and choose <span class='inline'>r_A\geq 0</span> and <span class='inline'>r_B\geq 0</span> such that 
    <span class='inline'>v \in tA</span> for all <span class='inline'>t\geq r_A</span> and <span class='inline'>v \in sB </span> for all <span class='inline'>s\geq r_B</span>.
    Then <span class='inline'>v \in (tA)\cap (tB) = t(A\cap B) </span> for all <span class='inline'>t\geq \max\{r_A,r_B\}</span>,
    so <span class='inline'>A\cap B</span> is absorbent.
    One has <span class='inline'>p_{A\cap B} \geq  \sup \{ p_A,p_B\}</span> by (II).
    To show the converse inequality assume that  <span class='inline'>v \in \mathrm{E}</span> and <span class='inline'>t  >  \sup \{ p_A (v) ,p_B (v)\}</span>.
    Then <span class='inline'>v \in tA \cap tB = t(A\cap B)</span>, which implies <span class='inline'>p_{A\cap B} (v)\leq t</span>. Hence
    <span class='inline'>p_{A\cap B} (v) \leq  \sup \{ p_A (v) ,p_B (v)\}</span> since <span class='inline'>t  >  \sup \{ p_A (v) ,p_B (v)\}</span>
    was arbitrary.
  
  </li></ol><p>



<br><br><strong>Lemma 16.15</strong>
  Let <span class='inline'>p:\mathrm{E} \to\mathbb{R}</span> be a sublinear map on a vector space <span class='inline'>\mathrm{E}</span> and
  <span class='inline'>A\subset \mathrm{E}</span> convex. If
  <br><br><span class='display'> \mathbb{B}_p (0,1) \subset A \subset \overline{\mathbb{B}}_p (0,1) ,</span><br>
  then the gauge functional <span class='inline'>p_A</span> coincides with <span class='inline'>\sup \{p,0\} </span>. If <span class='inline'>p</span> is even
  a seminorm, then <span class='inline'>p=p_A</span>. 
<br><br>

<br><i>Proof.</i>
  Let <span class='inline'>p:\mathrm{E}\to\mathbb{R}</span> be sublinear. Observe that then  <span class='inline'>\mathbb{B}_p (0,1)</span> is absorbent by
  \Crefthm:properties-subadditive-convex-real-valued-maps-vector-space
  (IV).
  Hence <span class='inline'>A</span> must also be absorbent by assumption, so the associated Minkowski gauge <span class='inline'>p_A</span> is
  positively homogeneous by
  \Crefthm:properties-gauge-functional-absorbent-set
  (I). 
  
  Assume now that there exists <span class='inline'>v\in\mathrm{E}</span> such that <span class='inline'>\max\{p(v),0 \}  <  p_A(v)</span>. By positive
  homogeneity of <span class='inline'>p</span> and <span class='inline'>p_A</span>
  one can achive by possibly multiplying <span class='inline'>v</span> by a positive real number that <span class='inline'>\max\{p(v),0 \}  <  1  <  p_A(x)</span>.  The first
  inequality entails <span class='inline'>v \in  \mathbb{B}_p (0,1)</span>, the second <span class='inline'>v\notin \overline{\mathbb{B}}_p (0,1) </span> which is a contradiction.
  Next assume that there exists <span class='inline'>v\in\mathrm{E}</span> with <span class='inline'>p_A(v)  <  \max\{p(v),0 \}</span>. As before one can then achieve that
  <span class='inline'> p_A(v)  <  1  <  \max\{p(v),0 \}</span> for some <span class='inline'>v\in\mathrm{E}</span>. By the first inequality one concludes <span class='inline'>v \in  A</span>,
  by the second <span class='inline'>v \notin A</span>. This is a contradiction. So the equality <span class='inline'>\max\{p(v),0 \} = p_A(v)</span> holds for all <span class='inline'>v\in \mathrm{E}</span>. 
  
  In case <span class='inline'>p</span> is a seminorm, then <span class='inline'>p(v) \geq 0</span> for all <span class='inline'>v\in \mathrm{E}</span> and the second claim follows by the first. 


<br><br><strong>Proposition 16.16</strong>
  Let <span class='inline'>\mathrm{E}</span> be a topological vector space, and <span class='inline'>p:\mathrm{E} \to \mathbb{R}</span> be sublinear. Then the following are equivalent.
  
  </p><ol class='enumeration'>

  <li value='(I)'>
    <span class='inline'>p</span> is continuous in the origin. 
  </li><li value='(II)'>
    <span class='inline'>p</span> is uniformly continuous.
  </li><li value='(III)'>
    <span class='inline'>p</span> is continuous.  
  </li><li value='(IV)'>
    <span class='inline'>\mathbb{B}_p (0,1)</span> is a zero neighborhood.
  
  </li></ol><p>

<br><br>

<br><i>Proof.</i>
  Let us first show (I)  <span class='inline'>\implies</span> (II).
  To this end fix <span class='inline'>\varepsilon  > 0</span>. By assumption there exists a zero neighborhood <span class='inline'>V\subset \mathrm{E}</span> such that
  <span class='inline'>|p(v)|  <  \varepsilon</span> for all <span class='inline'>v\in V</span>. By possibly passing to <span class='inline'>V \cap (-V)</span> one can assume that
  <span class='inline'>V</span> is symmetric. 
  \Crefthm:properties-subadditive-convex-real-valued-maps-vector-space (II)
  now implies
  <br><br><span class='display'>
     | p(v) - p(w)|  <   \varepsilon \quad \text{for all } v,w \in V .
  </span><br>
  Hence <span class='inline'>p</span> is uniformly continuous.   
  The implications (II) <span class='inline'>\implies</span> (III)
  and (III) <span class='inline'>\implies</span> (IV) are trivial.
  It remains to prove
  (IV) <span class='inline'>\implies</span> (I).
  Assume that  <span class='inline'>\mathbb{B}_p (0,1)</span> is a zero neighborhood.
  Then there exists a symmetric zero neighborhood <span class='inline'>V</span> contained in  <span class='inline'>\mathbb{B}_p (0,1)</span>.  Since <span class='inline'>p(0)=0</span> one concludes by
  \Crefthm:properties-subadditive-convex-real-valued-maps-vector-space (II)
  <br><br><span class='display'>
     | p(v) |  <   \max \{ p(v), p(-v )\}  <  1   \quad \text{for all } v \in V .
  </span><br>
  But this implies <span class='inline'>|p(v)|  <  \varepsilon </span> for all <span class='inline'>v \in \varepsilon V</span> and <span class='inline'>\varepsilon  > 0</span>,
  so <span class='inline'>p</span> is continuous at the origin. 


</p><h2>Normability</h2><p>\addcontentslinetocsubsectionNormability

<br><br><strong>Definition 16.17</strong>
  A topological vector space <span class='inline'>\mathrm{E}</span> is called <i>seminormable</i> if its topology is generated by a single
  seminorm <span class='inline'>p:\mathrm{E}\to \mathbb{R}_{\geq 0}</span>.
  If the topology on  <span class='inline'>\mathrm{E}</span> coincides with the vector space topology generated by a norm <span class='inline'>\|\cdot\|</span>,
  then one calls <span class='inline'>\mathrm{E}</span> <i>normable</i>.
<br><br>

<br><br><strong>Theorem 16.18</strong>[Kolmogorov's normability criterion]
  A topological vector space <span class='inline'>\mathrm{E}</span> is normable if and only if it is a ref_error space and 
  possesses a bounded convex neighborhood of the origin.  
<br><br>

</p><h1>17 Cauchy filters and completeness</h1><p>


</p><h1>18 Function spaces and their topologies</h1><p>


<br><br><strong>Proposition 18.1</strong>
  
  Let <span class='inline'>X</span> be a topological space and <span class='inline'>(Y,d)</span> a metric space.
  Then the following holds true.
  
  </p><ol class='enumeration'>

  <li value='(I)'>
  The space
  <br><br><span class='display'>
    \mathscr{B} (X,Y) = \big\{ f : X \to Y \bigm\vert
    \exists y_0\in Y \, \exists C  > 0 \, \forall x\in X : \:  d\big(f(x),y_0\big) \leq C\big\}
      </span><br>
  of bounded functions from <span class='inline'>X</span> to <span class='inline'>Y</span> is a metric space with metric
  <br><br><span class='display'>
    \varrho : \mathscr{B} (X,Y) \times \mathscr{B} (X,Y) \to \mathbb{R}_{\geq 0} , \: (f,g) \mapsto
     \sup_{x\in X} d\big( f(x),g(x)\big)   .
  </span><br>
  </li><li value='(II)'>
  
    If <span class='inline'>(Y,d)</span> is complete, then <span class='inline'>(\mathscr{B} (X,Y),\varrho)</span> is so, too.
  </li><li value='(III)'>
  
    The space
    <br><br><span class='display'>
      \mathscr{C}_{b} (X,Y) = \mathscr{C} (X,Y) \cap \mathscr{B} (X,Y) 
    </span><br>
    of continuous bounded functions from <span class='inline'>X</span> to <span class='inline'>Y</span> is a closed subspace of <span class='inline'>\mathscr{B} (X,Y)</span>. 
  
  </li></ol><p>

<br><br>
<br><i>Proof.</i>
  Note first that  by the triangle inequality there exists for every <span class='inline'>f\in \mathscr{B} (X,Y)</span> and <span class='inline'>y\in Y</span>
  a real number <span class='inline'>C_{f,y} > 0</span> such that
  <br><br><span class='display'> 
    d\big(f(x),y\big) \leq C_{f,x} \quad \text{for all } x\in X .
  </span><br>  
  
  </p><ol class='enumeration'>

  <li value='\itshape ad (\itshape I\hspace1pt). '>
    Before verifying the axioms of a metric for <span class='inline'>\varrho</span> we need to show that <span class='inline'>\varrho</span> is well-defined meaning that
    <span class='inline'>\sup_{x\in X} d\big( f(x),g(x)\big)  <  \infty</span> for all <span class='inline'>f,g \in \mathscr{B} (X,Y)</span>. 
    To this end fix some <span class='inline'>y\in Y</span> and observe using the triangle inequality
    that  
    <br><br><span class='display'>
      d\big( f(x),g(x)\big)  \leq d\big( f(x), y\big) + d\big( y, g(x)\big)
      \leq C_{f,y} + C_{g,y} \quad \text{for all } x \in X . 
    </span><br>
    Since furthermore <span class='inline'>d\big( f(x),g(x)\big) \geq 0</span> for all <span class='inline'>x\in X</span>, the map <span class='inline'>\varrho</span> is well-defined indeed
    with image in <span class='inline'>\mathbb{R}_{\geq 0}</span>.
    If <span class='inline'>\varrho (f,g) = 0</span>, then <span class='inline'>d \big( f(x),g(x) \big)=0</span> for all <span class='inline'>x\in X</span>, hence <span class='inline'>f=g</span>.
    Obviously, <span class='inline'>\varrho</span> is symmetric since <span class='inline'>d</span> is symmetric. Finally, let
    <span class='inline'>f,g,h\in \mathscr{B} (X,Y)</span> and check using the triangle inequality for <span class='inline'>d</span>:
    <br><br><span class='display'>
      
      \varrho (f,g)  = \sup_{x\in X} d\big( f(x),g(x)\big)  \leq
      \sup_{x\in X} \left( d\big( f(x),h (x)\big) + d\big( h(x),g(x)\big)\right)  \leq </span><br><br><span class='display'>
       \leq \sup_{x\in X} d\big( f(x),h (x)\big) + \sup_{x\in X} d\big( h(x),g(x)\big) =
      d(f,h) + d(h,g) . 
      
    </span><br>
    Hence  <span class='inline'>\varrho</span> is a metric. 
   </li><li value='\itshape ad (\itshape II\hspace1pt). '>
     Assume <span class='inline'>(Y,d)</span> to be complete and let <span class='inline'>(f_n)_{n\in\mathbb{N}}</span> be a  Cauchy sequence in <span class='inline'>\mathscr{B} (X,Y)</span>.
     Let <span class='inline'>\varepsilon  > 0</span> and choose <span class='inline'>N_\varepsilon \in \mathbb{N}</span> so that
     <br><br><span class='display'>
           \varrho (f_n,f_m)  <  \varepsilon \quad \text{for all } n,m\geq N . 
     </span><br>
     Then for every <span class='inline'>x\in X</span> the relation
     <br><br><span class='display'> \tag{18.1}
       
       d\big(f_n(x),f_m(x)\big)  <  \varepsilon \quad \text{for all } n,m\geq N_\varepsilon 
     </span><br><br>
     holds true, so <span class='inline'>(f_n(x))_{n\in \mathbb{N}}</span> is a Cauchy sequence in <span class='inline'>Y</span>.
     By completeness of <span class='inline'>(Y,d)</span> it has a limit which we denote by <span class='inline'>f(x)</span>.
     By passing to the limit <span class='inline'>m\to \infty</span> in \eqrefeq:cauchy-sequence-relation-values
     one obtains that
     <br><br><span class='display'> \tag{18.2}
       
       d\big(f(x),f_n(x)\big) \leq \varepsilon \quad \text{for all } x \in X \text{ and } n \geq N_\varepsilon . 
     </span><br><br>
     Using the triangle inequality one infers from this for an element <span class='inline'>y\in Y</span> which we now fix that
     <br><br><span class='display'>
       d\big(f(x),y )\big) \leq  d\big(f(x),f_{N_1}(x))\big) + d\big(f_{N_1}(x),y \big) \leq
       1  +  C_{f_{N_1},y} . 
     </span><br>
     Hence <span class='inline'>f</span> is a bounded function. Moreover, \eqrefeq:limit-relation-values entails
     that
     <br><br><span class='display'>
       \varrho (f,f_n) = \sup_{x\in X} d\big(f(x),f_n(x)\big) \leq \varepsilon
       \quad \text{for all } n \geq N_\varepsilon ,
     </span><br>
     so <span class='inline'>(f_n)_{n\in \mathbb{N}}</span> converges to <span class='inline'>f</span>. 
   </li><li value='\itshape ad (\itshape III\hspace1pt). '>
     We have to show that the limit <span class='inline'>f</span> of a sequence <span class='inline'>(f_n)_{n\in}</span> of functions
     <span class='inline'>f_n \in \mathscr{C}_{b} (X,Y)</span> which converges in <span class='inline'>(\mathscr{B} (X,Y),\varrho)</span> has to be continuous.
     To this end let <span class='inline'>\varepsilon  > 0</span> and choose <span class='inline'>N_\varepsilon \in \mathbb{N}</span> so that
     <br><br><span class='display'>
             \varrho (f_n,f)  <  \frac{\varepsilon}{3}  \quad \text{for all } n \geq N_\varepsilon .
     </span><br>
     Let <span class='inline'>x_0\in X</span>. By continuity of <span class='inline'>f_{N_\varepsilon}</span> there exists a neighborhood <span class='inline'>U\subset X</span> of <span class='inline'>x</span> so
     that
     <br><br><span class='display'>
          d\big(f_{N_\varepsilon} (x),f_{N_\varepsilon}(x_0)\big)  <   \frac{\varepsilon}{3} \quad \text{for all } x\in U . 
     </span><br>
     By the triangle inequality one concludes that
     <br><br><span class='display'>
       d\big(f (x),f(x_0)\big) \leq 
       d\big(f(x),f_{N_\varepsilon}(x)\big) + d\big(f_{N_\varepsilon} (x),f_{N_\varepsilon}(x_0)\big) +
       d\big(f_{N_\varepsilon} (x_0),f(x_0)\big) <  \varepsilon 
     </span><br>
     for all <span class='inline'>x\in U</span>. Hence <span class='inline'>f</span> is continuous at <span class='inline'>x_0</span>. Since <span class='inline'>x_0\in X</span> was arbitrary <span class='inline'>f</span>, is  a continuous map,
     hence an elemnt of <span class='inline'>\mathscr{C}_{b} (X,Y)</span>. 
  
  </li></ol><p>
\mbox 


<br><br><strong>Proposition 18.2</strong>
  Let <span class='inline'>X</span> be a topological space and <span class='inline'>\mathbb{K}</span> the division algebra of real or complex numbers or of quaternions.
  Then the following holds true.
  
  </p><ol class='enumeration'>

  <li value='(I)'>
    The space <span class='inline'>\mathscr{B} (X,\mathbb{K})</span> of bounded <span class='inline'>\mathbb{K}</span>-valued functions on <span class='inline'>X</span> can be expressed as
    <br><br><span class='display'> \tag{18.3}
      
      \mathscr{B} (X,\mathbb{K}) = 
      \big\{ f : X \to \mathbb{K} \bigm\vert 
      \exists C  >  0 \, \forall x\in X :\:  |f(x)| \leq C \big\} .
    </span><br><br>
    It carries the structure of a <span class='inline'>\mathbb{K}</span>-algebra by pointwise addition and multiplication of functions
    and becomes  a Banach algebra when equipped with the <i>supremums-norm</i>
    <br><br><span class='display'>
      \| \cdot \|_\infty : \: \mathscr{B} (X,\mathbb{K}) \to \mathbb{K},\quad
      f \mapsto \sup_{x\in X} |f(x)| .
    </span><br>
    </li><li value='(II)'> 
    The subspace <span class='inline'>\mathscr{C}_{b} (X,\mathbb{K}) \subset \mathscr{B} (X,\mathbb{K})</span> 
    of bounded continuous <span class='inline'>\mathbb{K}</span>-valued functions on <span class='inline'>X</span> is a closed subalgebra of
    <span class='inline'>\big( \mathscr{B} (X,\mathbb{K}) , \| \cdot \|_\infty\big)</span>,
    so a Banach algebra as well when endowed with the supremums-norm. 
    For <span class='inline'>X</span> compact this means in particular that the algebra <span class='inline'>\big( \mathscr{C} (X,\mathbb{K}), \| \cdot \|_\infty\big)</span>
    is a Banach algebra.
  
  </li></ol><p>

<br><br>

<br><i>Proof.</i>
  Eq.~\eqrefeq:algebra-bounded-functions-values-real-complex-numbers-quaternions is obvious since
  the distance of two elements <span class='inline'>a,b\in \mathbb{K}</span> is given by <span class='inline'>d(a,b) = |a-b|</span>, so in particular
  <span class='inline'>d(a,0) = |a|</span>. Let <span class='inline'>f,g \in \mathscr{B} (X,\mathbb{K})</span> and choose <span class='inline'>C_f,C_g \geq 0</span> so that
  <span class='inline'> |f(x)| \leq C_f </span> and <span class='inline'> |g(x)| \leq C_g </span> for all <span class='inline'>x \in X</span>. Then, by the triangle inequality
  and absolute homogeneity of the absolute value, 
  <br><br><span class='display'>
    | f(x) + g (x)| \leq C_f + C_g , \quad | a\, f(x) | \leq |a| \, C_f , \quad \text{and} \quad
    | f(x) \cdot g (x)| \leq C_f \cdot C_g . 
  </span><br>
  Hence the sum and the product of two bounded functions are bounded and so is any scalar multiple of a bounded function.
  Therefore, <span class='inline'>\mathscr{B} (X,\mathbb{K})</span> is an algebra over <span class='inline'>\mathbb{K}</span>. Using the triangle inequality and absolute homogeneity of the
  absolute value again one verifies that  <span class='inline'> \|f \|_\infty</span> is a norm on  <span class='inline'>\mathscr{B} (X,\mathbb{K})</span> indeed and that
  it fulfills <span class='inline'>\|fg \|_\infty\leq \|f \|_\infty \cdot \|g \|_\infty</span> for all <span class='inline'>f,g \in \mathscr{B} (X,\mathbb{K})</span>. 
  Furthermore, by definition, <span class='inline'> \|f \|_\infty = \varrho (f,0)</span> for all <span class='inline'>f \in \mathscr{B} (X,\mathbb{K})</span>, where <span class='inline'>\varrho</span> is
  defined as in \Crefthm:metric-structure-space-bounded-maps.
  Since <span class='inline'>(\mathscr{B} (X,\mathbb{K}),\varrho) </span> is a complete metric space,
  <span class='inline'>(\mathscr{B} (X,\mathbb{K}),\|\cdot \|_\infty)</span> therefore is a Banach algebra.  This proves the first claim.
   
  For the second observe that for <span class='inline'>f, g \in \mathscr{C}_{b} (X,\mathbb{K})</span> and <span class='inline'>a\in \mathbb{K}</span> the
  sum <span class='inline'>f+g</span>, the scalar multiple <span class='inline'>af</span>, and the product <span class='inline'>f\cdot g</span> are elements of  <span class='inline'>\mathscr{C}_{b} (X,\mathbb{K})</span> again.
  To verify this let <span class='inline'>x\in X</span> and <span class='inline'>\varepsilon  > 0</span>. Choose neighborhoods
  <span class='inline'>U_1</span> and <span class='inline'>U_2</span> of <span class='inline'>x</span> so that
  <br><br><span class='display'>
    | f (y) - f(x) | <  \min \left\{\frac{\varepsilon}{2}, \frac{\varepsilon}{|a|+1}, \frac{\varepsilon}{2(|g(x)|+1)} \right\}
    \quad \text{for } y\in U_1
  </span><br>   
  and
  <br><br><span class='display'>
    | g(y) - g(x) |  <  \left\{1,\frac{\varepsilon}{2},\frac{\varepsilon}{2(|f(x)|+1)} \right\} \quad\text{for } y\in U_2 .
  </span><br>
  Then for all <span class='inline'>y\in U_1\cap U_2</span> 
  <br><br><span class='display'>
    
      | (f+g) (y) - (f+g) (x) |  \leq  | f (y) - f(x) | +  | g (y) - g (x) |  <  \varepsilon , </span><br><br><span class='display'>
      | (af) (y) - (af) (x) |  \leq  |a|  \cdot | f (y) - f(x) |  <  \varepsilon , </span><br><br><span class='display'>
      | (f\cdot g) (y) - (f\cdot g) (x) |  \leq |g(y)| \cdot | f (y) - f(x) |  +  |f(x) | \cdot | (g (y) - g (x) |
        <  \varepsilon .
    
  </span><br>
  This means that <span class='inline'>f+g</span>, <span class='inline'>af</span> and <span class='inline'>fg</span> are continuous in <span class='inline'>x</span>, hence elements of <span class='inline'>\mathscr{C}_{b} (X,\mathbb{K})</span>
  since <span class='inline'>x \in X</span> was arbitrary. So <span class='inline'>\mathscr{C}_{b} (X,\mathbb{K})</span> is a subalgebra of <span class='inline'>\mathscr{B} (X,\mathbb{K})</span>.   
  By \Crefthm:metric-structure-space-bounded-maps one knows that <span class='inline'>\mathscr{C}_{b} (X,\mathbb{K})</span>
  is a closed subspace of <span class='inline'>\mathscr{B} (X,\mathbb{K})</span>. The rest of the claim is obvious.


<br><br><strong>18.3</strong>
As the next step, we introduce seminorms and their topologies on spaces of differentiable functions defined over an
open set <span class='inline'>\Omega\subset\mathbb{R}^n</span>. We agree that from now on <span class='inline'>\Omega</span> will always  denote in this section an open subset
of <span class='inline'>\mathbb{R}^n</span>. For any differentiability order <span class='inline'>m\in \mathbb{N} \cup \{ \infty\}</span>
the symbol <span class='inline'>\mathscr{C}^m (\Omega)</span> stands for the space of <span class='inline'>m</span>-times continuously differentiable complex valued
functions on <span class='inline'>\Omega</span>. For <span class='inline'>i=1,\ldots,n</span> we denote by <span class='inline'>x^i : \mathbb{R}^n \to \mathbb{R}</span>  the <span class='inline'>i</span>-th coordinate function
and, if <span class='inline'>m\geq 1</span>, by <span class='inline'>\partial_i : \mathscr{C}^{m} (\Omega) \to \mathscr{C}^{m-1} (\Omega)</span>
the operator which maps <span class='inline'>f \in \mathscr{C}^m (\Omega)</span> to the partial derivative
<span class='inline'>\frac{\partial f}{\partial x^i}</span>. More generally, if <span class='inline'>\alpha \in \mathbb{N}^n</span> is a multiindex satisfying
<span class='inline'>|\alpha| = \alpha_1+\ldots \alpha_n \leq m</span>, then we write
<span class='inline'>\partial^\alpha : \mathscr{C}^{m} (\Omega) \to \mathscr{C}^{m-|\alpha|} (\Omega)</span>  for the higher order partial derivative
which maps <span class='inline'>f \in \mathscr{C}^{m} (\Omega)</span> to
<span class='inline'>\frac{\partial^{|\alpha|} f}{\partial x_1^{\alpha_1} \cdot \ldots \cdot \partial x_n^{\alpha_n}}</span>. Recall that the
sum and the product of two <span class='inline'>m</span>-times differentiable functions and scalar multiples of  <span class='inline'>m</span>-times differentiable functions
are again <span class='inline'>m</span>-times differentiable, hence <span class='inline'>\mathscr{C}^{m} (\Omega)</span> forms a <span class='inline'>\mathbb{C}</span>-algebra.
Now we define <span class='inline'>\widebar{\mathscr{C}}^{m} (\Omega)</span> to be the space of continuous functions on the closure <span class='inline'>\widebar{\Omega}</span>
which are <span class='inline'>m</span>-times continuosly differentiable on <span class='inline'>\Omega</span> so that each of its partial derivatives of order <span class='inline'>\leq m</span>
has a continuos extension to <span class='inline'>\widebar{\Omega}</span>. Since the operators  <span class='inline'>\partial_i</span> are linear and also derivations
by the Leibniz rule,  <span class='inline'>\widebar{\mathscr{C}}^{m} (\Omega)</span> is a subalgebra of <span class='inline'>\mathscr{C}^{m} (\Omega)</span>. In general, these
algebras do not coincide as for example the function <span class='inline'>\frac 1x</span> on <span class='inline'>\mathbb{R}_{ > 0}</span> shows. It is an element
of <span class='inline'>\mathscr{C}^{\infty} (\mathbb{R}_{ < 0})</span> but can not be extended to  a continuous function on <span class='inline'>\mathbb{R}_{\geq 0}</span>,
so is not an element of <span class='inline'>\widebar{\mathscr{C}}^{\infty} (\mathbb{R}_{ < 0})</span>.

If <span class='inline'>X \subset \mathbb{R}^n</span> is locally closed which means that <span class='inline'>X</span> is the intersection of an open and a closed susbet of <span class='inline'>\mathbb{R}^n</span>,
then  define <span class='inline'>\mathscr{C}^{m} (X)</span> as the quotient space <span class='inline'>\mathscr{C}^{m} (\Omega) / \mathscr{J}_{X} (\Omega)</span>, where
<span class='inline'>\Omega \subset \mathbb{R}^n</span> open is chosen so that <span class='inline'>X = \widebar{X} \cap \Omega</span> and where
<span class='inline'>\mathscr{J}_{X}</span> denotes the ideal sheaf of all <span class='inline'>m</span>-times continuously differentiable functions
vanishing on <span class='inline'>X</span> that is
<br><br><span class='display'>
   \mathscr{J}_{X} (\Omega) = \big\{ f \in \mathscr{C}^{m} (\Omega)  \bigm\vert f|_X = 0 \big\}  .
</span><br>
Using a smooth partition of unity type of argument one shows that  <span class='inline'>\mathscr{C}^{m} (X)</span> does not depend on the particular
choice of the neighborhood <span class='inline'>\Omega</span> in which <span class='inline'>X</span> is relatively closed and that <span class='inline'>\mathscr{C}^{m} (X)</span> can be naturally
identified with the space of continuous functions on <span class='inline'>X</span> which have an extension to an element of
<span class='inline'>\mathscr{C}^{m} (\Omega)</span>.  

<br><br><strong>Proposition 18.4</strong>
  Let <span class='inline'>\Omega \subset \mathbb{R}^n</span> be open and bounded and <span class='inline'>m\in \mathbb{N}_{ >  0}</span>. Then  <span class='inline'>\widebar{\mathscr{C}}^{m} (\Omega)</span>
  equipped with the norm
  <br><br><span class='display'>
    \| \cdot \|_{\Omega,m} : \widebar{\mathscr{C}}^{m} (\Omega) \to \mathbb{R}_{\geq 0}, \quad
    f \mapsto 
  </span><br>
  
  
<br><br>
</p><h1>19 Summability</h1><p>

<br><br><strong>Definition 19.1</strong>
Assume to be given a locally convex topological vector space <span class='inline'>\mathrm{V}</span> over the field <span class='inline'>\mathbb{K}</span> of real or complex numbers.
Let <span class='inline'>(v_i)_{i \in I}</span> be a family of elements of <span class='inline'>\mathrm{V}</span>. Let <span class='inline'>\mathscr{F} (I)</span> be the
set of finite subsets of <span class='inline'>I</span> and note that it is filtered by set-theoretic inclusion. 
The family  <span class='inline'>(v_i)_{i \in I}</span> then gives rise to the net 
<span class='inline'>\Big( \sum_{i \in J} v_i \Big)_{J \in \mathscr{F}(I)}</span>. One calls the family  <span class='inline'>(v_i)_{i \in I}</span>
<i>summable</i> to an element <span class='inline'>v \in \mathrm{V}</span> if the net 
<span class='inline'>\Big( \sum_{i \in J} v_i \Big)_{J \in \mathscr{F}(I)}</span> converges to <span class='inline'>v</span>. In other words this means that 
for every convex zero neighborhood <span class='inline'>U \subset \mathrm{V}</span> and <span class='inline'>\varepsilon  > 0</span> there exists an element
<span class='inline'>J_{U,\varepsilon} \in \mathscr{F} (I)</span> such that for all finite sets <span class='inline'>J</span> with <span class='inline'> J_{U,\varepsilon} \subset J \subset I</span>
<br><br><span class='display'>
   p_U \left( v - \sum_{i \in J} v_i \right)  <  \varepsilon .
</span><br>
As before, <span class='inline'>p_U</span> denotes here the gauge of <span class='inline'>U</span>. 
If <span class='inline'>\mathrm{V}</span> is Hausdorff, the limit <span class='inline'>v</span> of a summable family  <span class='inline'>(v_i)_{i \in I}</span> is
uniquely determined, and one  writes in this situation
<br><br><span class='display'>
   v = \sum_{i \in I} v_i .  
</span><br>
We denote the space of summable families in <span class='inline'>\mathrm{V}</span> over the given index set <span class='inline'>I</span> by 
<span class='inline'>\ell^1 (I ,\mathrm{V})</span>. For <span class='inline'>E=\mathbb{C}</span> we just write <span class='inline'>\ell^1 (I )</span> instead of <span class='inline'>\ell^1 (I ,\mathbb{C})</span>. If in addition the index set 
coincides with <span class='inline'>\mathbb{N}</span>, we briefly denote <span class='inline'>\ell^1 (\mathbb{N} )</span> by <span class='inline'>\ell^1</span>.
<br><br>

<br><br><strong>Proposition 19.2</strong>[Cauchy criterion for summability]
  Let <span class='inline'>\mathrm{V}</span> be a complete locally convex topological vector space. 
  A family <span class='inline'>(v_i)_{i \in I}</span> of elements of <span class='inline'>\mathrm{V}</span> then is summable 
  to some <span class='inline'>v\in \mathrm{V}</span> if and only if it satisfies the following Cauchy condition:
  </p><ol class='enumeration'>
  <li value='{\sffamily (C)}'> 
    For every convex zero neighborhood <span class='inline'>U \subset \mathrm{V}</span> and <span class='inline'>\varepsilon  > 0</span> there exists an element
    <span class='inline'>J_{U,\varepsilon} \in \mathscr{F} (I)</span> such that for all <span class='inline'>K \in \mathscr{F} (I)</span> with  <span class='inline'> K \cap J_{U,\varepsilon} = \emptyset</span>
    the relation 
    <br><br><span class='display'>
      p_U \left( \sum_{i \in K} v_i \right)  <  \varepsilon 
    </span><br>
    holds true. 
  </li></ol><p>
 
<br><br>
<br><i>Proof.</i>
  By completeness of <span class='inline'>\mathrm{V}</span> it suffices to verify that the net <span class='inline'>\Big( \sum_{i \in J} v_i \Big)_{J \in \mathscr{F}(I)}</span> is a Cauchy net
  if and only if condition  (C) is satisfied. Recall that one calls
  <span class='inline'>\Big( \sum_{i \in J} v_i \Big)_{J \in \mathscr{F}(I)}</span> a Cauchy net if for every convex zero neighborhood <span class='inline'>U \subset \mathrm{V}</span> 
  all <span class='inline'>\varepsilon  > 0</span> there exists an element <span class='inline'>J_{U,\varepsilon} \in \mathscr{F} (I)</span> such that for all <span class='inline'>J,J' \in \mathscr{F} (I)</span> 
  containing  <span class='inline'> J_{U,\varepsilon}</span> as a subset the relation 
  <br><br><span class='display'>
     p_U \left( \sum_{i \in J} v_i - \sum_{i\in J'} v_i \right)  <  \varepsilon 
  </span><br>
  holds true. 
  But that is clearly equivalent to condition  (C). 


<br><br><strong>19.3</strong> Several other notions of summability have been introduced in the analysis and functional analysis literature.  
These are mainly either used to establish summability criteria or are used in the study of 
topological tensor products and nuclearity of locally convex topological vector spaces, see <dt-cite key="GroPTTEN"></dt-cite><dt-cite key="PieNLCS"></dt-cite>. 
In the following we define these further notions of summability and study their properties.
The symbol <span class='inline'>\mathrm{V}</span>  hereby always stands for a locally convex \textt.v.s., <span class='inline'>I</span> always denotes a nonempty
index set, and <span class='inline'>\mathscr{F} (I)</span> the set of its finite subsets.

<br><br><strong>Definition 19.4</strong>
  A family   <span class='inline'>(v_i)_{i \in I}</span> in <span class='inline'>\mathrm{V}</span> is called <i>weakly summable</i> to <span class='inline'>v \in \mathrm{V}</span> if for 
  every continuous linear form <span class='inline'>\alpha : \mathrm{V} \to \mathbb{K}</span> the net 
  <span class='inline'>\Big( \sum_{i \in J} \alpha( v_i ) \Big)_{J \in \mathscr{F}(I)}</span> converges in <span class='inline'>\mathbb{K}</span> to <span class='inline'>\alpha ( v )</span>.
  In other words this means that for every <span class='inline'>\alpha \in \mathrm{V}'</span> and <span class='inline'>\varepsilon  > 0</span> there exists a finite set 
  <span class='inline'>J_{\alpha,\varepsilon} \subset I</span> such that for all finite sets <span class='inline'>J</span> with <span class='inline'>J_{\alpha,\varepsilon} \subset  J \subset I </span> 
  <br><br><span class='display'>
    \left| \alpha (v) -  \sum_{j\in J} \alpha( v_i )   \right| <  \varepsilon . 
  </span><br>
  The set of all weakly summable families in <span class='inline'>\mathrm{V}</span> with index set <span class='inline'>I</span> is denoted <span class='inline'>\ell^1 [I, \mathrm{V}]</span>.
<br><br>

<br><br><strong>Definition 19.5</strong>
  A family  <span class='inline'>(v_i)_{i \in I}</span> in <span class='inline'>\mathrm{V}</span> is called <i>absolutely summable</i> if for every circled convex 
  zero neighborhood <span class='inline'>U \subset \mathrm{V}</span> there exists some <span class='inline'>C\geq 0</span> such that
  <br><br><span class='display'>
    \sum_{i \in J} p_U \left( v_i\right) \leq C \quad \text{for all } J \in \mathscr{F} (I) .
  </span><br>
  We denote the set of all absolutely summable families  in <span class='inline'>\mathrm{V}</span> by  <span class='inline'>\ell^1 \{ I, \mathrm{V} \}</span>.
<br><br>

<br><br><strong>Proposition 19.6</strong>
  A family <span class='inline'>(v_i)_{i \in I} \subset \mathrm{V}</span> is absolutely summable if and only if for every element <span class='inline'>U</span> 
  of a basis of circled convex zero neighborhoods there exists a <span class='inline'>C\geq 0</span> such that
  <br><br><span class='display'>
    \sum_{i \in J} p_U \left( v_i\right) \leq C \quad \text{for all } J \in \mathscr{F} (I) .
  </span><br>
<br><br>

<br><i>Proof.</i>
  


<br><br><strong>Definition 19.7</strong>
 A family <span class='inline'>(v_i)_{i \in I}</span> in <span class='inline'>\mathrm{V}</span> is called <i>totally summable</i> if there exists a bounded 
 absolutely convex subset <span class='inline'>B\subset \mathrm{V}</span>  and a <span class='inline'>C\geq 0</span> such that
 <br><br><span class='display'>
   \sum_{i \in J} p_B \left( v_i\right) \leq C  \quad \text{for all } J \in \mathscr{F} (I) .
 </span><br>
 We write <span class='inline'>\ell^1 \langle I, \mathrm{V} \rangle</span> for the set of all totally summable families in <span class='inline'>\mathrm{V}</span>.
<br><br>

</p><h2>Summable families of complex numbers</h2><p>\addcontentslinetocsubsectionSummable families of complex numbers

<br><br><strong>Lemma 19.8</strong>[cf.~<dt-cite key="ERROR"></dt-cite>[Lem.~1.1.2]PieNLCS]
  Let <span class='inline'>(z_i)_{i\in I}</span> be a family of  complex numbers for which there exists a positive real number <span class='inline'>C  >  0</span> 
  such that 
  <br><br><span class='display'>
     \left|\sum_{i\in J} z_i \right| \leq C \quad \text{for all } J \in \mathscr{F} (I) .
  </span><br>
  Then one has the estimate
   <br><br><span class='display'>
     \sum_{i\in J}\left| z_i \right| \leq 4 C \quad \text{for all } J \in \mathscr{F} (I) .
  </span><br>
<br><br>

<br><i>Proof.</i>
  We assume first that all <span class='inline'>z_i</span> are real. Then let <span class='inline'>I^+</span> the set of all indices <span class='inline'>i\in I</span> such that <span class='inline'>z_i \geq 0</span>,
  and <span class='inline'>I^-</span> the set of all  <span class='inline'>i\in I</span> such that <span class='inline'>z_i  <  0</span>. Then, for all finite <span class='inline'>J\subset I</span>
  <br><br><span class='display'>
     \sum_{i\in J} \left| z_i \right| =  \sum_{i\in J\cap I^+}  \left| z_i  \right| +  \sum_{i\in J\cap I^-}  \left| z_i  \right|
    =  \left| \sum_{i\in J\cap I^+}  z_i  \right| +  \left| \sum_{i\in J\cap I^-}  z_i  \right| \leq 2  C .
  </span><br> 
  In the general case decompose <span class='inline'>z_i</span> into real and imaginary parts <span class='inline'>x_i = \Re z_i</span> and   <span class='inline'>y_i = \Im z_i</span>.
  By the triangle inequality one obtains for all finite <span class='inline'>J\subset I</span>
  <br><br><span class='display'>
    \sum_{i\in J} \left| z_i \right| \leq \sum_{i\in J} \left| x_i \right| + \sum_{i\in J} \left| y_i \right| \leq 4 C .
  </span><br>


<br><br><strong>Proposition 19.9</strong>

  For a  family <span class='inline'>(z_i)_{i\in I}</span> of complex numbers the following are equivalent.
  
  </p><ol class='enumeration'>

  <li value='(I)'> The family <span class='inline'>(z_i)_{i\in I}</span> is summable. 
  </li><li value='(II)'> The family <span class='inline'>(\left| z_i \right| )_{i\in I}</span> is summable.
  </li><li value='(III)'> The family <span class='inline'>(z_i)_{i\in I}</span> is absolutely summable.

  </li><li value='(IV)'> There exists some <span class='inline'>C  >  0</span> such that 
        <span class='inline'>\sum_{i\in J}\left| z_i \right| \leq C</span> for all <span class='inline'>J\in \mathscr{F} (I)</span>.
  
  </li></ol><p>

  In case that  one hence all of the conditions are fulfilled, the estimate 
  <br><br><span class='display'>
     \left|  \sum_{i\in I} z_i \right|  \leq \sum_{i\in I}\left| z_i \right| 
  </span><br>
  holds true.
<br><br>

<br><i>Proof.</i>
  Assume that  <span class='inline'>(z_i)_{i\in I}</span> is absolutely summable. Since <span class='inline'>\mathbb{C}</span> is normed with norm given by the absolut value 
  this just means that there exists some <span class='inline'>C  >  0</span> such that 
  <span class='inline'>\sum_{i\in J}\left| z_i \right| \leq C</span> for all <span class='inline'>J\in \mathscr{F} (I)</span>. Hence the supremum 
  <span class='inline'>c = \sup \left\{ \sum_{i\in J}\left| z_i \right| \mid J \in \mathscr{F} (I)\right\}</span> exists and is <span class='inline'>\leq C</span>. 
  For given <span class='inline'>\varepsilon  > 0</span> choose <span class='inline'>J_\varepsilon \in \mathscr{F} (I)</span> such that 
  <br><br><span class='display'>
        c- \varepsilon \leq \sum_{i\in J_\varepsilon}\left| z_i \right| \leq c .
  </span><br>
  Then one has for all <span class='inline'>K\in \mathscr{F} (I)</span> with <span class='inline'>K\cap J_\varepsilon = \emptyset</span> 
  <br><br><span class='display'>
     \left| \sum_{i\in K} z_i \right| \leq  \sum_{i\in K} \left| z_i \right| \leq \varepsilon .
  </span><br>
  Hence <span class='inline'>\left( \sum_{i\in J} z_i \right)_{J \in \mathscr{F} (I)}</span> is a Cauchy net, so has to
  converges  by completeness of <span class='inline'>\mathbb{C}</span>. This proves summability of   <span class='inline'>(z_i)_{i\in I}</span>.
  
  Vice versa, assume now that   <span class='inline'>(z_i)_{i\in I}</span> is summable. Then
  <span class='inline'>\left( \sum_{i\in J} z_i \right)_{J \in \mathscr{F} (I)}</span> is a Cauchy net. Hence there exists an element 
  <span class='inline'>J_1 \in  \mathscr{F} (I)</span> such that for all <span class='inline'>K\in  \mathscr{F} (I)</span> with <span class='inline'>K \cap J_1 = \emptyset</span>  
  the inequality 
  <br><br><span class='display'>
      \left| \sum_{i\in K} z_i \right|  <  1 
  </span><br>
  holds true. Let <span class='inline'>C = \sum_{i\in J_1} \left| z_i\right|</span>. Then one has for all <span class='inline'>J\in  \mathscr{F} (I)</span>
  <br><br><span class='display'>
       \left| \sum_{i\in J} z_i \right| \leq  \left| \sum_{i\in J\setminus J_1} z_i \right| +  
       \left| \sum_{i\in J\cap J_1} z_i \right| \leq 1 + C .
  </span><br>
  By the preceding lemma the set of partial sums <span class='inline'> \sum_{i\in J} \left| z_i \right|</span>, where <span class='inline'>J</span> runs through the 
  finite subsets of <span class='inline'>I</span>, is then bounded by <span class='inline'>4 + 4C</span>, hence  <span class='inline'>(z_i)_{i\in I}</span> is absolutely summable.


</p><h2>Summability in Banach spaces</h2><p>\addcontentslinetocsubsectionSummability in Banach spaces

<br><br><strong>Proposition 19.10</strong>
  Let <span class='inline'>\mathrm{V}</span> be a normed vector space. 
  For a  family <span class='inline'>(v_i)_{i\in I}</span> of elements in <span class='inline'>\mathrm{V}</span> the following are equivalent:
  
  </p><ol class='enumeration'>

  <li value='(I)'> The family <span class='inline'>(v_i)_{i\in I}</span> is absolutely summable. 
  </li><li value='(II)'> The family <span class='inline'>(\left\| v_i \right\| )_{i\in I}</span> is summable.
  </li><li value='(III)'> There exists some <span class='inline'>C  >  0</span> such that 
        <span class='inline'>\sum_{i\in J}\left\| v_i \right\| \leq C</span> for all <span class='inline'>J\in \mathscr{F} (I)</span>.
  
  </li></ol><p>

  If <span class='inline'>\mathrm{V}</span> is even a Banach space, these conditions are all equivalent to 
  
  </p><ol class='enumeration'>

  \setcounterenumi3
  <li value='(I)'> The family <span class='inline'>(v_i)_{i\in I}</span> is summable.
  
  </li></ol><p>

<br><br>
<br><i>Proof.</i>
  (II) and (III)
  are equivalent by \Crefthm:summability-criteria-family-complex-numbers
  Assume now that (I) holds true. 



<strong>to do:</strong> Carl Neumann series


</p><h2>Properties of and relations between the various summability types</h2><p>\addcontentslinetocsubsectionProperties of and relations between the various summability types 

<br><br><strong>Theorem 19.11</strong>
  Let <span class='inline'>I</span> be a non-empty index set. Then the spaces <span class='inline'>\ell^1 (I, \mathrm{V} )</span> of summable families, 
  <span class='inline'>\ell^1 [I, \mathrm{V} ]</span> of weakly summable families, <span class='inline'>\ell^1 \{I, \mathrm{V} \}</span> of absolutely summable families and
  <span class='inline'>\ell^1 \langle I, \mathrm{V} \rangle</span> of totally summable families in <span class='inline'>E</span> are all subvector spaces of 
  the product vector space <span class='inline'>E^I = \Pi_{i\in I} E</span>.   Furthermore one has the following chain of inclusions:
  <br><br><span class='display'>
     \ell^1 \langle I, \mathrm{V} \rangle\subset\ell^1 \{I, \mathrm{V} \}   \quad\text{and} \quad \ell^1 (I, \mathrm{V}) \subset \ell^1 [I, \mathrm{V} ] .
  </span><br> 
  If <span class='inline'>E</span> is complete, then one even has 
   <br><br><span class='display'>
        \ell^1 \{I, \mathrm{V} \}   \subset \ell^1 (I, \mathrm{V})     
   </span><br>
<br><br>

<br><i>Proof.</i>
    Now let <span class='inline'>(v_i)</span> be a summable family and <span class='inline'>\alpha : \mathrm{V} \to \mathbb{K}</span> a continuous linear form. 

 Let <span class='inline'>U</span> be an absolutely convex zero neighborhood. Then <span class='inline'>U</span> absorbes <span class='inline'>B</span>, so there exists <span class='inline'>r > 0</span> such that
 <span class='inline'>B \subset rU</span>. Hence




</p><h1>20 Topological tensor products</h1><p>

<br><br><strong>Definition 20.1</strong>[cf.~<dt-cite key="ERROR"></dt-cite>[Chap.~I, \S\,3, n<span class='inline'>^\text{o}</span>\,3]GroPTTEN]
  Let <span class='inline'>\mathrm{V}</span> and <span class='inline'>\mathrm{W}</span> be two locally convex topological vector spaces over the ground field <span class='inline'>\mathbb{K}</span>. 
  A locally convex vector topology <span class='inline'>\tau</span> on the (algebraic) tensor product <span class='inline'>\mathrm{V} \otimes \mathrm{W}</span> 
  is called <i>compatible with the tensor product structure</i>, an <i>admissible tensor product topology</i>
  or just <i>admissible</i>  if the following conditions hold true:
  </p><ol class='enumeration'>
  <li value=' (ATPT1)'>
     The canonical map <span class='inline'>\mathrm{V} \times \mathrm{W}  \to \mathrm{V} \otimes_\tau \mathrm{W}</span> is seperately continuous
     that is  for each <span class='inline'>v \in \mathrm{V}</span> and each <span class='inline'>w\in\mathrm{W}</span> the linear maps 
     <br><br><span class='display'> \mathrm{W} \to  \mathrm{V} \otimes_\tau \mathrm{W}, y \mapsto v \otimes y \quad\text{and} \quad
        \mathrm{V} \to  \mathrm{V} \otimes_\tau \mathrm{W}, x \mapsto x \otimes w </span><br>
     are continuous where <span class='inline'>\mathrm{V} \otimes_\tau \mathrm{W} </span> denotes the vector space 
     <span class='inline'>\mathrm{V} \otimes \mathrm{W}</span> equipped with <span class='inline'>\tau</span>. 
  </li><li value=' (ATPT2)'> For all linear maps <span class='inline'>\alpha \in \mathrm{V}'</span> and <span class='inline'>\beta \in \mathrm{W}'</span> the canonical linear map 
     map <span class='inline'>\alpha \otimes \beta :  \mathrm{V} \otimes_\tau \mathrm{W} \to  \mathbb{K}</span>
     is continuous. 
  </li><li value=' (ATPT3)'> For every equicontinuous subset <span class='inline'>A \subset \mathrm{V}'</span> and equicontinuous subset <span class='inline'>B\subset \mathrm{W}'</span>
     the set <span class='inline'>\left\{ \alpha \otimes \beta \mid \alpha \in A \:\&\: \beta \in B \right\}</span> is an
     equicontinuous subset of the topological dual of <span class='inline'>\mathrm{V} \otimes_\tau \mathrm{W}</span>. 
  </li></ol><p>
  The locally convex vector topology <span class='inline'>\tau</span>   
  is called <i>strongly compatible with the tensor product structure</i>, 
  a <i>strongly admissible tensor product topology</i> or briefly <i>strongly admissible</i> 
  if it satisfies:
  </p><ol class='enumeration'>
  <li value='{\sffamily (sATPT)}'>
     The canonical map <span class='inline'>\mathrm{V} \times \mathrm{W}  \to \mathrm{V} \otimes_\tau \mathrm{W}</span> is continuous where
      <span class='inline'>\mathrm{V} \times \mathrm{W}</span> carries the product topology. 
  </li></ol><p>
<br><br>

<br><br><strong>20.2</strong>
The admissible  respectively strongly admissible vector topologies on <span class='inline'> \mathrm{V} \otimes \mathrm{W}</span> are obviously partially ordered 
by set-theoretic inclusion. Therefore, the following definition makes sense.

<br><br><strong>Definition 20.3</strong>
  
<br><br>


\chapterBanach Spaces and Algebras

</p><h1>21 Functional calculus</h1><p>




\chapterHilbert Spaces


</p><h1>22 Inner product spaces</h1><p>

<br><br><strong>22.1</strong> 
Let us first remind the reader that as before <span class='inline'>\mathbb{K}</span> stands for the field 
of real or of complex numbers. We will keep this notational agreement 
throughout the whole chapter.
<br><br><strong>Definition 22.2</strong>
By a <i>sesquilinear form</i> on a <span class='inline'>\mathbb{K}</span>-vector space <span class='inline'>\mathrm{V}</span> one understands a map
<span class='inline'>\langle \cdot , \cdot \rangle : \mathrm{V} \times \mathrm{V} \to \mathbb{K}</span>
with the following two properties:
</p><ol class='enumeration'>
<li value='( SF1)'>
 
  The map <span class='inline'>\langle \cdot , \cdot \rangle</span> is <i>linear</i> in its first coordinate which means that
  <br><br><span class='display'>
    \langle v_1 + v_2, w \rangle = \langle v_1, w \rangle + \langle v_2, w \rangle
    \quad \text{and} \quad \langle r v, w \rangle = r \langle v, w \rangle
  </span><br>
  for all  <span class='inline'>v, w , v_1,v_2 \in \mathrm{V}</span> and <span class='inline'>r\in \mathbb{K}</span>.
</li><li value='( SF2)'>
  
  The map <span class='inline'>\langle \cdot , \cdot \rangle</span> is <i>conjugate-linear</i> in its second coordinate which means that
  <br><br><span class='display'>
    \langle v_1 + v_2, w \rangle = \langle v_1, w \rangle + \langle v_2, w \rangle
    \quad \text{and} \quad \langle  v, r w \rangle = \overline{r} \langle v, w \rangle
  </span><br>
  for all  <span class='inline'>v, w , v_1,v_2 \in \mathrm{V}</span> and <span class='inline'>r\in \mathbb{K}</span>.
</li></ol><p>
A <i>hermitian form</i> is a sesquilinear form <span class='inline'>\langle \cdot , \cdot \rangle</span> on <span class='inline'>\mathrm{V}</span> with the following
additional property:
</p><ol class='enumeration'>
<li value='( SF1)'>
 
  The map <span class='inline'>\langle \cdot , \cdot \rangle</span> is <i>conjugate symmetric</i> which means that 
  <br><br><span class='display'>
    \langle v, w \rangle = \overline{\langle w, v \rangle} \quad \text{for all  } v, w \in \mathrm{V} .
  </span><br>
</li></ol><p>
A sesquilinear form  <span class='inline'>\langle \cdot , \cdot \rangle</span> is  called
<i>weakly-nondegenerate</i> if it satisfies axiom
</p><ol class='enumeration'>
<li value='( SF1'>
 
  For every <span class='inline'>v\in \mathrm{V}</span>, the map <span class='inline'>\mathrm{V} \to \mathbb{K}</span>, <span class='inline'>w \to \langle w,v \rangle</span> is the zero 
  map if and only if <span class='inline'>v=0</span>.
</li></ol><p>
Finally, one calls a hermitian form  <span class='inline'>\langle \cdot , \cdot \rangle</span> on <span class='inline'>\mathrm{V}</span>   
<i>positive semidefinite</i> if
</p><ol class='enumeration'>
<li value='( SF1'>
 
  <span class='inline'>\langle v,v \rangle \geq 0</span> for all <span class='inline'>v\in \mathrm{V}</span>.
</li></ol><p>
<br><br>

<br><br><strong>Remark 22.3</strong>
Recall that a map  <span class='inline'>\langle \cdot , \cdot \rangle : \mathrm{V} \times \mathrm{V} \to \mathbb{K}</span> is called <i>bilinear</i>,
if it satisfies ( SF1) and 
</p><ol class='enumeration'>
<li value=' (BF1)'>
  
  The map <span class='inline'>\langle \cdot , \cdot \rangle</span> is <i>linear</i> in its second coordinate which means that
  <br><br><span class='display'>
    \langle v_1 + v_2, w \rangle =  \langle  v_1, w \rangle + \langle v_2, w \rangle
    \quad \text{and} \quad \langle  v, r w \rangle = r \langle v, w \rangle
  </span><br>
  for all  <span class='inline'>v, v_1,v_2, w \in \mathrm{V}</span> and <span class='inline'>r\in \mathbb{K}</span>.
</li></ol><p>
If the underlying ground field <span class='inline'>\mathbb{K}</span> coincides with the field of real numbers, 
a sesquilinear form is by definition the same as a bilinear form,
and a hermitian form the same as a symmetric bilinear form. 
<br><br>

<br><br><strong>22.4</strong> 
Given a positive semidefinite hermitian form <span class='inline'>\langle \cdot , \cdot \rangle</span> on a 
<span class='inline'>\mathbb{K}</span>-vector space <span class='inline'>\mathrm{V}</span>, one calls two vectors <span class='inline'>v,w \in \mathrm{V}</span> <i>orthogonal</i> 
if <span class='inline'>\langle v , w \rangle = 0</span>. Since the hermitian form 
<span class='inline'>\langle \cdot , \cdot \rangle</span> is assumed to be positive semidefinite, the map 
<br><br><span class='display'>
 \| \cdot \| : \mathrm{V} \to \mathbb{R}_{\geq 0} , \: v \mapsto \|v \| = \sqrt{\langle v , v \rangle} 
</span><br>
is well-defined. We will later see that <span class='inline'>\| \cdot \|</span>  is a seminorm on <span class='inline'>\mathrm{V}</span>
and therefore call the map <span class='inline'>\| \cdot \|</span> the <i>seminorm associated to</i>
<span class='inline'>\langle \cdot , \cdot \rangle</span>. The following formulas are immediate consequences of the 
properties defining a positive semidefinite hermitian form and the definition
of the associated seminorm: 
<br><br><span class='display'> \tag{22.1} 
  
   \| v+w \|^2  = \| v\|^2 + 2\, \Re \, \langle  v ,  w \rangle + \| w\|^2 \quad \text{for all } 
  v,w \in \mathrm{V} , </span><br><br><span class='display'>
  
   \| v+w \|^2  = \| v\|^2 + \| w\|^2 \quad \text{for all orthogonal } v,w \in \mathrm{V} ,  </span><br><br><span class='display'>
   
   \| v+w \|^2  + \|v-w\|^2  = 2 \big( \| v\|^2 + \| w\|^2 \big) \quad \text{for all } v,w \in \mathrm{V},</span><br><br><span class='display'>
   
   \| rv \| = \sqrt{ |r|^2 \langle  v ,  v \rangle }  = |r| \| v \| 
  \quad \text{for all } v,w \in \mathrm{V} \text{ and } r\in \mathbb{K} .
</span><br><br> 
Formula \eqrefeq:pythagorean-theorem is an abstract version of the <i>pythagorean theorem</i>,
\Crefeq:parallelogram-identity is called the <i>parallelogram identity</i>. 
The triangle inequality for the map <span class='inline'>\| \cdot \|</span>  will turn out to be a consequence of the 
following result. 

<br><br><strong>Proposition 22.5</strong>[Cauchy--Schwarz inequality]

Given a positive semidefinite hermitian form <span class='inline'>\langle \cdot , \cdot \rangle</span> on a <span class='inline'>\mathbb{K}</span>-vector space 
<span class='inline'>\mathrm{V}</span> the following inequality holds true:
<br><br><span class='display'> \tag{22.2}

  |\langle v, w \rangle| \leq \|v\|\|w\| \quad \text{for all $v,w \in \mathrm{V}$}.
</span><br><br>
Equality holds if and only if <span class='inline'>v</span> and <span class='inline'>w</span> are linearly dependant.
<br><br>
<br><i>Proof.</i>
If <span class='inline'>v</span> or <span class='inline'>w</span> is <span class='inline'>0</span>, the proof is trivial, hence we can assume both to be nonzero. Put
<br><br><span class='display'>
  c = - \frac{\langle v, w \rangle}{\|v\|^2}
</span><br>
and compute
<br><br><span class='display'> \tag{22.3}


   0  \leq \|c v + w\|^2 = \langle c v + w, c v + w \rangle = 
   |c|^2 \langle v, v \rangle + c \langle v, w \rangle + 
   \overline{c}\langle w, v \rangle + \langle w, w \rangle = </span><br><br><span class='display'>
    =  |c|^2\|v\|^2 + 2 \, \Re \big( c\langle v, w \rangle \big) + \|w\|^2 = 
   \frac{|\langle v, w \rangle|^2}{\|v\|^2} - 2\frac{|\langle v, w \rangle|^2}{\|v\|^2} + \|w\|^2 = </span><br><br><span class='display'>
    = \|w\|^2 - \frac{|\langle v, w \rangle|^2}{\|v\|^2} .
 
</span><br><br>
Hence
<br><br><span class='display'>
   |\langle v, w \rangle|^2 \leq \|v\|^2\|w\|^2 
</span><br>
which entails the Cauchy--Schwarz inequality. 

If <span class='inline'>v,w</span> are linearly dependant nonzero elements of <span class='inline'>\mathrm{V}</span>, then there exists a nonzero scalar 
<span class='inline'>a\in \mathbb{K}</span> such that <span class='inline'>v = a w</span>. Hence 
<br><br><span class='display'>
  |\langle v , w \rangle| = |a| \, \| w \|^2 
  = \| v \|  \| w \| \, .
</span><br>
Vice versa, if equality holds, then \Crefeq:expanding-norm-of-sum-in-inner-product-space 
entails that <span class='inline'>c v +w  = 0</span>, which means that <span class='inline'>v</span> and <span class='inline'>w</span> are linearly dependant. 


<br><br><strong>Lemma 22.6</strong>

  A positive semidefinite hermitian form <span class='inline'>\langle \cdot , \cdot \rangle</span> on a <span class='inline'>\mathbb{K}</span>-vector space 
  <span class='inline'>\mathrm{V}</span> is weakly-nondegenerate if and only if it is <i>positive definite</i> that is if and only if
  </p><ol class='enumeration'>
  \setcounterenumi4
  <li value='( SF1'>
   
  <span class='inline'>\langle v,v \rangle  >  0</span> for all <span class='inline'>v\in \mathrm{V} \setminus \{ 0 \}</span>.
  </li></ol><p>
<br><br>

<br><i>Proof.</i>
  A positive definite real bilinear or complex  hermitian form <span class='inline'>\langle \cdot , \cdot \rangle</span> is 
  non-degenerate since for every <span class='inline'>v \in \mathrm{V} \setminus \{ 0 \}</span> the  linear form
  <span class='inline'>\langle - ,v \rangle : \mathrm{V} \to \mathbb{K}</span> then is  nonzero  because  <span class='inline'>\langle v,v \rangle  >  0</span>.

  Conversely, if <span class='inline'>\langle - ,v \rangle : \mathrm{V} \to \mathbb{K}</span> is nonzero for all 
  <span class='inline'>v \in \mathrm{V} \setminus \{ 0 \}</span>, then  there exists an element <span class='inline'>w \in \mathrm{V}</span> such that 
  <span class='inline'>\langle w,v \rangle \neq 0</span>. The Cauchy--Schwarz inequality entails
  <br><br><span class='display'>
    0  <  |\langle w,v \rangle |^2 \leq \langle w,w \rangle \, \langle v,v \rangle ,
  </span><br>
  which implies <span class='inline'>\langle v,v \rangle  >  0</span>. Hence <span class='inline'>\langle \cdot , \cdot \rangle</span> is positive definite.



<br><br><strong>Proposition 22.7</strong>
 The map 
 <br><br><span class='display'>
  \| \cdot \| :V \to \mathbb{R}_{\geq 0} , \: v \mapsto \|v \| = \sqrt{\langle v , v \rangle} 
 </span><br>
 associated to a positive semidefinite hermitian form 
 <span class='inline'>\langle \cdot , \cdot \rangle</span> on a <span class='inline'>\mathbb{K}</span>-vector space <span class='inline'>\mathrm{V}</span> is a seminorm. 
 If the hermitian form is positive definite, then <span class='inline'>\| \cdot \|</span> is even  a norm. 
<br><br>
<br><i>Proof.</i>
 Absolute homogeneity  (N2) is given by Eq.~\eqrefeq:absolute-homogeneity.
 The triangle inequality is a consequence of the Cauchy--Schwarz inequality:
 <br><br><span class='display'>
   \| v + w \|^2 =   \| v\|^2 + 2 \, \Re \, \langle  v ,  w \rangle + \| w\|^2 \leq
    \| v\|^2 + 2 \, \|  v \| \, \| w \| + \| w\|^2 = \big(\| v\|+\| w\| \big)^2 .
 </span><br> 
 Finally, if <span class='inline'>\langle \cdot , \cdot \rangle</span> is positive definite, then 
 <span class='inline'>\| v \| = \sqrt{\langle v , v \rangle}  >  0 </span> for all <span class='inline'>v \in \mathrm{V} \setminus \{ 0 \}</span>,
 so <span class='inline'>\| \cdot \|</span> is  a norm.



 Hilbert space definition
<br><br><strong>Definition 22.8</strong> 

By an <i>inner product</i> or a <i>scalar product</i> on a <span class='inline'>\mathbb{K}</span>-vector space <span class='inline'>\mathfrak{H}</span> one 
understands a positive definite hermitian form on <span class='inline'>\mathfrak{H}</span>. A <span class='inline'>\mathbb{K}</span>-vector space <span class='inline'>\mathfrak{H}</span> 
together with an inner product <span class='inline'>\langle \cdot , \cdot \rangle : \mathfrak{H} \times \mathfrak{H} \to \mathbb{K}</span> is 
called an <i>inner product space</i> or a <i>pre-Hilbert space</i>. 

A hermitian form on a  <span class='inline'>\mathbb{K}</span>-vector space <span class='inline'>\mathfrak{H}</span> which is only positive semidefinite is called a <i>semi-inner product</i> or a <i>semi-scalar product</i>.

A <i>Hilbert space</i> is an inner product space  <span class='inline'>(\mathfrak{H} , \langle \cdot , \cdot \rangle)</span>  which is 
complete as a normed vector space. In other words, a Hilbert space is Banach space where the 
norm on the space is induced by an inner product.
<br><br>

<br><br><strong>Examples 22.9</strong>


  </p><ol class='enumeration'>

<li value='(a) '> The vector space <span class='inline'>\mathbb{R}^n</span> with the <i>euclidean inner product</i> 
      <br><br><span class='display'> 
        \langle \cdot , \cdot \rangle : \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}, \:
        \big( (v_1,\ldots , v_n),(w_1,\ldots , w_n) \big) \mapsto 
        \sum_{i=1}^n v_i w_i  
      </span><br>
      is a real Hilbert space. Obviously, <span class='inline'>\langle \cdot , \cdot \rangle</span> is linear in the first argument,
      symmetric, and positive definite, hence a real inner product. The associated norm is 
      the <i>euclidean norm</i>. We have seen before that <span class='inline'>\mathbb{R}^n</span> with the euclidean norm is complete.      
</li><li value='(b) '> The vector space <span class='inline'>\mathbb{C}^n</span> together with the hermitian form 
      <br><br><span class='display'>
        \langle \cdot , \cdot \rangle : \mathbb{C}^n \times \mathbb{C}^n \to \mathbb{C}, \:
        \big( (v_1,\ldots , v_n),(w_1,\ldots , w_n) \big) \mapsto 
        \sum_{i=1}^n v_i\overline{w}_i
      </span><br>
      is a complex Hilbert space. One immediately verifies that <span class='inline'>\langle \cdot , \cdot \rangle</span> is linear in the first argument,
      conjugate symmetric, and positive definite. Hence <span class='inline'>\langle \cdot , \cdot \rangle</span> is a complex inner product which we 
      sometimes call the <i>standard hermitian inner product</i> on <span class='inline'>\mathbb{C}^n</span>.  Its associated norm is again the euclidean 
      norm, so by completeness of <span class='inline'>\mathbb{C}^n\cong \mathbb{R}^{2n}</span> endowed with the euclidean norm one obtains the claim.      
</li><li value='(c) '> The set 
      <br><br><span class='display'>
        \ell^2 = 
        \left\{(z_k)_{k\in \mathbb{N}} \in \mathbb{C}^\mathbb{N} \;\ifnum\currentgrouptype=16 \middle\fi|\; \sum_{k=0}^\infty |z_k|^2  <  \infty \right\}
      </span><br>
      of square summable sequences of complex numbers  is a complex Hilbert space 
      with inner product
      <br><br><span class='display'>
        \langle \cdot , \cdot \rangle :
        \ell^2 \times \ell^2 \to \mathbb{C}, \: \big((z_k)_{k\in \mathbb{N}},(w_k)_{k\in \mathbb{N}} \big)
        \mapsto \sum_{k=0}^\infty z_k \overline{w}_k .
      </span><br>
      To prove this one needs to first verify that <span class='inline'>\ell^2</span> is a subvector space of <span class='inline'>\mathbb{C}^\mathbb{N}</span>. 
      For <span class='inline'>z = (z_k)_{k\in \mathbb{N}} \in \mathbb{C}^\mathbb{N}</span> denote by <span class='inline'>\| z\|</span> the <i>extended norm</i> 
      <span class='inline'>\sqrt{\sum_{k=0}^\infty |z_k|^2} = \sup\limits_{K\in \mathbb{N}} \sqrt{\sum_{k=0}^K |z_k|^2} \in  {[ 0,\infty ]} </span>.
      Then <span class='inline'>z\in \ell^2</span> if and only if <span class='inline'>\|z\|  <  \infty</span>. Now let <span class='inline'>a \in \mathbb{C}</span> and <span class='inline'>z\in \ell^2</span> and compute
      <br><br><span class='display'>
         \| a z \| = \sqrt{\sum_{k=0}^\infty |a  z_k|^2} = |a| \, \sqrt{\sum_{k=0}^\infty |z_k|^2} = |a| \cdot \| z \|  <  \infty .
      </span><br> 
      Hence <span class='inline'>az \in \ell^2</span>. If <span class='inline'>z,w \in \ell^2</span>, denote for each <span class='inline'>K\in \mathbb{N}</span> by <span class='inline'>z_{(K)}</span> and <span class='inline'>w_{(K)}</span> the ``cut-off'' 
      vectors <span class='inline'>(z_0, \ldots , z_K) \in \mathbb{C}^{K+1}</span> and  <span class='inline'>(w_0, \ldots , w_K) \in \mathbb{C}^{K+1}</span>, respectively. 
      By the triangle inequality for the norm on the Hilbert space <span class='inline'>\mathbb{C}^{K+1}</span>  one concludes 
      <br><br><span class='display'>
         \sqrt{\sum_{k=0}^K  | z_k + w_k |^2} =  \| z_{(K)} + w_{(K)} \| \leq 
         \| z_{(K)} \| + \| w_{(K)} \| \leq \| z \| + \| w \|  <  \infty .
      </span><br> 
      Therefore, the sequence of partial sums <span class='inline'>\sum_{k=0}^K  | z_k + w_k |^2</span>, <span class='inline'>K\in \mathbb{N}</span>, is bounded,
      so convergent by the the monotone convergence theorem. One  obtains 
       <br><br><span class='display'>
          \| z + w \| = \lim_{K\to\infty} \sqrt{ \sum_{k=0}^K  | z_k + w_k |^2} \leq \| z \| + \| w \|  <  \infty .
      </span><br>
      Hence  <span class='inline'>z + w</span> is square summable and <span class='inline'>\ell^2</span> a vector subspace of <span class='inline'>\mathbb{C}^\mathbb{N}</span> indeed. 
      Note that our argument also shows that the restriction of the extended norm to <span class='inline'>\ell^2</span> is a norm. 

      We need to show that <span class='inline'>\langle \cdot , \cdot \rangle</span> is well-defined. 
      To this end it suffices to prove that for all <span class='inline'>z,w \in\ell^2</span> the family <span class='inline'>\left( z_k \overline{w}_k\right)_{k\in \mathbb{N}}</span> 
      is absolutely summable or in other words that <span class='inline'>\sum_{k=0}^\infty \left| z_k \overline{w}_k \right|  <  \infty</span>. 
      One concludes by the H\"older inequality for  sums  
      <br><br><span class='display'>
        \sum_{k=0}^K \left| z_k  \overline{w}_k \right| = \sum_{k=0}^K \left| z_k  w_k \right| 
                \leq \| z_{(K)} \| \,  \| w_{(K)} \| \leq  \| z \| \,  \| w \| .
      </span><br>
      So the left hand side has an upper bound uniform in <span class='inline'>K</span> which by the monotone convergence theorem entails
      convergence of the partial sums and the estimate 
      <br><br><span class='display'>
         \sum_{k=0}^\infty \left| z_k \overline{w}_k \right| \leq  \| z \| \,  \| w \|  <  \infty . 
      </span><br> 
      By definition it is clear that <span class='inline'> \langle \cdot , \cdot \rangle </span> is linear in the first argument, 
      conjugate symmetric and positive definite, hence a complex inner product. Note that the norm 
      associated to  <span class='inline'> \langle \cdot , \cdot \rangle </span> coincides with the above defined map <span class='inline'>\| \cdot \|</span>. 

      It remains to be shown that <span class='inline'>\ell^2</span> is complete. Let <span class='inline'>(z^n)_{n\in \mathbb{N}}</span> with <span class='inline'>z^n = {(z^n_k)}_{k\in \mathbb{N}}\in \ell^2</span>
      for all <span class='inline'>n\in \mathbb{N}</span> be a Cauchy sequence in <span class='inline'>\ell^2</span>.    
      For <span class='inline'>\varepsilon  > 0</span> choose <span class='inline'>N_\varepsilon \in \mathbb{N}</span> so that
      <br><br><span class='display'>
        \| z^n - z^m   \| <  \varepsilon \quad \text{for all } n,m \geq N_\varepsilon . 
      </span><br>
      For each fixed <span class='inline'>k\in \mathbb{N}</span> one therefore has 
      <br><br><span class='display'> \tag{22.4}
        
        | z^n_k - z^m_k | \leq \| z^n - z^m   \| <  \varepsilon \quad \text{for all } n,m \geq N_\varepsilon . 
      </span><br><br>
      By completeness of <span class='inline'>\mathbb{C}</span> there exist <span class='inline'>z_k \in \mathbb{C}</span> such that <span class='inline'>\lim_{n\to\infty} z^n_k = z_k</span> for all <span class='inline'>k\in \mathbb{N}</span>. 
      We claim that <span class='inline'>z = (z_k)_{k\in \mathbb{N}}</span> is an element of <span class='inline'>\ell^2</span> and that <span class='inline'>(z^n)_{n\in \mathbb{N}}</span> converges to <span class='inline'>z</span>.
      To verify this observe that for all <span class='inline'>\varepsilon  > 0</span>, <span class='inline'>K\in \mathbb{N}</span> and <span class='inline'>n\geq N_\varepsilon</span>
      <br><br><span class='display'>
        \sum_{k=0}^K  | z_k - z^n_k |^2 = \lim_{m\to\infty}  \sum_{k=0}^K  | z^m_k - z^n_k |^2 
        \leq \sup_{m \geq N_\varepsilon} \sum_{k=0}^K  | z^m_k - z^n_k |^2 
        \leq \sup_{m \geq N_\varepsilon} \| z^m - z^n \|^2 \leq \varepsilon^2 . 
      </span><br>
      This implies by the triangle inequality and the fact that the Cauchy sequence <span class='inline'>(z^n)_{n\in \mathbb{N}}</span> is bounded in norm by some 
      <span class='inline'>C > 0</span> that for all <span class='inline'>K\in \mathbb{N}</span> and <span class='inline'>N = N_1</span>
      <br><br><span class='display'>
        \sqrt{\sum_{k=0}^K  | z_k|^2 } = \| z_{(K)} \| \leq  \| z_{(K)} - z^N_{(K)} \| + \| z^N_{(K)} \| 
        \leq  \| z_{(K)} - z^N_{(K)} \| + \| z^N \| 
        \leq 1 + C . 
      </span><br>
      Hence <span class='inline'> \| z \|= \sqrt{\sum_{k=0}^\infty | z_k|^2 } \leq 1 + C </span>  and <span class='inline'>z \in \ell^2</span>. In addition one obtains
      <br><br><span class='display'>
       \| z - z^n \| = \lim_{K\to\infty} \sqrt{\sum_{k=0}^K  | z_k - z^n_k |^2} \leq \varepsilon \quad \text{for all } n \geq N_\varepsilon . 
      </span><br>
      This means that <span class='inline'>z</span> is the limit of the sequence <span class='inline'>(z^n)_{n\in \mathbb{N}}</span> and <span class='inline'>\ell^2</span> is complete. 
</li><li value='(d) '> Let 
      <br><br><span class='display'> 
        \mathscr{L}^2(\mathbb{R}^n) = \left\{ f : \mathbb{R}^n \to \mathbb{C} \;\ifnum\currentgrouptype=16 \middle\fi|\; f
        \text{ is Lebesgue measurable and }
        \int_{\mathbb{R}^n}|f|^2 d\lambda  <  \infty \right\}
      </span><br> 
      denote the space of Lebesgue square integrable functions on <span class='inline'>\mathbb{R}^n</span>. 
      Then the map    
      <br><br><span class='display'>
          \langle \cdot , \cdot \rangle : \mathscr{L}^2(\mathbb{R}^n) \times  \mathscr{L}^2(\mathbb{R}^n) \to \mathbb{C}, \: 
         (f,g) \mapsto \int_{\mathbb{R}^n}f\overline{g}\, d\lambda
      </span><br>
      is a positive semidefinite hermitian form on <span class='inline'>\mathscr{L}^2(\mathbb{R}^n)</span>. 
      Modding out <span class='inline'>\mathscr{L}^2(\mathbb{R}^n)</span> by the kernel 
      <br><br><span class='display'> 
        \mathscr{N} := \operatorname{Ker} (\| \cdot \|) = 
        \left\{ f \in \mathscr{L}^2(\mathbb{R}^n) \;\ifnum\currentgrouptype=16 \middle\fi|\; \int_{\mathbb{R}^n}|f|^2 d\lambda = 0 \right\}
      </span><br>
      gives the Lebesgue space
      <br><br><span class='display'>
          L^2 (\mathbb{R}^n) := \mathscr{L}^2(\mathbb{R}^n) / \mathscr{N} .
      </span><br>
      
      The hermitian form <span class='inline'>\langle \cdot , \cdot  \rangle </span> vanishes on <span class='inline'>\mathscr{N} \times  \mathscr{L}^2(\mathbb{R}^n)</span> and 
      <span class='inline'>\mathscr{L}^2(\mathbb{R}^n) \times \mathscr{N}</span> by the Cauchy--Schwarz inequality, hence descends to a hermitian form
      <br><br><span class='display'>
        \langle \cdot , \cdot \rangle : L^2(\mathbb{R}^n) \times  L^2(\mathbb{R}^n) \to \mathbb{C}, \:
        (f + \mathscr{N} ,g+ \mathscr{N}) \mapsto \int_{\mathbb{R}^n}f\overline{g}\, d\lambda .
      </span><br>
      That hermitian form is positive definite, since 
      <span class='inline'>\langle f + \mathscr{N}, f + \mathscr{N} \rangle = 0</span> means 
      <span class='inline'> \int_{\mathbb{R}^n}|f|^2 d\lambda =0</span>, hence <span class='inline'>f\in \mathscr{N}</span>.
      So <span class='inline'>L^2(\mathbb{R}^n)</span> together with <span class='inline'>\langle \cdot , \cdot \rangle </span> is a 
      Hilbert space which we call the 
      <i>Hilbert space of square-integrable functions</i> on <span class='inline'>\mathbb{R}^n</span>. 
      \mbox 
\bfseries to be added: provide details on well-definedness of hermitian form and show completeness     

  </li></ol><p>

<br><br>

 Theorem giving condition to relate inner product with norm

<br><br><strong>Theorem 22.10</strong> 

Let <span class='inline'>\mathrm{V}</span> be a normed <span class='inline'>\mathbb{K}</span>-vector space. Then the norm <span class='inline'>\|\cdot\| : \mathrm{V} \to \mathbb{R}_{\geq 0}</span>
is associated to an inner product <span class='inline'>\langle \cdot , \cdot \rangle :  \mathrm{V} \times \mathrm{V} \to \mathbb{K}</span> 
if and only if the <i>parallelogram identity</i> 
<br><br><span class='display'>
  \| v + w \|^2 + \| v -  w\|^2 = 2\|v\|^2 + 2\|w\|^2 
</span><br>
holds true for all <span class='inline'>v,w \in \mathrm{V}</span>. In this case, the inner product of two elements <span class='inline'>v,w\in \mathrm{V}</span>
can be expressed by the <i>polarization identity for</i> <span class='inline'>\mathbb{K} = \mathbb{R}</span>
<br><br><span class='display'> \tag{22.5}
  
  \langle v , w \rangle = \frac 14 \left( \| v + w \|^2  - \| v - w \|^2 \right)
  = \frac 12 \left( \| v + w \|^2  - \| v \|^2 - \| w \|^2 \right)
</span><br><br>
respectively by the  <i>polarization identity for</i> <span class='inline'>\mathbb{K} = \mathbb{C}</span>
<br><br><span class='display'> \tag{22.6}
  
  \langle v , w \rangle = \frac 14 \sum_{k=1}^4 \mathfrak{i}^k \, \| v + \mathfrak{i}^k \, w \|^2  .
</span><br><br>
<br><br>
<br><i>Proof.</i>
The forward direction is a consequence of
label_error, Eq.~(22.1). 
To show the backward direction we consider two cases <span class='inline'>\mathbb{K} = \mathbb{R}</span> and 
<span class='inline'>\mathbb{K} = \mathbb{C}</span> separately.

\textit1.~Case. Given the norm <span class='inline'>\|\cdot\|</span> define <span class='inline'>\langle \cdot , \cdot \rangle : \mathrm{V} \times \mathrm{V} \to \mathbb{R}</span> by real polarization
<br><br><span class='display'>
   \langle v , w \rangle = \frac 14 \left( \| v + w \|^2  - \| v - w \|^2 \right), \quad \text{where } v,w\in \mathrm{V}  .
</span><br>
Note that the parallelogram identity entails
<br><br><span class='display'>
  \frac 14 \left( \| v + w \|^2  - \| v - w \|^2 \right) =  
  \frac 12 \left( \| v + w \|^2  - \| v \|^2 - \| w \|^2 \right) . 
</span><br>
Observe that by definition <span class='inline'>\langle v , w \rangle = \langle w , v \rangle</span> and <span class='inline'>\| v \| = \sqrt{ \langle v , v \rangle}</span>.
Let us show additivity in the first variable. Let <span class='inline'>v_1,v_2,w \in \mathrm{V}</span> and compute using the parallelogram identity 
<br><br><span class='display'>
  
     \| v_1 + v_2 + w \|^2  = 2 \| v_1 + w \|^2 + 2 \| v_2\|^2 -  \| v_1 + w - v_2\|^2 , </span><br><br><span class='display'> 
     \| v_1 + v_2 + w \|^2  = 2 \| v_2 + w \|^2 + 2 \| v_1\|^2 -  \| v_2 + w - v_1\|^2 .
  
</span><br>
Hence 
<br><br><span class='display'>
  
     \| v_1 + v_2 \pm w \|^2  =  
     \| v_1 \pm w \|^2 +  \| v_2 \pm w \|^2 +  \| v_1\|^2 + \| v_2\|^2 -  \| v_1 \pm w - v_2\|^2  -  \| v_2 \pm w - v_1\|^2 .
  
</span><br>
Subtracting the <span class='inline'>-</span> version from the <span class='inline'>+</span> version of this equation entails
<br><br><span class='display'>
  
    \langle v_1 + v_2 , w \rangle \,  = \frac 14 \left( \| v_1 + v_2 + w \|^2  - \| v_1 + v_2 - w \|^2 \right)= </span><br><br><span class='display'>
     = \frac 14 \left( \| v_1 + w \|^2 +  \| v_2 + w \|^2 -  \| v_1 - w \|^2 -  \| v_2 - w \|^2 \right) =
    \langle v_1  , w \rangle +  \langle v_2 , w \rangle ,
  
</span><br>
so additivity in the first variable is proved. By induction  one derives from this that 
for all natural <span class='inline'>n</span>
<br><br><span class='display'> \tag{22.7}

  \langle nv , w \rangle = n \langle v , w \rangle \quad \text{for all } v,w \in \mathrm{V}  . 
</span><br><br>
Since then <span class='inline'>\langle - nv , w \rangle - n \langle v , w \rangle = \langle -nv + nv , w \rangle = 0</span> for all <span class='inline'>n\in \mathbb{N}</span>,
Eq.~\eqrefeq:natural-number-homogeneity also holds for <span class='inline'>n\in \mathbb{Z}</span>. 
Now let <span class='inline'>p\in \mathbb{Z}</span> and <span class='inline'>q \in \mathbb{N}_{ >  0}</span>. Then <span class='inline'> q\, \langle \frac pq v , w \rangle = \langle p v , w \rangle = p \, \langle  v , w \rangle</span>, 
hence one has for rational <span class='inline'>r</span>
<br><br><span class='display'> \tag{22.8}

 \langle rv , w \rangle = r \langle v , w \rangle \quad \text{for all } v,w \in \mathrm{V}  . 
</span><br><br>
Since addition, multiplication by scalars and the norm are continuous, the function 
<br><br><span class='display'>
   \mathbb{R} \to \mathbb{R}, \:r \mapsto  \langle rv , w \rangle - r \langle v , w \rangle = \frac 14 \left( \| r v + w \|^2 + r \|  v - w \|^2   - \| rv - w \|^2 -  r \|  v + w \|^2 \right) 
</span><br>
is continuous. Since  it vanishes over <span class='inline'>\mathbb{Q}</span>, it has to coincide with the zero map. Therefore, 
Eq.~\eqrefeq:rational-number-homogeneity holds for all <span class='inline'>r\in \mathbb{R}</span>. So <span class='inline'>\langle \cdot , \cdot \rangle</span> is linear in 
the first coordinate. By symmetry, it is so too in the second coordinate. Hence <span class='inline'>\langle \cdot , \cdot \rangle</span> is a 
symmetric bilinear form inducing <span class='inline'>\| \cdot \|</span>. 

\textit2.~Case. In the case <span class='inline'>\mathbb{K} = \mathbb{C}</span> use complex polarization and put
<br><br><span class='display'>
   \langle v , w \rangle = \frac 14 \sum_{k=1}^4 \mathfrak{i}^k \, \| v + \mathfrak{i}^k \, w \|^2  
   \quad \text{for all } v,w\in \mathrm{V}  .
</span><br>
Then  <span class='inline'>\langle \cdot , \cdot \rangle</span> is conjugate symmetric, since 
<br><br><span class='display'>
   \overline{\langle v , w \rangle} = \frac 14 \sum_{k=1}^4 (- \mathfrak{i})^k \, \| v + \mathfrak{i}^k \, w \|^2  
   =   \frac 14 \sum_{k=1}^4 (-\mathfrak{i})^k \, \| (-\mathfrak{i})^k \, v +  w \|^2 =
   \langle w , v \rangle .
</span><br>
Next compute
<br><br><span class='display'>
  \Re \langle v , w \rangle =  \frac 14 \left( \| v + w \|^2  - \| v - w \|^2 \right)
</span><br>
and 
<br><br><span class='display'>
  \Im \langle v , w \rangle =  \frac 14 \left( \| v + \mathfrak{i} w \|^2  - \| v - \mathfrak{i} w \|^2 \right) .
</span><br>
By the first case one concludes that  <span class='inline'>\Re \langle \cdot , \cdot \rangle</span> and <span class='inline'>\Im \langle \cdot , \cdot \rangle</span>
are both <span class='inline'>\mathbb{R}</span>-linear in the first  and the second coordinate. Moreover,
<br><br><span class='display'>
  \Re \langle \mathfrak{i}  v , w \rangle =  \frac 14 \left( \| \mathfrak{i} v + w \|^2  - \| \mathfrak{i} v - w \|^2 \right)
  = \frac 14 \left( \| v - \mathfrak{i} w \|^2  - \| v + \mathfrak{i} w \|^2 \right) = 
  - \Im \langle v ,  w \rangle
</span><br>
and 
<br><br><span class='display'>
  \Im \langle \mathfrak{i} \, v , w \rangle =  
  \frac 14 \left( \| \mathfrak{i} v + \mathfrak{i} w \|^2  - \| \mathfrak{i} v - \mathfrak{i} w \|^2 \right) = 
  \Re \langle  v , w \rangle ,
</span><br>
hence <span class='inline'>\langle \cdot , \cdot \rangle</span> is complex linear in the first coordinate. 
Finally,
<br><br><span class='display'>
  \Re \langle v , v \rangle =  \| v  \|^2 \quad \text{and} \quad 
  \Im \langle v , v \rangle =  \frac 14 \left( \| v + \mathfrak{i} v \|^2  - \| v - \mathfrak{i} v \|^2 \right) = 0 .
</span><br>
This finishes the proof that <span class='inline'> \langle \cdot , \cdot \rangle</span> is a complex inner product inducing the 
norm <span class='inline'>\| \cdot \|</span>.


<br><br><strong>22.11</strong>
Next we will turn Hilbert spaces into a category. To this end one needs to know what morphisms in this
category should be. There are two options each giving rise to a category of Hilbert spaces. These categories
just differ by their morphism classes. The first one is to
have as morphisms  linear maps <span class='inline'>A:\mathfrak{H}_1\to\mathfrak{H}_2</span> preserving the inner products which means that
they fulfill
<br><br><span class='display'>
  \langle Av_1,Av_2 \rangle = \langle v_1,v_2 \rangle  \quad \text{for all } v_1,v_2 \in \mathfrak{H}_1 .
</span><br> 
By \Crefthm:parallegram-identity-guarantees-that-norm-comes-from-some-inner-product this property is
equivalent to
<br><br><span class='display'>
  \| Av \| = \| v \| \quad \text{for all } v \in \mathfrak{H}_1 ,
</span><br> 
that is to <span class='inline'>A</span> being <i>norm preserving</i> or <i>isometric</i>. Obviously, the identity map between two
Hilbert spaces is isometric and the composition of two composable isometric linear maps between Hilbert
spaces is again isometric and linear. Hence Hilbert spaces together with norm preserving linear maps between
them form a  category which we denote by <span class='inline'>\mathsf{Hilb_{np}}</span>. The isomorphisms in this category
are the surjective and inner product preserving linear maps between Hilbert spaces. Such maps
are called <i>unitary</i>. The condition of a linear map being norm preserving is pretty restrictive, so
the category <span class='inline'>\mathsf{Hilb_{np}}</span> contains only few morphisms. This can be healed by allowing all
<i>bounded</i> linear maps between Hilbert spaces to be morphisms that is of all
linear <span class='inline'>A:\mathfrak{H}_1\to\mathfrak{H}_2</span> for which there exists a <span class='inline'>C\geq 0</span> such that
<br><br><span class='display'>
  \| Av \| \leq C \| v \| \quad \text{for all } v \in \mathfrak{H}_1 .
</span><br>
The smallest such <span class='inline'>C</span> is called the <i>operator norm</i> of <span class='inline'>A</span> and is denoted <span class='inline'>\| A\|</span>.
Equivalently, the operator norm is given by
<br><br><span class='display'>
  \| A\| = \sup \big\{ \| Av \| \bigm\vert v\in \mathfrak{H}_1, \, \| v \| \leq 1 \big\}
  = \sup \big\{ \| Av \| \bigm\vert v\in \mathfrak{H}_1, \, \| v \| = 1 \big\} .
</span><br> 
Every norm preserving linear map is bounded with operator norm <span class='inline'>1</span>.
In particular the identity map on a Hilbert space is bounded. Moreover, if
<span class='inline'>A: \mathfrak{H}_1\to\mathfrak{H}_2</span>  and <span class='inline'>B: \mathfrak{H}_2\to\mathfrak{H}_3</span> are bounded linear operators
between Hilbert spaces, then the composition <span class='inline'>BA :  \mathfrak{H}_1\to\mathfrak{H}_3</span> is bounded
with operator norm <span class='inline'>\leq \| B\|\, \| A\|</span> since for all <span class='inline'>v \in \mathfrak{H}_1 </span> with <span class='inline'>\| v\|\leq 1</span>
<br><br><span class='display'>
  \| BAv \| \leq \| B \| \, \|Av\| \leq \| B\|\, \| A\| . 
</span><br>
Hence Hilbert spaces as objects together with bounded linear maps as morphisms form a category which we
denote by <span class='inline'>\mathsf{Hilb}</span> and call the <i>category of Hilbert spaces</i>. Note that the morphisms
in this category appear to ``forget'' the inner product and just preserve the linear and the topological
structure. John Baez <dt-cite key="ERROR"></dt-cite>[p.~133]BaeHDAII2HS has explained how to heal this apparent defect by showing that
<span class='inline'>\mathsf{Hilb}</span> carries a so-called <span class='inline'>*</span>-structure given by the adjoint map on bounded linear operators.
We will come back to this point later when we introduce adjoint operators. 

<br><br><strong>22.12</strong>
Last in this section we will introduce bounded bilinear and sesquilinear maps. We define them for normed
vector spaces. Their main application lies in the operator theory on Hilbert spaces, so we introduce
them here.  

<br><br><strong>Definition 22.13</strong>
  Let <span class='inline'>\mathrm{V}</span> be a vector space over <span class='inline'>\mathbb{K}</span> with norm <span class='inline'>\| \cdot \| : \mathrm{V} \to \mathbb{R}_{\geq 0}</span>. 
  A bilinear or sesquilinear form <span class='inline'>b : \mathrm{V} \times \mathrm{V} \to \mathbb{K}</span> is called <i>bounded</i> if 
  there exists a <span class='inline'>C  > 0</span> such that 
  <br><br><span class='display'>
    | b(v,w)| \leq C \, \| v\| \, \| w \| \quad \text{for all } v,w \in \mathrm{V} .
  </span><br>
  In this case,
  <br><br><span class='display'>
    \| b \| := \sup \big\{ | b(v,w) | \bigm\vert v,w \in \mathrm{V} \: \ \: \| v\| = \| w \| = 1 \big\} 
  </span><br> 
  exists and is called the <i>norm</i> of the form <span class='inline'>b</span>. 
<br><br>
<br><br><strong>Example 22.14</strong>
  The inner product on a (pre-) Hilbert space is bounded by the Cauchy--Schwarz inequality and has norm <span class='inline'>1</span>.
<br><br>

<br><br><strong>Proposition 22.15</strong>
A bounded bilinear or sesquilinear form <span class='inline'>b : \mathrm{V} \times \mathrm{V} \to \mathbb{K}</span> on a normed vector space <span class='inline'>\mathrm{V}</span> over 
<span class='inline'>\mathbb{K}</span> is continuous. Vice versa, if <span class='inline'>\mathrm{V}</span> is complete, then continuity of <span class='inline'>b : \mathrm{V} \times \mathrm{V} \to \mathbb{K}</span>
implies boundedness.
 <br><br>
<br><i>Proof.</i>
If <span class='inline'>b</span> is bounded, then
<br><br><span class='display'>
   
  \big\vert b(v,w) - b(v',w') \big\vert \,  
  \leq   \big\vert b(v,w) - b(v',w) \big\vert + \big\vert b(v',w) - b(v',w') \big\vert \leq </span><br><br><span class='display'>
   \leq \| b \| \, \left( \|  w \| \, \| v-v'\| +  \|  v' \| \, \| w-w'\| \right)   
  
</span><br>
for all <span class='inline'>v,v',w,w' \in \mathrm{V}</span>. Hence <span class='inline'>b</span> is locally Lipschitz continuous, so in particular continuous. 

Now assume that <span class='inline'>\mathrm{V}</span> is a Banach space and that <span class='inline'>b</span> is continuous. Then one can find <span class='inline'>\delta  > 0</span> such that 
for all <span class='inline'>v,w \in  V</span> of norm less than <span class='inline'>\delta</span> the relation <span class='inline'> |b(v,w)|  <  1</span> holds true. But that entails for all 
non-zero <span class='inline'>v,w</span>
<br><br><span class='display'>
   |b(v,w)| = \frac{4 \, \|v\| \, \|w\|}{\delta^2} \cdot b\left( \delta \frac{v}{2 \|v\|}, \delta \frac{w}{2 \|w\|}\right)
   \leq  \frac{4}{ \delta^2} \|v\| \, \|w\| .
</span><br> 
Hence <span class='inline'>b</span> is bounded.





</p><h1>23 Orthogonal decomposition and the Riesz representation theorem</h1><p>
  
<br><br><strong>23.1</strong> 
One of the issues with infinite-dimensional analysis is that a closed subspace of an infinite dimensional Banach space might not have a 
closed complement. Fortunately, the situation in Hilbert space theory is not so grim because 
every closed subspace of a Hilbert space admits an orthogonal complement. This is one of the four 
crucial properties  which distinguish Hilbert spaces from Banach spaces and which are stated in the following. 

In this section <span class='inline'>\mathfrak{H}</span> will always denote a Hilbert space over the field <span class='inline'>\mathbb{K}=\mathbb{R}</span> or <span class='inline'>\mathbb{K}=\mathbb{C}</span>. 
The symbol <span class='inline'>\langle \cdot , \cdot\rangle</span> will stand for the inner product of <span class='inline'>\mathfrak{H}</span>. 

<br><br><strong>Theorem 23.2</strong>[Best approximation theorem] 
   Every closed convex nonempty subset <span class='inline'>C</span> of a Hilbert space 
   <span class='inline'>\mathfrak{H}</span> has a unique element of minimal norm.
<br><br>
<br><i>Proof.</i>
Let <span class='inline'>d = \inf\{ \|v\| \mid v \in C \}</span> which is a non-negative real number. We claim there exists a unique 
<span class='inline'>v_0 \in C</span> with <span class='inline'>\|v_0\| =d</span>. 
For uniqueness, consider two vectors <span class='inline'>v_0, v_1</span> satisfying the desired property, and let <span class='inline'>v = \frac{1}{2}(v_0 + v_1)</span> 
be their midpoint. Then
<br><br><span class='display'>
  \|v\| = \frac{1}{2}\|v_0 + v_1\| \leq \frac{1}{2}(\|v_0\| + \|v_1\|) = d
</span><br>
By minimality of <span class='inline'>d</span> this entails <span class='inline'>\|v\| =d</span>. By the parallelogram identity
<br><br><span class='display'>
    \left\|\frac{1}{2} (v_0 + v_1)\right\|^2 + \left\|\frac{1}{2}(v_0 - v_1) \right\|^2  = 
    2\left\|\frac{v_0}{2}\right\|^2 + 2\left\|\frac{v_1}{2}\right\|^2 = d^2 ,
</span><br>
hence
<br><br><span class='display'>
\left\| \frac{1}{2} (v_0 - v_1) \right\|^2 \leq d^2 - \|v\|^2 = 0 ,
</span><br>
proving <span class='inline'>v_0 = v_1</span>. 

For the proof of existence observe that by definition of <span class='inline'>d</span> there exists a sequence <span class='inline'>(v_n)_{n \in \mathbb{N}} \subset C</span> such 
that <span class='inline'>\lim_{n \to \infty}\|v_n \| = d</span>. By convexity
<br><br><span class='display'>
   \frac{1}{2}(v_n + v_m) \in C
</span><br>
for all <span class='inline'>n,m \in \mathbb{N}</span>, hence <span class='inline'>\frac{1}{4}\|v_n + v_m \|^2 \geq d^2</span>. The parallelogram equality entails
<br><br><span class='display'>
0 \leq \| v_n - v_m \|^2 = 2\|v_n \|^2 + 2\|v_m \|^2 - \| v_n + v_m \|^2 \leq 2\|v_n \|^2 + 2\|v_m \|^2 - 4d^2 .
</span><br>
Since <span class='inline'>\lim_{n \to \infty}\|v_n \| = d</span> there exists for given <span class='inline'>\varepsilon  > 0</span> an <span class='inline'>N\in \mathbb{N}</span> such that 
<span class='inline'> \|v_n \|^2 -d^2 \leq \frac 14 \varepsilon^2 </span> for all <span class='inline'>n \geq N</span>. Hence, for <span class='inline'>n,m \geq N</span>
<br><br><span class='display'>
  0 \leq \| v_n - v_m \| \leq \varepsilon ,
</span><br> 
and <span class='inline'>(v_n)_{n \in \mathbb{N}}</span> is a Cauchy-sequence, so convergent by completeness of <span class='inline'>\mathfrak{H}</span>. Put <span class='inline'>v_0:= \lim_{n \to \infty}v_n</span>. 
Then <span class='inline'>v_0 \in C</span> since <span class='inline'>C</span> is closed and <span class='inline'>\|v_0 \|=\lim_{n \to \infty}\|v_n \| = d</span>. The existence claim follows 
and the proof is finished.


<br><br><strong>Theorem and Definition 23.3</strong>[Orthogonal decomposition theorem] 

Let <span class='inline'>\mathrm{V} \subset \mathfrak{H}</span> be a closed subspace of the Hilbert space <span class='inline'>\mathfrak{H}</span>. Then the 
<i>orthogonal complement</i>
<br><br><span class='display'>
  \mathrm{V}^\bot = \big\{ w \in \mathfrak{H} \bigm\vert \langle v,w \rangle = 0 \text{ for each } v \in \mathrm{V} \big\}
</span><br>
is a closed subspace of <span class='inline'>\mathfrak{H}</span> and <span class='inline'>\mathfrak{H} = \mathrm{V} \oplus \mathrm{V}^\bot</span>. 
The map <span class='inline'>\operatorname{pr}_\mathrm{V} : \mathfrak{H} \to \mathrm{V}</span> which maps <span class='inline'>w \in \mathfrak{H}</span> to the unique <span class='inline'>w_1\in \mathrm{V}</span> 
such that <span class='inline'>w - w_1 \in   \mathrm{V}^\bot</span> is called the <i>orthogonal projection</i> onto <span class='inline'>\mathrm{V}</span>.
It satisfies <span class='inline'>\left\| w-  \operatorname{pr}_\mathrm{V} (w)\right\| = d(w,\mathrm{V}) := \inf \big\{ \| v-w \| \bigm\vert v\in \mathrm{V} \big\}</span> that is <span class='inline'>\operatorname{pr}_\mathrm{V} (w)</span> is the unique element of <span class='inline'>\mathrm{V}</span> having shortest distance from <span class='inline'>w</span>.  
<br><br>
<br><i>Proof.</i>
For <span class='inline'>v \in \mathfrak{H}</span> define <span class='inline'>v^\flat :\mathfrak{H} \to \mathbb{R}</span> by <span class='inline'>v^\flat (w) = \langle w,v \rangle</span>. Recall that this map is 
continuous and linear. Hence the kernel <span class='inline'>(v^\flat)^{-1}(0)</span> is a closed linear subspace of <span class='inline'>\mathfrak{H}</span> and 
<br><br><span class='display'>
  \mathrm{V}^{\bot} = \bigcap_{v \in \mathrm{V}} (v^\flat)^{-1}(0)
</span><br>
is a closed linear subspace. To show <span class='inline'>\mathrm{V} \cap \mathrm{V}^\bot = \{0\}</span>, consider 
<span class='inline'>v \in \mathrm{V} \cap \mathrm{V}^\bot</span>. Then <span class='inline'>\|v \|^2 = \langle v,v \rangle = 0</span>. 
Now, given some <span class='inline'>w \in \mathfrak{H}</span>, it can be written as <span class='inline'>w = w_1 + w_2</span> with 
<span class='inline'>w_1 \in \mathrm{V}</span> and <span class='inline'>w_2 \in \mathrm{V}^\bot</span>. To see this put <span class='inline'>C = w - \mathrm{V}</span>. Then <span class='inline'>C</span> is closed and convex. 
By the best approximation theorem there exists a unique element <span class='inline'>w_2 \in C</span> of minimal norm. Let  <span class='inline'>w_1</span>
be the unique element of <span class='inline'>\mathrm{V}</span> such that <span class='inline'>w_2 = w -w_1</span>. It remains to show <span class='inline'>w_2 \in \mathrm{V}^\bot</span>. 
Since <span class='inline'>w_2</span> has minimal norm among the elements of <span class='inline'>w-\mathrm{V}</span> the following inequality holds for all 
vectors <span class='inline'>v \in \mathrm{V}</span>:
<br><br><span class='display'>
\|w_2 \|^2 \leq \| w_2 + v \|^2 = \|w_2 \|^2 + 2\, \Re\langle w_2,v\rangle + \| v \|^2 . 
</span><br>
Hence
<br><br><span class='display'>
0 \leq 2\, \Re\langle w_2,v\rangle + \| v \|^2 \quad \text{for all  } v \in \mathrm{V}  .
</span><br>
Now assume that <span class='inline'>\|v\|=1</span> and choose <span class='inline'>\varphi \in \mathbb{R}</span> such that <span class='inline'>e^{i\varphi}\langle w_2, v \rangle \in \mathbb{R}</span>.
Setting <span class='inline'>v' = e^{-i\varphi}v</span>, one obtains for all <span class='inline'>\lambda \in \mathbb{R}</span> by the last inequality
<br><br><span class='display'>
  0 \leq 2 \langle w_2,\lambda v'\rangle + \| \lambda v' \|^2 = 
  2\lambda\langle w_2, x'\rangle + \lambda^2.
</span><br>
For <span class='inline'>\lambda = -\langle w_2, v' \rangle</span> this entails  the estimate
<br><br><span class='display'> 
   \| \langle w_2, v' \rangle \|^2 = 
   - \left( - 2\|\langle w_2,v \rangle \|^2 + \| \langle w_2, v' \rangle \|^2 \right) = - \left(  2\lambda\langle w_2, x'\rangle + \lambda^2 \right) \leq 0 .
</span><br>
Hence <span class='inline'>\langle w_2, v \rangle = 0</span> for all unit vectors <span class='inline'>v \in \mathrm{V}</span>, therefore <span class='inline'>w_2 \in \mathrm{V}^\bot</span>.

The remainder of the claim is now a consequence of the construction of <span class='inline'>w_1</span> from the given <span class='inline'>w</span> and the 
observation that <span class='inline'>\operatorname{pr}_\mathrm{V} (w) = w_1</span>. 


<br><br><strong>Corollary 23.4</strong>
  For every closed subspace <span class='inline'>\mathrm{V} \subset \mathfrak{H}</span> of a Hilbert space <span class='inline'>\mathfrak{H}</span> the relation
  <br><br><span class='display'>
     V = (V^\perp)^\perp 
  </span><br>
  holds true. 
<br><br>

<br><i>Proof.</i>
  One has <span class='inline'>V \subset  (V^\perp)^\perp </span> by definition of the orthogonal complement. 
  Since <br><br><span class='display'> \mathfrak{H} = V \oplus  V^\perp =  (V^\perp)^\perp \oplus V^\perp </span><br> 
  by the preceding theorem, the claim follows.


<br><br><strong>Theorem 23.5</strong>[Riesz representation theorem for Hilbert spaces]
  Let <span class='inline'>\mathfrak{H}</span> be a Hilbert space and <span class='inline'>\mathfrak{H}'</span> its topological dual. Then the <i>musical map</i> 
  <br><br><span class='display'> {}^\flat: \mathfrak{H} \to \mathfrak{H}',\quad 
     v \mapsto v^\flat = \left( \mathfrak{H} \ni w \mapsto \langle w,v\rangle \in \mathbb{K}\right) </span><br>
  is an isometric isomorphism which is linear in the real case and conjugate-linear in the complex case. 
<br><br>

<br><i>Proof.</i>
  Obviously, <span class='inline'>{}^\flat</span> is linear if the ground field <span class='inline'>\mathbb{K}</span> equals <span class='inline'>\mathbb{R}</span> and conjugate-linear if <span class='inline'>\mathbb{K}=\mathbb{C}</span>.
  Now observe that for all <span class='inline'>v \in \mathfrak{H}</span> by the Cauchy--Schwarz inequality 
  <br><br><span class='display'>
    \| v^\flat \| = \sup\big\{ |\langle w,v \rangle | \bigm\vert w \in \mathfrak{H} \: \ \: \|w\| =1 \big\} = 
    \| v \| ,
  </span><br>
  hence <span class='inline'>{}^\flat</span> is an isometry, so in particular injective. 
  It remains to show surjectivity. So assume that <span class='inline'>\alpha : \mathfrak{H} \to \mathbb{K}</span> is a nontrivial 
  continuous linear form. 
  Let <span class='inline'>\mathrm{V}</span> be its kernel. Then  <span class='inline'>\mathrm{V}</span> is a closed linear subspace of <span class='inline'>\mathfrak{H}</span>.
  Since <span class='inline'>\alpha</span> is nontrivial, the orthogonal complement <span class='inline'>\mathrm{V}^\bot</span> is nontrivial, too. Hence 
  <span class='inline'>\mathrm{V}^\bot \cong \mathfrak{H}/\mathrm{V}</span> is isomorphic to <span class='inline'>\operatorname{im} \alpha = \mathbb{K}</span> 
  and there exists a  vector <span class='inline'>v \in \mathrm{V}^\bot \setminus \{ 0 \} </span> such that 
  <span class='inline'>\alpha (v) = 1</span>. Since <span class='inline'>v</span> spans <span class='inline'> \mathrm{V}^\bot</span> there exists   for every <span class='inline'>w\in \mathfrak{H}</span> a
  unique <span class='inline'>\lambda_w  \in \mathbb{K}</span> such that <span class='inline'>w = \operatorname{pr}_V (w) + \lambda_w v</span>. Then compute 
  <br><br><span class='display'>
    \alpha (w) = \alpha (\lambda_w v ) = \lambda_w  \quad \text{and} \quad 
    \left( \frac{v}{\|v\|^2}\right)^\flat (w) = 
    \frac{1}{\|v\|^2} \langle w, v \rangle =  \frac{ \lambda_w}{\|v\|^2} \langle v , v \rangle 
    = \lambda_w .
  </span><br>
  This entails <span class='inline'>\alpha = \left( \frac{v}{\|v\|^2}\right)^\flat</span>, and <span class='inline'>{}^\flat</span> is surjective.


<br><br><strong>Remark 23.6</strong>
  Sometimes, and we will follow that convention, the inverse of the musical isomorphism 
  <span class='inline'>{}^\flat: \mathfrak{H} \to \mathfrak{H}'</span> is denoted <span class='inline'>{}^\sharp: \mathfrak{H}' \to \mathfrak{H}</span>. 
<br><br>

<br><br><strong>Corollary 23.7</strong>
  Every Hilbert space <span class='inline'>\mathfrak{H}</span> is <i>reflexive</i> that is the canonical map
  <br><br><span class='display'> H \to H'' , \: v \mapsto \left( H' \ni \lambda \mapsto \lambda(v) \in \mathbb{K} \right) </span><br>
  is an isometric isomorphism. 
<br><br>

<br><i>Proof.</i>
  By the Riesz Representation Theorem, the dual <span class='inline'>\mathfrak{H}'</span> is a Hilbert space 
  with inner product  
  <br><br><span class='display'>
    \langle\!\langle \cdot, \cdot  \rangle\!\rangle : \mathfrak{H}' \times \mathfrak{H}' \to \mathbb{K}, \:  
    (\lambda,\mu)   \mapsto \langle\!\langle \lambda, \mu \rangle\!\rangle = \langle \mu^\sharp,\lambda^\sharp \rangle .
  </span><br> 
  Hence, by applying the Riesz Representation Theorem twice, 
  the map <span class='inline'>{}^\flat \circ {}^\flat : \mathfrak{H} \to  \mathfrak{H}''</span> is an isometric linear isomorphism. 
  Now compute for <span class='inline'>v\in \mathfrak{H}</span> and <span class='inline'>\lambda \in \mathfrak{H}'</span>
  <br><br><span class='display'>
     (v^\flat)^\flat (\mu) = \langle\!\langle \lambda, v^\flat \rangle\!\rangle =
     \langle v, \lambda^\sharp \rangle = \lambda (v) . 
  </span><br>
  Hence <span class='inline'>{}^\flat \circ {}^\flat</span> coincides with the canonical map above and the claim
  follows. 


<br><br><strong>Corollary 23.8</strong>

  Let <span class='inline'>b:\mathfrak{H} \times \mathfrak{H}\to \mathbb{K}</span> be a bounded sesquilinear form on a Hilbert space <span class='inline'>\mathfrak{H}</span>. Then there exists
  unique bounded linear map <span class='inline'>A : \mathfrak{H} \to \mathfrak{H}</span> such that
  <br><br><span class='display'>
      b(v,w)  = \langle Av,w \rangle \quad \text{for all } v,w\in \mathfrak{H} .
  </span><br>
  Moreover, the operator norm <span class='inline'>\| A \|</span> coincides with <span class='inline'>\| b\|</span>. 
<br><br>
<br><i>Proof.</i>
  First let us show uniqueness. So let <span class='inline'>A,B  : \mathfrak{H} \to \mathfrak{H}</span> be bounded and linear so that
  <br><br><span class='display'>
          b(v,w)  = \langle Av,w \rangle = \langle Bv,w \rangle  \quad \text{for all } v,w\in \mathfrak{H} .
  </span><br>
  Then <span class='inline'> \|(A-B)v \|^2 = \langle Av-Bv,(A-B)v \rangle = b(v,(A-B)v) - b(v,(A-B)v)=  0</span> for all <span class='inline'>v\in \mathfrak{H}</span> 
  which entails equality of <span class='inline'>A</span> and <span class='inline'>B</span>. 

  To prove existence observe that for every <span class='inline'>v\in \mathfrak{H}</span> the map <span class='inline'>\mathfrak{H} \to \mathbb{K}</span>, <span class='inline'>w \mapsto \overline{b(v,w)}</span>
  is bounded an linear, so by the Riesz representation theorem there exists for every <span class='inline'>v</span> an element <span class='inline'>Av \in \mathfrak{H}</span> 
  such that <span class='inline'>\langle w,Av \rangle =  \overline{b(v,w)}</span> for all <span class='inline'>w\in \mathfrak{H}</span>. 
  Let us show that the map <span class='inline'>A</span> is linear. 
  For <span class='inline'>v_1,v_2\in \mathfrak{H}</span> check that
  <br><br><span class='display'>
    
      \langle w,A(v_1+v_2) \rangle  =  \overline{b(v_1+v_2,w)} = \overline{b(v_1,w)}+ \overline{b(v_2,w)} = </span><br><br><span class='display'>
       = \langle w,Av_1 \rangle  +\langle w,Av_2 \rangle =  \langle w,Av_1+Av_2 \rangle \quad \text{for all } w\in \mathfrak{H} . 
    
  </span><br>
  But that implies <span class='inline'>A(v_1+v_2) = Av_1+Av_2</span>. Given <span class='inline'>r\in \mathbb{K}</span> and <span class='inline'>v\in\mathfrak{H}</span> one verifies
  <br><br><span class='display'>
    \langle w,A(rv) \rangle =  \overline{b(rv,w)} = \overline{rb(v,w)} = \overline{r} \, \overline{b(v,w)}
    =  \overline{r}  \langle w,Av \rangle =  \langle w,rAv \rangle \quad \text{for all } w\in \mathfrak{H} . 
  </span><br>
  Hence <span class='inline'>A(rv) = r Av</span> and linearity of <span class='inline'>A</span> is proved. 
  
  For the operator norm compute
  <br><br><span class='display'>
    
    \| A \|  = \sup \big\{ \left|\langle Av,w \rangle \right| \bigm\vert v,w \in \mathfrak{H} \: \ \: \|v\| = \|w\| =1 \big\} = </span><br><br><span class='display'>
     = \sup \big\{ \left| b(v,w) \right| \bigm\vert v,w \in \mathfrak{H} \: \ \: \|v\| = \|w\| =1 \big\} = \| b\| .
   
  </span><br>


<br><br><strong>23.9</strong>
Last in this section we will examine the <i>Hilbert direct sum</i> or just <i>Hilbert sum</i> of a family
<span class='inline'>(\mathfrak{H}_i)_{i\in I}</span> of Hilbert spaces. It is defined by
<br><br><span class='display'>
  
   \widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i  = \left\{ (v_i)_{i\in I} \in \prod_{i\in I}\mathfrak{H}_i
   \Bigm\vert \left( \|v_i\|^2 \right)_{i\in I} \text{ is summable} \right\} = </span><br><br><span class='display'>
    = \left\{ (v_i)_{i\in I} \in \prod_{i\in I}\mathfrak{H}_i
   \Bigm\vert \exists C \geq 0 \, \forall J \in \mathscr{F} (I): \: \sum_{i\in J} \|v_i\|^2 \leq C \right\} ,
  
</span><br>
where, as usual, <span class='inline'>\mathscr{F} (I)\subset \mathscr{P}(I)</span> denotes the set of all finite subsets of <span class='inline'>I</span>.

<br><br><strong>Proposition 23.10</strong>
  Let <span class='inline'>(\mathfrak{H}_i)_{i\in I}</span> be a family of Hilbert spaces. Then the Hilbert direct sum
  <span class='inline'>\widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i</span> is a Hilbert space with inner product  given by
  <br><br><span class='display'>
    \langle -,- \rangle : \widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i \times
    \widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i \to \mathbb{K}, \quad
    \left( (v_i)_{i\in I} ,  (w_i)_{i\in I} \right) \mapsto \sum_{i\in I} \langle v_i,w_i \rangle .
  </span><br>
<br><br>

<br><i>Proof.</i>
  We show first that <span class='inline'>\widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i</span> is a subvector space of
  the direct product <span class='inline'>\prod_{i\in I} \mathfrak{H}_i</span>.  
  Let <span class='inline'>z\in \mathbb{K}</span> and <span class='inline'>(v_i)_{i\in I}, (w_i)_{i\in I}\in \widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i</span>.
  Choose <span class='inline'>C,D \geq 0</span> such that
  <br><br><span class='display'>
    \sum_{i\in J} \|v_i\|^2 \leq C \quad\text{and}\quad
    \sum_{i\in J} \|w_i\|^2 \leq D \quad\text{for all} J \in \mathscr{I} .
  </span><br>
  Then
  <br><br><span class='display'> \tag{23.1}
    
    \sum_{i\in J} \|z v_i\|^2 = |z| \, \sum_{i\in J} \| v_i\|^2\leq |z| \, C \quad
    \text{for all } J\in \mathscr{I} ,
  </span><br><br>
  so <span class='inline'>(zv_i)_{i\in I} \in \widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i</span>. 
  Moreover, by Minkowski's inequality for finite sums,
  <br><br><span class='display'> \tag{23.2}
    
    \sum_{i\in J} \|v_i + w_i\|^2 \leq
    \left( \sqrt{\sum_{i\in J} \|v_i\|^2} +  \sqrt{\sum_{i\in J} \| w_i\|^2} \right)^2
    \leq \left( \sqrt{C} + \sqrt{D} \right)^2 \quad\text{for all } J\in \mathscr{I} .
  </span><br><br>
  Hence the family <span class='inline'>\left( \| v_i + w_i\|^2 \right)_{i\in I}</span> is summable and
  <span class='inline'>\left( v_i + w_i \right)_{i\in I} \in \widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i</span>. 
  
  Next observe that the map
  <br><br><span class='display'>
    \big\| - \big\| : \widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i \to \mathbb{K},
    \: (v_i)_{i\in I} \mapsto \big\| (v_i)_{i\in I}  \big\| = \sqrt{\sum_{i\in I} \| v_i\|^2} 
  </span><br>
  is well-defined by definition of the Hilbert direct sum. It is even a norm
  by \eqrefeq:estimate-finite-sum-square-norms-multiple and
  \eqrefeq:estimate-finite-sum-square-norms-sum. 
    
  Now we need to show that the inner product on <span class='inline'>\widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i</span>
  is well-defined which means that the family <span class='inline'>\left( \langle v_i,w_i \rangle \right)_{i\in I}</span> is summable
  for all <span class='inline'>(v_i)_{i\in I} ,  (w_i)_{i\in I} \in \widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i</span>.
  To this end let <span class='inline'>J\subset I</span> be a finite subset. Then, by the triangle inequality, 
  the Cauchy--Schwarz inequality on the Hilbert spaces <span class='inline'>\mathfrak{H}_i</span> and the
  Cauchy--Schwarz inequality for finite sums,
  <br><br><span class='display'>
    \left| \sum_{i\in J} \langle v_i,w_i \rangle \right| \leq
    \sum_{i\in J} \left| \langle v_i,w_i \rangle \right| \leq
    \sum_{i\in J} \| v_i\| \, \| w_i\| \leq
    \sqrt{\sum_{i\in J} \| v_i\|^2} \cdot \sqrt{\sum_{i\in J} \| w_i\|^2}
    \leq \big\| (v_i)_{i\in I}  \big\| \, \big\| (w_i)_{i\in I}  \big\| .
  </span><br>
  Hence the family <span class='inline'>\left( \langle v_i,w_i \rangle \right)_{i\in I}</span> is absolutely summable, so in particular
  summable, and the inner product is well-defined.

  By definition and since all the inner products on the Hilbert spaces <span class='inline'>\mathfrak{H}_i</span> are conjugate
  symmetric and positive definite, the map <span class='inline'>\langle -,- \rangle </span> on
  <span class='inline'>\widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i</span> has to be conjugate symmetric and positive definite
  as well. It remains to show linearity in the first argument.
  Denote for  <span class='inline'>(v_i)_{i\in I}, (w_i)_{i\in I} \in \prod_{i\in I} \mathfrak{H}_i</span>
  and <span class='inline'>J\in \mathscr{F} (I)</span> by <span class='inline'>\langle (v_i)_{i\in I} ,(w_i)_{i\in I} \rangle_J</span> the finite sum
  <span class='inline'>\sum_{i\in J} \langle v_i,w_i \rangle</span>. Observe that the net
  <span class='inline'>\big( \langle (v_i)_{i\in I} ,(w_i)_{i\in I} \rangle_J \big)_{J\in \mathscr{F}(I)}</span> converges to
  <span class='inline'>\langle (v_i)_{i\in I} ,(w_i)_{i\in I} \rangle</span> in case both <span class='inline'>(v_i)_{i\in I}</span> and <span class='inline'>(w_i)_{i\in I}</span>
  are in <span class='inline'>\widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i</span>. Now let <span class='inline'>z\in \mathbb{K}</span> and 
  <span class='inline'>(v_i)_{i\in I}, (v_i^\prime)_{i\in I},  (w_i)_{i\in I} \in \widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i</span>.
  Then 
  <br><br><span class='display'>
    
      \langle (v_i)_{i\in I} + (v_i^\prime)_{i\in I},(w_i)_{i\in I} \rangle_J  =
      \langle (v_i)_{i\in I} ,(w_i)_{i\in I} \rangle_J + \langle (v_i^\prime)_{i\in I},(w_i)_{i\in I} \rangle_J
      \quad\text{and}</span><br><br><span class='display'>
      \langle z (v_i)_{i\in I},(w_i)_{i\in I} \rangle_J  = z \langle (v_i)_{i\in I} ,(w_i)_{i\in I} \rangle_J .
    
  </span><br>
  By convergence of all the nets <span class='inline'>\big( \langle (v_i)_{i\in I} ,(w_i)_{i\in I} \rangle_J \big)_{J\in \mathscr{F}(I)}</span>,
  linearity in the first argument follows.

  By construction, the norm associated to the inner product <span class='inline'>\langle -,- \rangle </span> on
  <span class='inline'>\widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i</span> coincides with the above defined norm <span class='inline'>\big\|-\big\|</span>.
  It remains to show that <span class='inline'>\widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i</span> equipped with the norm
  <span class='inline'>\big\|-\big\|</span> is complete. To this end observe that for every finite <span class='inline'>J\subset I</span> the map
  <br><br><span class='display'>
    \big\| - \big\|_J : \prod_{i\in I} \mathfrak{H}_i \to \mathbb{R}_{\geq 0}, \:
    (v_i)_{i\in I} \mapsto \sqrt{\langle (v_i)_{i\in I},(v_i)_{i\in I} \rangle_J}
    = \sqrt{\sum_{i\in J} \| v_i \|^2}
  </span><br>
  is a seminorm and that <span class='inline'>(v_i)_{i\in I} \in \prod_{i\in I} \mathfrak{H}_i</span> lies in
  the Hilbert direct sum <span class='inline'>\widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i</span> if and only if the
  family <span class='inline'>\left(\big\| (v_i)_{i\in I}  \big\|_J\right)_{J\in \mathscr{F}(I)}</span> is bounded. 
  Now let <span class='inline'>\left((v_i^n)_{i\in I} \right)_{n\in \mathbb{N}}</span> be a Cauchy sequence.
  Let <span class='inline'>\varepsilon  > 0</span> and choose <span class='inline'>N_\varepsilon \in \mathbb{N}</span> such that 
  <br><br><span class='display'> \tag{23.3}
    
    \big\| (v_i^m)_{i\in I} - (v_i^n)_{i\in I} \big\|  <  \varepsilon \quad
    \text{for all } n,m\geq N_\varepsilon .
  </span><br><br>
  Hence
  <br><br><span class='display'> \tag{23.4}
    
    \big\| (v_i^m)_{i\in I} - (v_i^n)_{i\in I} \big\|_J  <     \varepsilon \quad
    \text{for all } J\in \mathscr{F}(I) \text{ and }  n,m\geq N_\varepsilon . 
  </span><br><br>
  Taking <span class='inline'>J =\{ j\}</span> for <span class='inline'>j\in I</span> this implies that the sequence
  <span class='inline'> (v_j^n)_{n\in \mathbb{N}}</span> is a Cauchy sequence in the Hilbert space <span class='inline'>\mathfrak{H}_j</span>. 
  Let <span class='inline'>v_j \in \mathfrak{H}_j</span> be its limit. The family <span class='inline'>(v_i)_{i\in I}</span> then is
  an element of <span class='inline'>\widehat{\bigoplus\limits_{i\in I}} \mathfrak{H}_i</span>. To verify this
  put <span class='inline'>N=N_1</span> and observe that by \eqrefeq:cauchy-criterion-sequence-finite-cutoff
  for all finite <span class='inline'>J\subset I</span>
  <br><br><span class='display'>
    
    \big\| (v_i)_{i\in I} \big\|_J  \leq
    \big\| (v_i^N)_{i\in I} \big\|_J + \big\| (v_i)_{i\in I} - (v_i^N)_{i\in I} \big\|_J = </span><br><br><span class='display'>
     = \big\| (v_i^N)_{i\in I} \big\|_J + \lim_{m\to \infty} \big\| (v_i^m)_{i\in I} - (v_i^N)_{i\in I} \big\|_J
    \leq \big\| (v_i^N)_{i\in I} \big\| + 1.
    
  </span><br>
    
  Hence the family <span class='inline'>\left(\big\| (v_i)_{i\in I} \big\|_J\right)_{J\in \mathscr{F}(I)}</span>
  is bounded and <span class='inline'>(v_i)_{i\in I}</span> lies in the Hilbert direct sum of the spaces <span class='inline'>\mathfrak{H}_i</span>, <span class='inline'>i\in I</span>. 
  Moreover, \eqrefeq:cauchy-criterion-sequence-finite-cutoff entails that
  <br><br><span class='display'>
    \big\| (v_i)_{i\in I} - (v_i^n)_{i\in I} \big\|_J =
    \lim_{m\to \infty} \big\| (v_i^m)_{i\in I} - (v_i^n)_{i\in I} \big\|_J \leq \varepsilon \quad
    \text{for all } J\in \mathscr{F}(I) \text{ and }  n\geq N_\varepsilon . 
  </span><br> 
  Since <span class='inline'>\big\| (v_i)_{i\in I} - (v_i^n)_{i\in I} \big\|</span> is the limit of the
  net <span class='inline'>\left(\big\| (v_i)_{i\in I} - (v_i^n)_{i\in I} \big\|_J\right)_{J\in\mathscr{F}(I)}</span>,
  the estimate 
  <br><br><span class='display'>
    \big\| (v_i)_{i\in I} - (v_i^n)_{i\in I} \big\| \leq \varepsilon \quad
    \text{for all }  n\geq N_\varepsilon 
  </span><br>
  follows and the sequence <span class='inline'>\left((v_i^n)_{i\in I} \right)_{n\in \mathbb{N}}</span> convergence to
  <span class='inline'>(v_i)_{i\in I}</span>. This finishes the proof.    

</p><h1>24 Orthonormal bases in Hilbert spaces</h1><p>


<br><br><strong>Definition 24.1</strong>
  A (possibly empty) subset <span class='inline'>S</span> of a Hilbert space <span class='inline'>\mathfrak{H}</span> is called
  an <i>orthogonal system</i> or just <i>orthogonal</i> if for any  two different elements <span class='inline'>v,w \in S</span> the relation 
  <span class='inline'>\langle v,w \rangle = 0</span> holds true. If in addition <span class='inline'>\left\|v\right\|=1</span> for all elements <span class='inline'>v \in S</span>,
  then the set is called <i>orthonormal</i> or an <i>orthonormal system</i>.  
  A family <span class='inline'>(v_i)_{i\in I}</span> of vectors in <span class='inline'>\mathfrak{H}</span> is called <i>orthogonal</i> if 
  <span class='inline'>\langle v_i,v_j \rangle = 0</span> for all  <span class='inline'>i,j\in I</span> with <span class='inline'>i\neq j</span> and  <i>orthonormal</i> 
  if in addition <span class='inline'>\|v_i\| =1</span> for all <span class='inline'>i\in I</span>. 
<br><br>

<br><br><strong>24.2</strong>
  Obviously, the set of orthonormal subsets of a Hilbert space is ordered by set-theoretic inclusion. 
  Therefore, the following definition makes sense. 

<br><br><strong>Definition 24.3</strong>
  A maximal orthonormal set in a Hilbert space <span class='inline'>\mathfrak{H}</span> is called an <i>orthonormal basis</i>
  or a <i>Hilbert basis</i> of <span class='inline'>\mathfrak{H}</span>.      
<br><br>

<br><br><strong>Proposition 24.4</strong>
  Every  Hilbert space <span class='inline'>\mathfrak{H}</span> has an orthonormal basis. 
<br><br>

<br><i>Proof.</i>
  Wothout loss of generality we can assume that <span class='inline'>\mathfrak{H} \neq \{ 0\}</span>, because 
  <span class='inline'>\emptyset</span> is a Hilbert basis for <span class='inline'>\{ 0 \}</span>. 
  Let <span class='inline'>\mathscr{O}</span> denote the set of orthonormal subsets of <span class='inline'>\mathfrak{H}</span>. As mentioned before, <span class='inline'>\mathscr{O}</span> 
  is ordered by set-theoretic inclusion. Let <span class='inline'>\mathscr{C} \subset \mathscr{O}</span> be a non-empty chain. 
  Put <span class='inline'>U  = \bigcup_{S\in \mathscr{C}} S</span>. Then  <span class='inline'>U</span> is an upper bound of <span class='inline'>\mathscr{C}</span>.
  So by Zorn's lemma <span class='inline'>\mathscr{O}</span> has a maximal element.   


<br><br><strong>Remark 24.5</strong>
  
  </p><ol class='enumeration'>
 
  <li value='(a) '>
    By slight abuse of language we sometimes call an orthonormal family <span class='inline'>(b_i)_{i\in I}</span> in a Hilbert space <span class='inline'>\mathfrak{H}</span>
    an <i>orthonormal basis</i> or a <i>Hilbert basis</i> of <span class='inline'>\mathfrak{H}</span>  
    if the set <span class='inline'>\{ b_i \mid i\in I \}</span> is an orthornormal basis. 
  </li><li value='(b) '> 
    If on an orthonormal basis <span class='inline'>B \subset \mathfrak{H}</span> a total order relation is given, 
    one calls <span class='inline'>B</span> an <i>ordered Hilbert basis</i> of <span class='inline'>\mathfrak{H}</span>. Likewise,  
    an orthonormal basis of the form <span class='inline'>(b_i)_{i\in I}</span> is called <i>orderd</i> if the index set <span class='inline'>I</span> carries a total order.
  
  </li></ol><p>

<br><br>

<br><br><strong>Proposition 24.6</strong>[Pythagorean theorem for orthogonal families]\hspace1mm
  An orthogonal family <span class='inline'>(v_i)_{i\in I}</span> in a Hilbert space <span class='inline'>\mathfrak{H}</span> is summable if and only if 
  the family of norms <span class='inline'>\left(\|v_i\| \right)_{i\in I}</span> is square summable. In this case one has 
  <br><br><span class='display'>
     \left\|\sum_{i\in I} v_i\right\|^2 =  \sum_{i\in I} \|v_i\|^2 .
  </span><br>
<br><br>

<br><i>Proof.</i>
  Assume that <span class='inline'>\left(\|v_i\| \right)_{i\in I}</span> is square summable or in other words that the net of partial sums
  <span class='inline'>\left( \sum_{i\in J} \|v_i\|^2 \right)_{J\in\mathscr{F} (I)}</span>  converges to some <span class='inline'>s \in \mathbb{R}</span>. 
  For <span class='inline'>\varepsilon  > 0</span> choose a finite <span class='inline'>J_\varepsilon \subset I</span> such that for all finite <span class='inline'>J</span> with 
  <span class='inline'>J_\varepsilon \subset J\subset I</span> the relation
  <br><br><span class='display'>
           \left| s - \sum_{i\in J} \|v_i\|^2   \right|  <  \frac{\varepsilon^2}{2}
  </span><br>
  holds true. For finite <span class='inline'>K\subset I</span> with <span class='inline'>K\cap J_\varepsilon  =\emptyset</span> one then obtains by the pythagorean theorem for 
  finite orthogonal families, Eq.~((22.1)),
  <br><br><span class='display'>
      \left\| \sum_{i\in K} v_i\right\|^2 =  \sum_{i\in K}  \left\| v_i\right\|^2 \leq 
       \left| s - \sum_{i\in K \cup J_\varepsilon} \|v_i\|^2   \right|  + \left| s - \sum_{i\in  J_\varepsilon} \|v_i\|^2   \right|
        <  \varepsilon^2 .
  </span><br>
  Hence  <span class='inline'>\left( \sum_{i\in J} v_i \right)_{J\in\mathscr{F} (I)}</span> is a Cauchy net in <span class='inline'>\mathfrak{H}</span>, so convergent. 
 
  Now let  <span class='inline'>(v_i)_{i\in I}</span> be  summable to <span class='inline'>v\in \mathfrak{H}</span>. 
  Then there exists a <span class='inline'>J_1 \in \mathscr{F} (I)</span> such that for all finite <span class='inline'>J \subset I</span> 
  containing  <span class='inline'>J_1</span>
  <br><br><span class='display'>
    \left\| v -  \sum_{i\in J} v_i \right\| \leq 1 .
  </span><br> 
  This implies by the pythagorean theorem for finite orthogonal families 
   <br><br><span class='display'>
    \sum_{i\in J} \left\| v_i \right\|^2 =  \left\|  \sum_{i\in J} v_i \right\|^2  \leq 
    \left(  \left\| v -  \sum_{i\in J} v_i \right\| +  \left\| v \right\| \right)^2 \leq  ( 1 + \| v\| )^2 .
  </span><br> 
  Hence the net of partial sums <span class='inline'>\left( \sum_{i\in J} \|v_i\|^2 \right)_{J\in\mathscr{F} (I)}</span> is bounded, so convergent
  since each term <span class='inline'>\|v_i\|^2</span> is <span class='inline'>\geq 0</span>.  

  By continuity of the inner product and pairwise orthogonality of the <span class='inline'>v_i</span> we finally obtain in the convergent case
  <br><br><span class='display'>
   \left\| \sum_{i\in I} v_i \right\|^2 = \langle  \sum_{i\in I} v_i, \sum_{j\in I} v_j \rangle =
   \sum_{i\in I} \langle  v_i, \sum_{j\in I} v_j \rangle =  \sum_{i\in I} \sum_{j\in I} \langle  v_i, v_j \rangle =  \sum_{i\in I} \left\| v_i \right\|^2 .
  </span><br>


<br><br><strong>Proposition 24.7</strong>
  Let <span class='inline'>(v_i)_{i\in I}</span> be an orthonormal family in a Hilbert space <span class='inline'>\mathfrak{H}</span>. Then for every <span class='inline'>v \in \mathfrak{H}</span> 
  the family <span class='inline'>\left( \langle v,v_i \rangle \right)_{i\in I}</span>  is square summable and 
  <i>Bessel's inequality</i> holds true that is 
  <br><br><span class='display'>
    \sum_{i\in I} \left| \langle v,v_i \rangle \right|^2 \leq \| v \|^2 .
  </span><br>
<br><br>

<br><i>Proof.</i>
  


<br><br><strong>Theorem 24.8</strong>
Let <span class='inline'>B</span> be an orthonormal system in a Hilbert space <span class='inline'>\mathfrak{H}</span>. Then the following are equivalent:

  </p><ol class='enumeration'>

  <li value='(1)'> The orthonormal system <span class='inline'>B</span> is maximal, i.e.a Hilbert basis.
  </li><li value='(2)'> The orthonormal system <span class='inline'>B</span> is  <i>total</i> that is for all <span class='inline'>v \in H</span>    
      such that <span class='inline'>\langle v, b \rangle = 0</span> for all <span class='inline'>b \in B</span> the equality <span class='inline'>v = 0</span> holds true.
  </li><li value='(3)'>
     For every <span class='inline'>b\in B</span> let <span class='inline'>\mathfrak{H}_b = \{ r b \in \mathfrak{H} \mid r \in \mathbb{K}\}</span>. Then the canonical map 
     <br><br><span class='display'>
       \iota: \widehat{\bigoplus_{b \in B}} \mathfrak{H}_b \to \mathfrak{H} , \: 
       (v_b)_{b \in B} \mapsto \sum_{b \in B} v_b
     </span><br> 
     is an isometric isomorphism.  
  </li><li value='(4)'>
     The closed linear span <span class='inline'>\widebar{\operatorname{Span}}{B}</span> coincides with <span class='inline'>\mathfrak{H}</span>.
  </li><li value='(5)'> For all <span class='inline'>v \in \mathfrak{H}</span>, one has the
    <i>Fourier expansion</i>
    <br><br><span class='display'> v = \sum_{b \in B} \langle v, b \rangle b  . </span><br>
  </li><li value='(6)'> For all <span class='inline'>v, w \in \mathfrak{H}</span>, one has 
    <br><br><span class='display'> \langle v, w \rangle = \sum_{b \in B}\langle v, b \rangle \langle b, w \rangle . </span><br>
  </li><li value='(7)'> For all <span class='inline'>v \in \mathfrak{H}</span>, <i>Parseval's identity</i> holds true that is
    <br><br><span class='display'> \left\|v\right\|^2 = \sum_{b \in B} {\left|\langle v, b \rangle\right|}^2  . </span><br> 

  </li></ol><p>

<br><br>

<br><i>Proof.</i>
 (1) <span class='inline'>\Rightarrow</span> (2):
   If <span class='inline'>v \neq 0</span>, then <span class='inline'>\frac{v}{\left\|v\right\|}</span> is a unit vector orthogonal to each <span class='inline'>v_i</span>. Hence <span class='inline'>\{v\} \cup B</span> 
   is an orthonormal system which is strictly larger than <span class='inline'>B</span>, contradicting (1).

 (2) <span class='inline'>\Rightarrow</span> (3). 
   First note that by the pythagorean theorem for infinite families, \Crefthm:pythagorean-theorem-infinite-families,
   the canonical map <span class='inline'>\iota: \widehat{\bigoplus}_{b \in B} H_b \rightarrow H</span> is well-defined and an isometry. 
   Hence <span class='inline'>\iota</span> is injective. It remains to show that <span class='inline'>\iota</span> is surjective. 
   To this end observe that <span class='inline'>\operatorname{im} \iota</span> is closed in <span class='inline'>\mathfrak{H}</span> since <span class='inline'>\iota</span> is an isometry (the image is complete). 
   If <span class='inline'>\iota</span> is not surjective, then <span class='inline'>\operatorname{im} \iota^\perp</span> is not the zero vector space. 
   Choose <span class='inline'>v \in \operatorname{im} \iota^\perp \setminus \{ 0\}</span>. 
   Then <span class='inline'>v</span> is orthogonal to each element of <span class='inline'>B</span>, but <span class='inline'>v \neq 0</span>. This contradicts 
   (2), so <span class='inline'>\operatorname{im} \iota = \mathfrak{H}</span>.

  (3) <span class='inline'>\Rightarrow</span> (5): 
    We can represent any <span class='inline'>v \in \mathfrak{H}</span> in the form <span class='inline'>v = \iota \left( (v_b)_{b \in B} \right) = 
    \sum_{b\in B} v_b</span> with <span class='inline'>\left( v_b \right)_{b\in B} \in \widehat{\bigoplus}_{b \in B}  H_b</span>. 
    Write <span class='inline'>v_b = r_b \, b</span> for every <span class='inline'>b\in B</span>, where <span class='inline'>r_b \in \mathbb{K}</span> is uniquely determined by <span class='inline'>v_b</span>. 
    Then compute using continuity of the inner product
    <br><br><span class='display'>
      \langle v, b \rangle = \langle \sum_{c \in B} v_c, b \rangle = \sum_{c \in B} r_c \langle c, b \rangle = r_b .
    </span><br>
    Therefore,
    <br><br><span class='display'>
       v = \sum_{b \in B} r_b \, b = \sum_{b \in B} \langle v, b \rangle b .
    </span><br>

  (5) <span class='inline'>\Rightarrow</span> (6):
  Fourier expansion of <span class='inline'>v, w \in H</span> gives <span class='inline'>v = \sum\limits_{b \in B} \langle v, b \rangle b</span> and 
  <span class='inline'>w = \sum\limits_{b \in B} \langle w, b \rangle b</span>.   Then, by continuity of the inner product,
  <br><br><span class='display'>
    \langle v, w \rangle = \sum\limits_{b \in B} \langle v, b \rangle\langle b, w \rangle .
  </span><br>

  (5) <span class='inline'>\Rightarrow</span> (4):
  Let <span class='inline'>v\in \mathfrak{H}</span>. Then <span class='inline'>\sum\limits_{b\in J}\langle v, b \rangle b \in \operatorname{Span} (B)</span> for all finite  <span class='inline'>J \subset B</span>.
  But by Fourier expansion <span class='inline'>v</span> is the limit of the net 
  <span class='inline'>\left( \sum\limits_{b\in J}\langle v, b \rangle b \right)_{J\in \mathscr{F} (B)} </span>, so <span class='inline'>v</span> lies in the closure 
  <span class='inline'>\widebar{\operatorname{Span}} (B)</span>.

  (4)  <span class='inline'>\Rightarrow</span> (2):
  Assume that <span class='inline'>\langle v, b \rangle = 0</span> for all <span class='inline'>b \in B</span>. By (4), <span class='inline'>v</span> can be written as a limit 
  <span class='inline'>v = \lim\limits_{n\to\infty} v_n</span>, where <span class='inline'>v_n \in \operatorname{Span} (B)</span> for all <span class='inline'>n\in \mathbb{N}</span>. 
  Then  <span class='inline'>\langle v, v_n \rangle = 0</span> for all <span class='inline'>n\in \mathbb{N}</span> by assumption. 
  By continuity of the inner product this implies
  <br><br><span class='display'>
     \left\|v\right\|^2 = \lim\limits_{n\to\infty} \langle v, v_n \rangle = 0 ,
  </span><br>
  so <span class='inline'>v=0</span>. 

  (6) <span class='inline'>\Rightarrow</span> (7): 
  Put <span class='inline'>v = w</span>. Then, by assumption,
  <br><br><span class='display'>
   \left\|v\right\|^2 = \langle v, v \rangle = \sum\limits_{b\in B} \langle v, b \rangle \langle b, v \rangle = \sum\limits_{b \in B} {\left|\langle v, b \rangle\right|}^2 .
  </span><br>

  (7) <span class='inline'>\Rightarrow</span> (1):
  Assume (7) and that (1) is not true. 
  Then there exists <span class='inline'>v \in H</span> with <span class='inline'>\left\|v\right\| = 1</span> and <span class='inline'>\langle v, b \rangle = 0</span> for all <span class='inline'>b \in B</span>. But then
  <br><br><span class='display'>
    \left\|v\right\|^2 = \sum_{b \in B} {\left|\langle v, b \rangle\right|}^2 = 0,
  </span><br>
  which is a contradiction.

 

</p><h1>25 The monoidal structure of the category of Hilbert spaces</h1><p>

<br><br><strong>25.1</strong> 
Let <span class='inline'>\mathbb{K}</span> be the field of real or complex numbers. 
Hilbert spaces over <span class='inline'>\mathbb{K}</span> together with bounded <span class='inline'>\mathbb{K}</span>-linear maps 
between them form a category denoted by <span class='inline'>\mathbb{K}\text{-}\mathsf{Hilb}</span>
or just <span class='inline'>\mathsf{Hilb}</span> if no confusion can arise. This can be seen
immediately by observing that the identity map <span class='inline'>\mathbbm{1}_\mathfrak{H}</span> on a Hilbert space
is a bounded linear operator  and that the composition <span class='inline'>B \circ A : \mathfrak{H}_1 \to\mathfrak{H}_3</span>
of two bounded linear operators between Hilbert spaces 
<span class='inline'>A:\mathfrak{H}_1 \to \mathfrak{H}_2 </span> and <span class='inline'>B :\mathfrak{H}_2 \to \mathfrak{H}_3</span> is again a  
bounded linear operator. 
We want to endow the category <span class='inline'>\mathsf{Hilb}</span> with a bifunctor 
<span class='inline'> {\,\widehat{\otimes}\,} : \mathsf{Hilb} \times \mathsf{Hilb} \to \mathsf{Hilb}</span>
so that it becomes a monoidal category. The (bi)functor <span class='inline'>{\,\widehat{\otimes}\,}</span> will be 
called the <i>Hilbert tensor product</i>.

Unless mentioned differently, Hilbert spaces, vector spaces and the algebraic tensor product <span class='inline'>\otimes</span>
in this section are assumed to be taken over the ground field <span class='inline'>\mathbb{K}</span>. 

<br><br><strong>Proposition 25.2</strong>
  
 Let <span class='inline'>\mathfrak{H}_1</span> and <span class='inline'>\mathfrak{H}_2</span> be two Hilbert spaces. 
 Then there exists a unique inner product 
 <span class='inline'>\langle \cdot,\cdot \rangle: (\mathfrak{H}_1 \otimes \mathfrak{H}_2) \times (\mathfrak{H}_1 \otimes \mathfrak{H}_2)
  \to \mathbb{K} </span> on the algebraic tensor product <span class='inline'>\mathfrak{H}_1\otimes \mathfrak{H}_2</span> such that
  <br><br><span class='display'> \tag{25.1}
    
    \langle v_1 \otimes v_2 , w_1 \otimes w_2 \rangle =  \langle v_1,w_1 \rangle \cdot \langle v_2,w_2 \rangle 
    \quad\text{for all } v_1,w_1 \in \mathfrak{H}_1, \: v_2,w_2 \in \mathfrak{H}_2 .  
  </span><br><br>
<br><br>

<br><i>Proof.</i>
  Let us first provide some preliminary constructions. 
  Recall that  for every pair of vector spaces <span class='inline'>\mathrm{V}_1</span> and <span class='inline'>\mathrm{V}_2</span>
  the bilinear map 
  <br><br><span class='display'>
    
    \tau: \operatorname{Hom}\nolimits (\mathrm{V}_1 ,\mathbb{K}) \times \operatorname{Hom}\nolimits (\mathrm{V}_2,\mathbb{K})  \to
    \operatorname{Hom}\nolimits (\mathrm{V}_1 \otimes \mathrm{V}_2,\mathbb{K}), </span><br><br><span class='display'>
    (\lambda_1,\lambda_2)  \mapsto \big( \mathrm{V}_1 \otimes \mathrm{V}_2 \to \mathbb{K}, \: 
    v_1 \otimes v_2 \mapsto \lambda_1 (v_1) \cdot\lambda_2 (v_2) \big)    
    
  </span><br>
  induces a linear map
  <br><br><span class='display'>
    \widehat{\tau}: \operatorname{Hom}\nolimits (\mathrm{V}_1 ,\mathbb{K}) \otimes \operatorname{Hom}\nolimits (\mathrm{V}_2,\mathbb{K}) \to
    \operatorname{Hom}\nolimits (\mathrm{V}_1 \otimes \mathrm{V}_2,\mathbb{K})  
  </span><br>
  by the universal property of the tensor product.
  This map is an isomorphism. To see this choose a basis <span class='inline'>(v_{1i})_{i\in I} </span> of <span class='inline'>V_1</span> and
  a basis <span class='inline'>(v_{2j})_{j\in J} </span> of <span class='inline'>V_2</span>. Let  <span class='inline'>(v^\prime_{1i})_{i\in I} </span> and <span class='inline'>(v^\prime_{2j})_{j\in J} </span>
  denote the respective dual bases of <span class='inline'>V_1^\prime</span> and  <span class='inline'>V_2^\prime</span>. Then
  <span class='inline'>\left( v^\prime_{1i} \otimes v^\prime_{2j}\right)_{(i,j)\in I \times J}</span> is a basis of
  <span class='inline'>\operatorname{Hom}\nolimits (\mathrm{V}_1 ,\mathbb{K}) \otimes \operatorname{Hom}\nolimits (\mathrm{V}_2,\mathbb{K})</span> which under <span class='inline'>\widehat{\tau}</span>
  is  mapped bijectively to the basis <span class='inline'>\left( (v_{1i} \otimes v_{2j})^\prime \right)_{(i,j)\in I \times J}</span>
  of <span class='inline'>\operatorname{Hom}\nolimits (\mathrm{V}_1 \otimes \mathrm{V}_2,\mathbb{K})</span> dual to the basis
  <span class='inline'>\left( v_{1i} \otimes v_{2j}\right)_{(i,j)\in I \times J}</span> of <span class='inline'>\mathrm{V}_1 \otimes \mathrm{V}_2</span>.
  Hence <span class='inline'>\widehat{\tau}</span> is a linear isomorphism as claimed, and we can identify
  the tensor product <span class='inline'>\lambda_1\otimes \lambda_2</span> of two linear functionals
  <span class='inline'>\lambda_i: \mathrm{V}_i\to\mathbb{K}</span>, <span class='inline'>i=1,2</span> 
  with its image in <span class='inline'>\operatorname{Hom}\nolimits (\mathrm{V}_1 \otimes \mathrm{V}_2,\mathbb{K})</span>.  
 
  Now observe that for two conjugate-linear maps <span class='inline'>\mu_1 :\mathrm{V}_1 \to \mathbb{K}</span>
  and <span class='inline'>\mu_2 :\mathrm{V}_2 \to \mathbb{K}</span> the map 
  <span class='inline'> \tau^* (\mu_1,\mu_2)  = \overline{\overline{\mu_1}\otimes \overline{\mu_2}} : 
     \mathrm{V}_1 \otimes \mathrm{V}_2 \to \mathbb{K}</span>
  is conjugate-linear and satisfies 
  <br><br><span class='display'> \tag{25.2}
  
     \tau^* (\mu_1,\mu_2) \, (v_1\otimes v_2) = \mu_1(v_1) \cdot \mu_2(v_2) \quad
     \text{for all } v_1\in\mathrm{V}_1 ,\: v_2 \in\mathrm{V}_2 . 
  </span><br><br>
          One obtains a map 
  <br><br><span class='display'>
    \tau^*: \operatorname{Hom}\nolimits^* (\mathrm{V}_1,\mathbb{K}) \times \operatorname{Hom}\nolimits^* (\mathrm{V}_2,\mathbb{K}) 
    \to \operatorname{Hom}\nolimits^* (\mathrm{V}_1 \otimes \mathrm{V}_2 ,\mathbb{K}) , 
  </span><br> 
  where here the symbol <span class='inline'>\operatorname{Hom}\nolimits^* (\mathrm{V},\mathbb{K})</span> denotes the space  of all conjugate linear
  functionals on a vector space <span class='inline'>\mathrm{V}</span>. Since <span class='inline'>\tau^*</span> is biadditive and 
  since <span class='inline'>\tau^* (z\mu_1,\mu_2) = \tau^* (\mu_1,z\mu_2)</span> for all <span class='inline'>\mu_1\in \operatorname{Hom}\nolimits^*(\mathrm{V}_1 ,\mathbb{K})</span>,
  <span class='inline'>\mu_2\in \operatorname{Hom}\nolimits^*(\mathrm{V}_2 ,\mathbb{K})</span>, and <span class='inline'>z\in \mathbb{K}</span>, the map <span class='inline'>\tau^*</span> factors through a linear map 
   <br><br><span class='display'>
    \widehat{\tau^*} :\operatorname{Hom}\nolimits^* (\mathrm{V}_1 ,\mathbb{K}) \otimes \operatorname{Hom}\nolimits^* (\mathrm{V}_2,\mathbb{K}) \to
    \operatorname{Hom}\nolimits^* (\mathrm{V}_1 \otimes \mathrm{V}_2,\mathbb{K})  .
  </span><br>
  Using the above bases <span class='inline'>(v_{1i})_{i\in I} </span> and <span class='inline'>(v_{2j})_{j\in J} </span> of <span class='inline'>V_1</span> and <span class='inline'>V_2</span> respectively,
  one observes that <span class='inline'>\widehat{\tau^*}</span> is an isomorphism since it maps the basis
  <span class='inline'>\left( \overline{v^\prime_{1i}} \otimes \overline{v^\prime_{2j}}\right)_{(i,j)\in I \times J}</span> of
  <span class='inline'>\operatorname{Hom}\nolimits^* (\mathrm{V}_1 ,\mathbb{K}) \otimes \operatorname{Hom}\nolimits^* (\mathrm{V}_2,\mathbb{K})</span>
  bijectively to the basis <span class='inline'>\left( \overline{(v_{1i} \otimes v_{2j})^\prime} \right)_{(i,j)\in I \times J}</span>
  of the space <span class='inline'>\operatorname{Hom}\nolimits^* (\mathrm{V}_1 \otimes \mathrm{V}_2,\mathbb{K})</span>.  So <span class='inline'>\widehat{\tau^*}</span> is also
  a linear isomorphism, which allows us to identify the tensor product <span class='inline'>\mu_1 \otimes \mu_2</span>
  of two conjugate linear functionals  <span class='inline'>\mu_i: \mathrm{V}_i\to\mathbb{K}</span>, <span class='inline'>i=1,2</span> with its image in
  <span class='inline'>\operatorname{Hom}\nolimits^* (\mathrm{V}_1 \otimes \mathrm{V}_2,\mathbb{K})</span>.
  

  After these preliminary considerations we consider the map 
  <br><br><span class='display'>
    \mathfrak{H}_1\times \mathfrak{H}_2 \to \operatorname{Hom}\nolimits^* (\mathfrak{H}_1\otimes \mathfrak{H}_2,\mathbb{K}) ,
    \: (v_1,v_2) \mapsto \overline{v_1^\flat} \otimes  \overline{v_2^\flat} = 
    \tau^* \left( \overline{v_1^\flat} , \overline{v_2^\flat}  \right)=
    \widehat{\tau^*}  \left( \overline{v_1^\flat} \otimes \overline{v_2^\flat}  \right),
  </span><br>
  which is well-defined and bilinear since the musical isomorphisms
  <span class='inline'>{}^\flat: \mathfrak{H}_l \to \mathfrak{H}_l'</span>, <span class='inline'>v \mapsto  \langle  - ,v \rangle </span>, <span class='inline'>l=1,2</span>,
  are conjugate-linear and  since <span class='inline'>\tau^*</span> is bilinear. Hence it factors through a linear map 
  <br><br><span class='display'>
    \beta: \mathfrak{H}_1\otimes \mathfrak{H}_2 \to \operatorname{Hom}\nolimits^* (\mathfrak{H}_1\otimes \mathfrak{H}_2,\mathbb{K}) 
  </span><br>
  such that
  <br><br><span class='display'> \tag{25.3}
  
    \beta (v_1\otimes v_2) (w_1\otimes w_2) =  \langle v_1,w_1 \rangle \cdot \langle v_2,w_2 \rangle 
    \quad \text{for all } v_1,w_1\in \mathfrak{H}_1 , \: v_2,w_2\in \mathfrak{H}_2 . 
  </span><br><br>
  Now put 
  <br><br><span class='display'>
   \langle \cdot,\cdot \rangle : 
   (\mathfrak{H}_1 \otimes \mathfrak{H}_2) \times (\mathfrak{H}_1 \otimes \mathfrak{H}_2) 
   \to \mathbb{K}, \: (v,w) \mapsto \beta (v) (w) .  
  </span><br>
  Then <span class='inline'>\langle \cdot,\cdot \rangle</span> is sesquilinear by construction, and 
  \eqrefeq:defining-relation-inner-product-tensor-product holds true by 
  \eqrefeq:defining-relation-map-beta.

  Let us show that <span class='inline'>\langle \cdot,\cdot \rangle</span> is positive definite. Let 
  <span class='inline'>v = \sum_{k=1}^n v_{1k} \otimes v_{2k} \in \mathfrak{H}_1 \otimes \mathfrak{H}_2</span>. 
  Choose an orthonormal basis <span class='inline'>e_1, \ldots , e_m</span> of the linear subspace 
  spanned by <span class='inline'>v_{21}, \ldots , v_{2n}</span>. Expand 
  <span class='inline'> v_{2k} = \sum_{i=1}^m c_{ki} e_i</span> with <span class='inline'>c_{k1}, \ldots , c_{km} \in \mathbb{K}</span>. 
  Then 
  <br><br><span class='display'> \tag{25.4}
    
    v = \sum_{k=1}^n v_{1k} \otimes v_{2k} =  \sum_{k=1}^n \sum_{i=1}^m   v_{1k} \otimes  (c_{ki} e_i) =
    \sum_{i=1}^m \left( \sum_{k=1}^n   c_{ki} v_{1k} \right) \otimes  e_i =
    \sum_{i=1}^m  w_{1i}  \otimes  e_i ,
  </span><br><br>
  where <span class='inline'> w_{1i} = \sum_{k=1}^n   c_{ki} v_{1k} </span>. Hence
  <br><br><span class='display'> \tag{25.5}
    
    \langle v,v \rangle =  \langle \sum_{i=1}^m  w_{1i}  \otimes  e_i,\sum_{j=1}^m  w_{1j}  \otimes  e_j  \rangle  
    = \sum_{i=1}^m \sum_{j=1}^m  \langle w_{1i},  w_{1j} \rangle \, \langle  e_i,e_j  \rangle =
     \sum_{i=1}^m \| w_{1i} \|^2 \geq 0 .
  </span><br><br>
  Moreover, if <span class='inline'>\langle v,v \rangle = 0</span>, then <span class='inline'>w_{1i}=0</span> for <span class='inline'>i=1,\ldots , m</span>, which implies 
  <span class='inline'>v=  \sum_{i=1}^m  w_{1i}  \otimes  e_i =0</span>. 
  So <span class='inline'> \langle \cdot,\cdot \rangle</span> is an inner product on <span class='inline'>\mathfrak{H}_1\otimes \mathfrak{H}_2</span> satisfying
  \eqrefeq:defining-relation-inner-product-tensor-product. It is uniquely determined by this 
  condition since the vectors <span class='inline'>v_1\otimes v_2</span> with <span class='inline'>v_1\in \mathfrak{H}_1</span> and <span class='inline'>v_2\in \mathfrak{H}_2</span>  span
  <span class='inline'>\mathfrak{H}_1\otimes \mathfrak{H}_2</span>.


<br><br><strong>Definition 25.3</strong>
  Let <span class='inline'>\mathfrak{H}_1</span> and <span class='inline'>\mathfrak{H}_2</span> be Hilbert spaces.
  The Hilbert completion of the algebraic tensor product <span class='inline'>\mathfrak{H}_1 \otimes \mathfrak{H}_2</span>
  equipped with the unique inner product <span class='inline'>\langle \cdot,\cdot \rangle</span>  fulfilling 
  \eqrefeq:defining-relation-inner-product-tensor-product
  will be denoted <span class='inline'>\mathfrak{H}_1 {\,\widehat{\otimes}\,} \mathfrak{H}_2</span>, its inner product again by <span class='inline'>\langle \cdot,\cdot \rangle</span>. One calls the Hilbert space 
  <span class='inline'>\big(\mathfrak{H}_1 {\,\widehat{\otimes}\,} \mathfrak{H}_2 ,\langle \cdot,\cdot \rangle\big)</span>
  the <i>Hilbert tensor product</i> of <span class='inline'>\mathfrak{H}_1</span> and <span class='inline'>\mathfrak{H}_2</span> or just the
  <i>tensor product</i> of <span class='inline'>\mathfrak{H}_1</span> and <span class='inline'>\mathfrak{H}_2</span> if no confusion can arise.
<br><br>

<br><br><strong>Proposition 25.4</strong>
  Let <span class='inline'>\mathfrak{H}_1</span> and <span class='inline'>\mathfrak{H}_2</span> be Hilbert spaces.
  
  </p><ol class='enumeration'>

  <li value='(I)'>
    If <span class='inline'>A_i \subset \mathfrak{H}_i</span> for <span class='inline'>i=1,2</span> are total in the ambient  Hilbert space,
    then the set of simple vectors <span class='inline'>a_1\otimes a_2</span> with <span class='inline'>a_1 \mathfrak{H}_1</span> and
    <span class='inline'>a_2 \mathfrak{H}_2</span> is total in the Hilbert
    tensor product  <span class='inline'>\mathfrak{H}_1 {\,\widehat{\otimes}\,} \mathfrak{H}_2</span>. 
  </li><li value='(II)'>
    If <span class='inline'>(e_i)_{i\in I}</span> and <span class='inline'>(f_j)_{j\in J}</span> are orthonormal bases of  <span class='inline'>\mathfrak{H}_1</span> and <span class='inline'>\mathfrak{H}_2</span>,
    respectively, then <span class='inline'>(e_i\otimes f_j)_{(i,j)\in I \times J}</span> is an orthonormal basis of the Hilbert
    tensor product <span class='inline'>\mathfrak{H}_1 {\,\widehat{\otimes}\,} \mathfrak{H}_2</span>.
  
  </li></ol><p>

<br><br>



<br><i>Proof.</i>
  
  </p><ol class='enumeration'>

  <li value='\itshape ad (\itshape I\hspace1pt). '>
    Recall that a subset <span class='inline'>A \subset \mathfrak{H}</span> or a family <span class='inline'>A = (a_j)_{j\in J}</span> of elements of
    a Hilbert space <span class='inline'>\mathfrak{H}</span> is called <i>total</i> in <span class='inline'>\mathfrak{H}</span> if the linear span
    of <span class='inline'>A</span> is dense in  <span class='inline'>\mathfrak{H}</span>. By density of the algebraic tensor product
    <span class='inline'>\mathfrak{H}_1\otimes \mathfrak{H}_2</span> in the Hilbert tensor product
    <span class='inline'>\mathfrak{H}_1{\,\widehat{\otimes}\,} \mathfrak{H}_2</span>, the set of simple tensors <span class='inline'>v_1\otimes v_2</span>
    with <span class='inline'>v_i \in \mathfrak{H}_i</span> for <span class='inline'>i= 1,2</span>  is total in <span class='inline'>\mathfrak{H}_1{\,\widehat{\otimes}\,} \mathfrak{H}_2</span>.
    Hence it suffices to find for such <span class='inline'>v_i</span> and all <span class='inline'>\varepsilon  > 0</span>
    vectors <span class='inline'>w_i \in \operatorname{Span} A_i</span> for <span class='inline'>i= 1,2</span> such that
    <br><br><span class='display'>
                \| v_1\otimes v_2 - w_1\otimes w_2 \|  <  \frac{\varepsilon}{2} . 
    </span><br>
    By totality of <span class='inline'>A_i</span> in <span class='inline'>\mathfrak{H}_i</span> there exist <span class='inline'>w_i \in \operatorname{Span} A_i</span>  such that
    <br><br><span class='display'>
      \| v_1 - w_1 \|  <  \min \left\{ 1, \frac{\varepsilon}{2(\| v_2 \| +1 ) } \right\}
      \quad \text{and}\quad
      \| v_2 - w_2 \|  <  \frac{\varepsilon}{2(\| v_1 \| +1 ) } . 
    </span><br>
    Then
    <br><br><span class='display'>
      \| v_1\otimes v_2 - w_1\otimes w_2 \| \leq
      \| v_1 - w_1 \| \, \| v_2 \| +  \|  v_2 - w_2 \| \| w_1 \|   <  \varepsilon . 
    </span><br>
    
  </li><li value='\itshape ad (\itshape II\hspace1pt). '>
  The family <span class='inline'>(e_i\otimes f_j)_{(i,j)\in I \times J}</span> is orthonormal by definition of the inner product on
  <span class='inline'>\mathfrak{H}_1 {\,\widehat{\otimes}\,} \mathfrak{H}_2</span>. It is total by
  (I) and therefore a Hilbert basis.
  
  </li></ol><p>



<br><br><strong>Proposition 25.5</strong>
  
  Assigning to each pair of Hilbert spaces <span class='inline'>\mathfrak{H}_1</span> and <span class='inline'>\mathfrak{H}_2</span> the Hilbert tensor product
  <span class='inline'>\mathfrak{H}_1 {\,\widehat{\otimes}\,}  \mathfrak{H}_2</span>
  and to each pair of bounded linear operators <span class='inline'>A_1:\mathfrak{H}_1 \to \mathfrak{H}_3</span> and  <span class='inline'>A_2:\mathfrak{H}_2 \to \mathfrak{H}_4</span>
  between Hilbert spaces the unique bounded extension
  <span class='inline'>A_1 {\,\widehat{\otimes}\,} A_2 : \mathfrak{H}_1 {\,\widehat{\otimes}\,} \mathfrak{H}_2 \to   \mathfrak{H}_3 {\,\widehat{\otimes}\,}  \mathfrak{H}_4</span> of the operator
  <span class='inline'>A_1 \otimes A_2 : \mathfrak{H}_1 \otimes \mathfrak{H}_2 \to   \mathfrak{H}_3 {\,\widehat{\otimes}\,}  \mathfrak{H}_4</span>,
  <span class='inline'>v_1 \otimes v_2 \mapsto A_1(v_1) \otimes  A_2(v_2)</span>
  comprises a (covariant) bifunctor 
  <br><br><span class='display'> {\,\widehat{\otimes}\,} : \mathsf{Hilb} \times \mathsf{Hilb} \to \mathsf{Hilb} . </span><br>
  Moreover, <span class='inline'>{\,\widehat{\otimes}\,}</span> is isometric in the sense that
  <br><br><span class='display'> \tag{25.6}
    
    \| v_1 \otimes v_2\|  = \|v_1\| \, \|v_2\| \quad \text{for all } v_1\in \mathfrak{H}_1, \: v_2 \in \mathfrak{H}_1 \text{ and }</span><br><br><span class='display'>
    
    \| A_1 {\,\widehat{\otimes}\,}     A_2\|  = \| A_1\| \, \|A_2\| \quad \text{for all }
       A_1\in \mathfrak{B} ( \mathfrak{H}_1, \mathfrak{H}_3 ), \: A_2\in \mathfrak{B} ( \mathfrak{H}_2, \mathfrak{H}_4 ) . 
  </span><br><br>
<br><br>

<br><i>Proof.</i>
  We first show that <span class='inline'>A_1 \otimes A_2 </span> is a bounded operator. To this end observe that
  <span class='inline'>A_1 \otimes A_2 </span> can be written as the composition of the two operators <span class='inline'>A_1\otimes \mathbbm{1}_{\mathfrak{H}_2}</span>
  and <span class='inline'> \mathbbm{1}_{\mathfrak{H}_3} \otimes A_2</span>. Hence it suffices to show that each of these linear maps is bounded.
  Let <span class='inline'>v = \sum_{k=1}^n v_{1k} \otimes v_{2k} \in \mathfrak{H}_1 \otimes \mathfrak{H}_2</span> be of norm <span class='inline'>1</span>.
  As in the proof of \Crefthm:construction-tensor-inner-product  expand 
  <span class='inline'> v_{2k} = \sum_{i=1}^m c_{ki} e_i</span>, <span class='inline'>k=1,\ldots ,n</span>, where <span class='inline'>e_1, \ldots , e_m</span> is an orthonormal basis of
  <span class='inline'>\operatorname{Span} \{ v_{21}, \ldots , v_{2n}\}</span>  and <span class='inline'>c_{k1}, \ldots , c_{km} \in \mathbb{K}</span>. 
  Equations \eqrefeq:expansion-tensor-product-vector-orthonormal-basis-second-component
  and \eqrefeq:positivity-tensor-inner-product then entail that
  <br><br><span class='display'>
    v = \sum_{i=1}^m  w_{1i}  \otimes  e_i \quad\text{and}\quad
    1  = \langle v,v \rangle  = \sum_{i=1}^m \| w_{1i} \|^2 
  </span><br>
  for <span class='inline'> w_{1i} = \sum_{k=1}^n   c_{ki} v_{1k} </span>, <span class='inline'>i=1,\ldots , m</span>.
  Hence
  <br><br><span class='display'>
    \|( A_1 \otimes \mathbbm{1}_{\mathfrak{H}_2})v \|^2 =  \left\| \sum_{i=1}^m A_1 (w_{1i}) \otimes e_i\right\|^2
    = \sum_{i=1}^m \| A_1 (w_{1i}) \|^2 \leq \|A_1\|^2 \sum_{i=1}^m \| w_{1i} \|^2  = \|A_1\|^2  ,
  </span><br>
  so <span class='inline'>A_1\otimes \mathbbm{1}_{\mathfrak{H}_2}</span> is bounded with norm <span class='inline'>\leq \|A_1\|</span>.
  By symmetry,  <span class='inline'> \mathbbm{1}_{\mathfrak{H}_3} \otimes A_2</span> is  bounded with norm <span class='inline'>\leq \|A_2\|</span>. Hence
  <span class='inline'>A_1 \otimes A_2 = (\mathbbm{1}_{\mathfrak{H}_3} \otimes A_2 )\circ (A_1\otimes \mathbbm{1}_{\mathfrak{H}_2}) </span>
  is bounded and
  <br><br><span class='display'>
    \| A_1 \otimes A_2 \| \leq \|A_1\| \, \|A_2\| .
  </span><br> 
  Let us show the converse inequality. For given <span class='inline'>\varepsilon  > 0</span> there exist
  unit vectors <span class='inline'>v_i \in \mathfrak{H}_i</span>, <span class='inline'>i=1,2</span> such that
  <span class='inline'>\|A_iv_i \|\geq \| A_i \| - \frac{\varepsilon}{2(\| A_1\| +\|A_2\| +1)}</span>. Then
  <br><br><span class='display'>
    \| (A_1 {\,\widehat{\otimes}\,} A_2) (v_1\otimes v_2) \| =   \| A_1v_1\| \,  \| A_2v_2\|
    \geq \| A_1 \| \, \| A_2\| -  \varepsilon .
      </span><br>
  This implies 
  <br><br><span class='display'>
    \| A_1 \otimes A_2 \| \geq \|A_1\| \, \|A_2\| 
  </span><br>
  and \eqrefeq:completed-tensor-product-isometry-equation-bounded-linear-maps follows.
  Equality \eqrefeq:completed-tensor-product-isometry-equation-vectors is clear by
  construction of the Hilbert tensor product.

  Next observe that
  <span class='inline'>\mathbbm{1}_{ \mathfrak{H}_1} {\,\widehat{\otimes}\,} \mathbbm{1}_{\mathfrak{H}_2} = \mathbbm{1}_{\mathfrak{H}_1 {\,\widehat{\otimes}\,} \mathfrak{H}_2}</span>
  by definition.  Given Hilbert spaces <span class='inline'>\mathfrak{H}_1,\ldots,\mathfrak{H}_6</span>
  and bounded linear operators <span class='inline'>A_i: \mathfrak{H}_{i}\to \mathfrak{H}_{i+2}</span> and
  <span class='inline'>B_i : \mathfrak{H}_{i+2}\to \mathfrak{H}_{i+4}</span> for <span class='inline'>i=1,2</span>, the composition 
  <span class='inline'>(B_1 \otimes B_2 ) \circ (A_1 \otimes A_2)</span> coincides with
  <span class='inline'> (B_1\circ A_1) \otimes (B_2\circ A_2) </span> by functoriality of the algebraic tensor product. 
  By continuity of the operators <span class='inline'>A_1 {\,\widehat{\otimes}\,} A_2</span> and <span class='inline'>B_1 {\,\widehat{\otimes}\,} B_2</span> and
  by density of <span class='inline'>\mathfrak{H}_1\otimes \mathfrak{H}_2</span> in <span class='inline'>\mathfrak{H}_1{\,\widehat{\otimes}\,} \mathfrak{H}_2</span>
  the equality 
  <br><br><span class='display'>
    (B_1 {\,\widehat{\otimes}\,} B_2 ) \circ (A_1 {\,\widehat{\otimes}\,} A_2) =
    (B_1\circ A_1) {\,\widehat{\otimes}\,} (B_2\circ A_2)
  </span><br>
  follows. Hence <span class='inline'>{\,\widehat{\otimes}\,}</span> is a bifunctor as claimed. 



<br><br><strong>Proposition 25.6</strong>
 For every Hilbert space <span class='inline'>\mathfrak{H}</span> one has two natural isomorphisms 
  <br><br><span class='display'>
   \widehat{u}_\mathfrak{H} : \mathbb{K} {\,\widehat{\otimes}\,} \mathfrak{H} \to \mathfrak{H} ,\: z\otimes v \to z v \quad \text{and} \quad
   {}_\mathfrak{H} \widehat{u} : \mathfrak{H} {\,\widehat{\otimes}\,} \mathbb{K} \to \mathfrak{H} ,\: v \otimes z \to z v 
  </span><br> 
  called the <i>left</i> and the <i>right  unit</i>, respectively. Furthermore, for every triple of Hilbert spaces
  <span class='inline'>\mathfrak{H}_1,\mathfrak{H}_2,\mathfrak{H}_3</span> there is a natural isomorphism, called <i>associator</i>
  <br><br><span class='display'>
   \widehat{a}_{\mathfrak{H}_1,\mathfrak{H}_2,\mathfrak{H}_3} : (\mathfrak{H}_1 {\,\widehat{\otimes}\,} \mathfrak{H}_2) {\,\widehat{\otimes}\,} \mathfrak{H}_3 \to
   \mathfrak{H}_1 {\,\widehat{\otimes}\,} ( \mathfrak{H}_2  {\,\widehat{\otimes}\,} \mathfrak{H}_3 ),\:
   (v_1\otimes v_2)\otimes v_3 \mapsto v_1\otimes (v_2 \otimes v_3 ). 
  </span><br>  
  These data fulfill the so-called <i>coherence conditions</i> that is the <i>pentagon diagram</i>
  <br><br><span class='display'>
    \begin{tikzpicture}
\node (P0) at (90:2.8cm) {<span class='inline'>((\mathfrak</span>{H}_1 {\,\widehat{\otimes}\,} \mathfrak{H}_2) {\,\widehat{\otimes}\,} \mathfrak{H}_3) {\,\widehat{\otimes}\,} \mathfrak{H}_4<span class='inline'></span>};
\node (P1) at (90+72:2.5cm) {<span class='inline'>(\mathfrak</span>{H}_1{\,\widehat{\otimes}\,} (\mathfrak{H}_2{\,\widehat{\otimes}\,} \mathfrak{H}_3)){\,\widehat{\otimes}\,} \mathfrak{H}_4<span class='inline'></span>} ;
\node (P2) at (90+2*72:2.5cm) {<span class='inline'>\mathllap</span>{\mathfrak{H}_1{\,\widehat{\otimes}\,} ((\mathfrak{H}_2{\,\widehat{\otimes}\,} \mathfrak{H}_3)}{\,\widehat{\otimes}\,} \mathfrak{H}_4)<span class='inline'></span>};
\node (P3) at (90+3*72:2.5cm) {<span class='inline'>\mathfrak</span>{H}_1{\,\widehat{\otimes}\,} (\mathfrak{H}_2\mathrlap{{\,\widehat{\otimes}\,} (\mathfrak{H}_3{\,\widehat{\otimes}\,} \mathfrak{H}_4))}<span class='inline'></span>};
\node (P4) at (90+4*72:2.5cm) {<span class='inline'>(\mathfrak</span>{H}_1{\,\widehat{\otimes}\,} \mathfrak{H}_2){\,\widehat{\otimes}\,} (\mathfrak{H}_3{\,\widehat{\otimes}\,} \mathfrak{H}_4)<span class='inline'></span>};
\draw
(P0) edge[- > , > =angle 90] node[left] {<span class='inline'>\widehat</span>{a}_{\mathfrak{H}_1,\mathfrak{H}_2,\mathfrak{H}_3} {\,\widehat{\otimes}\,} \, \mathbbm{1}_{\mathfrak{H}_4}\hspace{2mm}<span class='inline'></span>} (P1)
(P1) edge[- > , > =angle 90] node[left] {<span class='inline'>\widehat</span>{a}_{\mathfrak{H}_1,\mathfrak{H}_2{\,\widehat{\otimes}\,} \mathfrak{H}_3 , \mathfrak{H}_4}<span class='inline'></span>} (P2)
(P2) edge[- > , > =angle 90] node[below] {<span class='inline'>\hspace</span>{5mm}\mathbbm{1}_{\mathfrak{H}_1}{\,\widehat{\otimes}\,} \, \widehat{a}_{\mathfrak{H}_2,\mathfrak{H}_3,\mathfrak{H}_4}<span class='inline'></span>} (P3)
(P4) edge[- > , > =angle 90] node[right] {<span class='inline'> \widehat</span>{a}_{\mathfrak{H}_1 , \mathfrak{H}_2,\mathfrak{H}_3 {\,\widehat{\otimes}\,}  \mathfrak{H}_4}<span class='inline'></span>} (P3)
(P0) edge[- > , > =angle 90] node[right] {<span class='inline'> \widehat</span>{a}_{\mathfrak{H}_1{\,\widehat{\otimes}\,} \mathfrak{H}_2, \mathfrak{H}_3 , \mathfrak{H}_4}<span class='inline'></span>} (P4);
  \end{tikzpicture}
  </span><br>
  and the <i>triangle diagram</i>
  <br><br><span class='display'>
  \begin{tikzcd}
      ( \mathfrak{H}_1 {\,\widehat{\otimes}\,} \mathbb{K}) {\,\widehat{\otimes}\,} \mathfrak{H}_2 
      \ar[rrrr,"\widehat{a}_{\mathfrak{H}_1,\mathbb{K},\mathfrak{H}_3}"] 
      \ar[drr,"{}_{\mathfrak{H}_1}\!\widehat{u} \, {\,\widehat{\otimes}\,} \,\mathbbm{1}_{\mathfrak{H}_2}",swap]   
      \mathfrak{H}_1 {\,\widehat{\otimes}\,} (\mathbb{K} {\,\widehat{\otimes}\,} \mathfrak{H}_2 )
      \ar[dll,"\mathbbm{1}_{\mathfrak{H}_1} {\,\widehat{\otimes}\,} \, \widehat{u}_{\mathfrak{H}_2}"]  </span><br><br><span class='display'>
        \mathfrak{H}_1 {\,\widehat{\otimes}\,} \mathfrak{H}_2    
  \end{tikzcd}
  </span><br>
  commute for all Hilbert spaces <span class='inline'>\mathfrak{H}_1,\mathfrak{H}_2,\mathfrak{H}_3,\mathfrak{H}_4</span>.  In other words,
  the category <span class='inline'>\mathsf{Hilb}</span> endowed with the Hilbert tensor product <span class='inline'>{\,\widehat{\otimes}\,}</span> is a monoidal  category. 
<br><br>

<br><i>Proof.</i>
  The category of <span class='inline'>\mathbb{K}</span>-vector spaces with the usual tensor product as tensor functor is monoidal.
  Denote the corresponding unit isomorphisms and associator by
  <span class='inline'>_{-}u</span>, <span class='inline'>u_{-}</span>, and <span class='inline'>a_{-,-,-}</span>, respectively. Then observe that by construction
  <span class='inline'>\mathbb{K} {\,\widehat{\otimes}\,} \mathfrak{H} = \mathbb{K} \otimes \mathfrak{H}</span> and <span class='inline'>\mathfrak{H} {\,\widehat{\otimes}\,} \mathbb{K} = \mathfrak{H} \otimes \mathbb{K}</span>
  for every Hilbert space <span class='inline'>\mathfrak{H}</span>. In particular this means that putting  
  <span class='inline'>\widehat{u}_\mathfrak{H} = u_\mathfrak{H}</span> and <span class='inline'>{}_{\mathfrak{H}}\widehat{u} = {}_{\mathfrak{H}}u</span> gives the desired units.
  Next recall that  <span class='inline'>\mathfrak{H}_1 \otimes \mathfrak{H}_2</span> is dense in <span class='inline'>\mathfrak{H}_1 {\,\widehat{\otimes}\,} \mathfrak{H}_2</span> 
  which by \Crefthm:totality-tensor-product-total-sets implies density of <span class='inline'>(\mathfrak{H}_1 \otimes \mathfrak{H}_2) \otimes \mathfrak{H}_3</span>
  and <span class='inline'>\mathfrak{H}_1 \otimes (\mathfrak{H}_2 \otimes \mathfrak{H}_3)</span> in <span class='inline'>(\mathfrak{H}_1 {\,\widehat{\otimes}\,} \mathfrak{H}_2) {\,\widehat{\otimes}\,} \mathfrak{H}_3</span>
  and <span class='inline'>\mathfrak{H}_1 {\,\widehat{\otimes}\,} (\mathfrak{H}_2 {\,\widehat{\otimes}\,} \mathfrak{H}_3)</span>, respectively.
  Similarly one argues that <span class='inline'>\mathfrak{H}_1 \otimes (\mathfrak{H}_2 \otimes (\mathfrak{H}_3\otimes \mathfrak{H}_4))</span>
  is dense in  <span class='inline'>\mathfrak{H}_1 {\,\widehat{\otimes}\,} (\mathfrak{H}_2 {\,\widehat{\otimes}\,} (\mathfrak{H}_3{\,\widehat{\otimes}\,} \mathfrak{H}_4))</span>,
      and so on. Since the associator map
  <span class='inline'>a_{\mathfrak{H}_1,\mathfrak{H}_2,\mathfrak{H}_3} : (\mathfrak{H}_1 \otimes \mathfrak{H}_2) \otimes \mathfrak{H}_3 \to
  \mathfrak{H}_1 \otimes ( \mathfrak{H}_2  \otimes \mathfrak{H}_3 )</span> is bounded, it extends in a unique way to a linear
  bounded map <span class='inline'>\widehat{a}_{\mathfrak{H}_1,\mathfrak{H}_2,\mathfrak{H}_3} : (\mathfrak{H}_1 {\,\widehat{\otimes}\,} \mathfrak{H}_2) {\,\widehat{\otimes}\,} \mathfrak{H}_3 \to
  \mathfrak{H}_1 {\,\widehat{\otimes}\,} ( \mathfrak{H}_2  {\,\widehat{\otimes}\,} \mathfrak{H}_3 )</span>. Using density, continuity, and commutativity
  of the pentagon and triangle diagrams for the tensor product functor one concludes that the coherence conditions for
  <span class='inline'>{\,\widehat{\otimes}\,}</span> with the unit and associator maps <span class='inline'>_{-}\widehat{u}</span>, <span class='inline'>\widehat{u}_{-}</span>, and <span class='inline'>\widehat{a}_{-,-,-}</span> are satisfied. 
 
</p><h1>26 Adjoints of bounded operators</h1><p>


<br><br><strong>26.1</strong> 
Throughout this section, <span class='inline'>\mathfrak{H}</span> stands for a Hilbert space over the 
field <span class='inline'>\mathbb{K}</span> of real or complex numbers. 
Let <span class='inline'>A \in \mathfrak{B} (\mathfrak{H})</span> that is let 
<span class='inline'>A:\mathfrak{H} \rightarrow \mathfrak{H}</span> be linear and bounded. Then the map
<br><br><span class='display'>
 b_A : \mathfrak{H} \times \mathfrak{H} \to \mathbb{K}, \: (v,w) \mapsto \langle v, Aw \rangle 
</span><br>
is sesquilinear and bounded with norm
<br><br><span class='display'>
\left\|b_A\right\| = \sup \big\{ \left| b_A(v,w)\right| \bigm\vert
   v,w\in \mathfrak{H} \:\\: \left\|w\right\|=\left\|v\right\|=1 \big\} = 
                \left\|A\right\| .
</span><br>
By \Crefthm:correspondence-bounded-sesquilinear-forms-bounded-operators 
to the Riesz representation theorem there exists a unique element 
<span class='inline'>A^* \in \mathfrak{B}(\mathfrak{H})</span> such that
<br><br><span class='display'>
 b_A (v,w) = \langle A^* v, w \rangle \quad 
 \text{for all } v,w \in \mathfrak{H} .
</span><br>
This operator satisfies <span class='inline'>\left\|A^*\right\|= \left\|b_A\right\| = \left\|A\right\|</span>. 
<br><br><strong>Definition 26.2</strong>
The unique operator <span class='inline'>A^*\in \mathfrak{B} (\mathfrak{H})</span> associated to some 
<span class='inline'>A\in \mathfrak{B}(\mathfrak{H})</span> such that 
<br><br><span class='display'>
 \langle v,Aw \rangle = \langle A^* v, w \rangle \quad 
 \text{for all } v,w \in \mathfrak{H} 
</span><br>
is called the <i>adjoint</i> of <span class='inline'>A</span>.
<br><br>

<br><br><strong>Proposition 26.3</strong>
If <span class='inline'>A \in \mathfrak{B} (\mathfrak{H})</span>, then so is its adjoint <span class='inline'>A^* \in \mathfrak{B} (\mathfrak{H})</span>.
<br><br>

<br><i>Proof.</i>
First we show that <span class='inline'>A^*</span> is linear. Given <span class='inline'>v, w, w' \in H</span>, we compute
<br><br><span class='display'>
\langle v, A^*(w + w') \rangle = \mu_{A, w+w'}(v) = \langle Av, w + w' \rangle = \langle Av, w \rangle + \langle Av, w' \rangle</span><br><br><span class='display'>
= \mu_{A, w}(v) + \mu_{A, w'}(v) = \langle v, A^*w \rangle + \langle v, A^*w' \rangle = \langle v, A^*w + A^*w' \rangle
</span><br>
Since this is true for all <span class='inline'>v \in H</span>, this implies that <span class='inline'>A^*(w+w') = A^*w'</span>.  Furthermore, given <span class='inline'>\lambda \in \mathbb{K}</span>, we have
<br><br><span class='display'>
\langle v, A^*(\lambda w) \rangle = \mu_{A, \lambda w}(v) = \langle Av, \lambda w \rangle = \widebar \lambda \langle Av, w \rangle</span><br><br><span class='display'>
= \widebar \lambda \mu_{A, w}(v) = \widebar \lambda \langle v, A^* w \rangle = \langle v, \lambda A^*w \rangle.
</span><br>
Again, since this is true for all <span class='inline'>v \in H</span>, we know <span class='inline'>A^*(\lambda w) = \lambda A^*w</span>. This proves that <span class='inline'>A^*</span> is linear.

It remains to show that <span class='inline'>A^*</span> is bounded. We know
<br><br><span class='display'>
\left\|A^*\right\| = \sup_{\left\|v\right\| = \left\|w\right\| = 1} {\left|\langle v, A^* w \rangle\right|} = \sup_{\left\|v\right\| = \left\|w\right\| = 1} {\left|\langle w, Av \rangle\right|} = \left\|A\right\|  <  \infty,
</span><br>
which is what we wanted to show. Note that <span class='inline'>\left\|A^*\right\| = \left\|A\right\|</span>.


We leave it as an exercise to show that
<br><br><span class='display'>
\left\|A\right\| = \sup_{\left\|v\right\| = \left\|w\right\| = 1} {\left|\langle v, Aw \rangle\right|}
</span><br>
for all <span class='inline'>A \in \mathfrak{L} (\mathfrak{H})</span>, as was used in the above proof.


<br><br><strong>Definition 26.4</strong>
An operator <span class='inline'>A \in \mathfrak{L} (\mathfrak{H})</span> is called <i>self-adjoint</i> if <span class='inline'>A = A^*</span>, <i>unitary</i> if <span class='inline'>A^* = A^{-1}</span>, and <i>normal</i> if <span class='inline'>[A, A^*] = AA^* - A^*A = 0</span>.
<br><br>


We note that self-adjoint and unitary operators are always normal, but normal operators do not have to be self-adjoint or unitary. In the remainder of these notes, we gather several results on self-adjoint and normal operators.

<br><br><strong>Lemma 26.5</strong>
An operator <span class='inline'>A \in \mathfrak{L} (\mathfrak{H})</span> is self-adjoint if and only if <span class='inline'>\langle Av, v \rangle \in \mathbb{R}</span> for all <span class='inline'>v \in H</span>.
<br><br>

<br><i>Proof.</i>
<span class='inline'>\Rightarrow</span>) If <span class='inline'>A</span> is self-adjoint, then
<br><br><span class='display'>
\langle Av, v \rangle = \mu_{A,v}(v) = \langle v, A^*v \rangle = \langle v, Av \rangle = \overline{\langle Av,v \rangle},
</span><br>
which implies that <span class='inline'>\langle Av,v \rangle \in \mathbb{R}</span>.

<span class='inline'>\Leftarrow</span>) Suppose that <span class='inline'>\langle Av, v \rangle \in \mathbb{R}</span> for all <span class='inline'>v \in H</span>. We know
<br><br><span class='display'>
\langle A(v+w), v+w \rangle = \langle Av, v \rangle + \langle Av, w \rangle + \langle Aw, v \rangle + \langle Aw, w \rangle. \tag{<span class='inline'>*</span>}
</span><br>
By assumption, <span class='inline'>\langle A(v+w), v+w \rangle</span>, <span class='inline'>\langle Av, v \rangle</span>, and <span class='inline'>\langle Aw, w \rangle</span> are all real. This implies that <span class='inline'>\langle Av, w \rangle + \langle Aw, v \rangle</span> is real as well, so
<br><br><span class='display'>
\Im \langle Av, w \rangle = -\Im \langle Aw, v \rangle= \Im \langle v, Aw \rangle.
</span><br>
Since this holds for all <span class='inline'>w \in H</span>, it holds for <span class='inline'>iw</span> as well. Thus,
<br><br><span class='display'>
\Re \langle Av, w \rangle = \Im \langle Av, -iw \rangle = \Im \langle v, A(-iw) \rangle = \Im i\langle v, Aw \rangle = \Re \langle v, Aw \rangle.
</span><br>
Combining the above two lines yields <span class='inline'>\langle Av, w \rangle = \langle v, Aw \rangle</span> for all <span class='inline'>v, w \in H</span>. Since the adjoint satisfies <span class='inline'>\langle Av, w \rangle = \langle v, A^*w \rangle</span>, this implies that <span class='inline'>A = A^*</span>.


<br><br><strong>Proposition 26.6</strong>
If <span class='inline'>A \in \mathfrak{L} (\mathfrak{H})</span> and <span class='inline'>\langle Av, v \rangle = 0</span> for all <span class='inline'>v \in H</span>, then <span class='inline'>A = 0</span>.
<br><br>

<br><i>Proof.</i>
Since <span class='inline'>\langle Av, v \rangle = 0</span> for all <span class='inline'>v \in H</span>, equation (<span class='inline'>*</span>) from Lemma 4 reduces to
<br><br><span class='display'>
\langle Av, w \rangle = -\langle Aw, v \rangle = -\langle w, Av \rangle = -\overline{\langle Av, w \rangle} \quad \text{for all } v, w \in H ,
</span><br>
i.e.<span class='inline'>\langle Av,w \rangle</span> has no real part for all <span class='inline'>v, w \in H</span>. But then fixing <span class='inline'>v</span> and setting <span class='inline'>w = Av</span> implies <span class='inline'>\left\|Av\right\|^2 = 0</span> for all <span class='inline'>v \in H</span>, so <span class='inline'>A = 0</span>.


<br><br><strong>Proposition 26.7</strong>
If <span class='inline'>A \in \mathfrak{L} (\mathfrak{H})</span> is self-adjoint, then 
<br><br><span class='display'>
\left\|A\right\| = \sup_{\left\|v\right\| = 1} {\left|\langle Av, v \rangle\right|}.
</span><br>
<br><br>

<br><i>Proof.</i>
We know
<br><br><span class='display'>
\left\|A\right\| = \sup_{\left\|v\right\| = \left\|w\right\| = 1} {\left|\langle Av, w \rangle\right|},
</span><br>
so we clearly have
<br><br><span class='display'>
\sup_{\left\|v\right\| = 1} {\left|\langle Av, v \rangle\right|} \leq \left\|A\right\|.
</span><br>


<br><br><strong>Proposition 26.8</strong>
If <span class='inline'>A \in \mathfrak{L} (\mathfrak{H})</span>, then <span class='inline'>A^*A</span> is self-adjoint and <span class='inline'>\left\|A^*A\right\| = \left\|A\right\|^2</span>.
<br><br>

<br><i>Proof.</i>
For arbitrary <span class='inline'>v \in H</span>, we have
<br><br><span class='display'>
\langle A^*Av, v \rangle = \langle Av, Av \rangle = \left\|Av\right\|^2 \in \mathbb{R},
</span><br>
so <span class='inline'>A^*A</span> is self-adjoint by Lemma 4. By Proposition 6,
<br><br><span class='display'>
\left\|A^*A\right\| = \sup_{\left\|v\right\| = 1} {\left|\langle A^*Av, v \rangle\right|}  = \sup_{\left\|v\right\| = 1} \left\|Av\right\|^2 = \left\|A\right\|^2. 
</span><br>


<br><br><strong>Proposition 26.9</strong>
If <span class='inline'>A \in \mathfrak{L} (\mathfrak{H})</span>, then there exist <span class='inline'>B,C \in \mathfrak{L} (\mathfrak{H})</span> self-adjoint such that <span class='inline'>A = B+iC</span>. Furthermore, <span class='inline'>A</span> is normal if and only if <span class='inline'>[B,C] = 0</span>.
<br><br>

<br><i>Proof.</i>
We define
<br><br><span class='display'>
B = \frac{1}{2}(A + A^*) \quad \text{ and } \quad C = \frac{i}{2}(A^* - A).
</span><br>
Clearly <span class='inline'>A = B + iC</span>. Note also that <span class='inline'>A^* = B - iC</span>. Furthermore, for all <span class='inline'>v \in H</span>
<br><br><span class='display'>
\langle Bv, v \rangle = \frac{1}{2} \langle Av, v \rangle + \frac{1}{2}\langle A^*v, v \rangle = \frac{1}{2}\langle Av, v \rangle + \frac{1}{2}\overline{\langle Av, v \rangle} \in \mathbb{R}
</span><br>
and
<br><br><span class='display'>
\langle Cv, v \rangle = \frac{i}{2}\langle A^*v, v \rangle - \frac{i}{2}\langle Av, v \rangle = \frac{i}{2}\overline{\langle Av, v \rangle} - \frac{i}{2}\langle Av, v \rangle \in \mathbb{R}
</span><br>
This implies that <span class='inline'>B</span> and <span class='inline'>C</span> are self-adjoint by Lemma 4.

Finally, we compute
<br><br><span class='display'>
[A, A^*] = [B + iC, B-iC] = -i[B, C] + i[C,B] = -2i[B,C],
</span><br>
Clearly <span class='inline'>A</span> is normal if and only if <span class='inline'>[B,C] = 0</span>. 


<br><br><strong>Proposition 26.10</strong>
If <span class='inline'>A</span> is normal, then <span class='inline'>\left\|Av\right\| = \left\|A^*v\right\|</span> for all <span class='inline'>v \in H</span>.
<br><br>

<br><i>Proof.</i>
Using the fact that <span class='inline'>A^*A = AA^*</span>, we compute
<br><br><span class='display'>
\left\|Av\right\|^2 = \langle Av, Av \rangle = \langle v, A^*Av \rangle = \langle v, AA^*v \rangle = \langle A^*v, A^*v \rangle = \left\|A^*v\right\|^2.
</span><br>
Taking a square root yields the desired result.


</p><h1>27 Projection-valued measures and spectral integrals</h1><p>
<br><br><strong>27.1</strong>
  In this section <span class='inline'>\mathfrak{H}</span> will always denote a fixed complex Hilbert space. 
<br><br><strong>Definition 27.2</strong>
  By a <i>projection-valued measure</i> or a <i>spectral measure</i> on a 
  measurable space <span class='inline'>(\Omega,\mathscr{A})</span> one understands a map 
  <span class='inline'>E: \mathscr{A} \to \mathfrak{B}(\mathfrak{H})</span> having the following properties:
  </p><ol class='enumeration'>
  \setcounterenumi-1
  <li value=' (SM1)'> For each <span class='inline'>\Delta \in \mathscr{A}</span> the operator <span class='inline'>E(\Delta)</span> is an orthogonal projection 
        that is <span class='inline'>E(\Delta)^2 = E(\Delta)</span> and <span class='inline'>E(\Delta)^* = E(\Delta)</span>.
  </li><li value=' (SM2)'> <span class='inline'>E(\Omega) = \mathrm{id}_\mathfrak{H}</span>.
  </li><li value=' (SM3)'> For every sequence <span class='inline'>(\Delta_n)_{n\in \mathbb{N}}</span> of pairwise disjoint elements of <span class='inline'>\mathscr{A}</span> 
        one has 
        <br><br><span class='display'> E\left(\bigcup_{n\in\mathbb{N}} \Delta_n \right) =   {s\,-\!\!}\sum_{n=0}^\infty E(\Delta_n) , </span><br> 
        where convergence is with respect to the strong operator toplogy.
  </li></ol><p>
<br><br>

<br><br><strong>Remark 27.3</strong>
  Recall that <i>convergence</i>  of a sequence of operators 
  <span class='inline'>(A_n)_{n\in \mathbb{N}} \subset \mathfrak{B}(\mathfrak{H})</span> in the <i>strong operator topology</i> to some <span class='inline'>A </span> means 
  that for every <span class='inline'>v\in \mathfrak{H}</span> the sequence <span class='inline'>(A_nv)_{n\in\mathbb{N}}</span> converges in <span class='inline'>\mathfrak{H}</span> to <span class='inline'>Av</span>. 
  One denotes this by <span class='inline'>A ={s\,-\!\!}\lim\limits_{n\to\infty} A_n</span>. 
  Likewise, <span class='inline'>B = {s\,-\!\!}\sum\limits_{n=0}^\infty A_n</span> means that the sequence of partial sums 
  <span class='inline'>\left( \sum\limits_{k=0}^n A_n \right)_{n\in \mathbb{N}}</span> converges  in the strong operator topology 
  to some <span class='inline'>B  \in \mathfrak{B} (\mathfrak{H})</span>.
<br><br>

<br><br><strong>Proposition 27.4</strong>
  A spectral measure <span class='inline'>E : \mathscr{A} \to \mathfrak{B} (\mathfrak{H})</span>   has the following properties
  in addition to the defining axioms:
  </p><ol class='enumeration'>\setcounterenumi1
  <li value='{{\sffamily (SM1')}}\hspace{-1mm}'>\refstepcounteritemno
     <span class='inline'>E(\emptyset) = 0</span>.
  </li><li value='{{\sffamily (SM2')}}\hspace{-1mm}'>\refstepcounteritemno
     (Finite additivity)  One has for all disjoint <span class='inline'>\Delta_1,\Delta_2 \in \mathscr{A}</span>
      <br><br><span class='display'> E( \Delta_1  \cup \Delta_2) = E(\Delta_1) + E(\Delta_2) . </span><br>
  \setcounterenumi2
  </li><li value=' (SM1)'>
     One has for all <span class='inline'>\Delta_1,\Delta_2 \in \mathscr{A}</span> 
     <br><br><span class='display'> E( \Delta_1  \cap \Delta_2) = E(\Delta_1)\cdot E(\Delta_2) . </span><br>
  </li></ol><p>
<br><br>

<br><i>Proof.</i>
  \itshape ad \hyperref[ite:spectral-measure-empty-set] (SM1').

  \itshape ad \hyperref[ite:spectral-measure-finite-additivity] (SM2').

  \itshape ad  (SM1).



</p><h1>28 Spectral theory of bounded operators</h1><p>
<br><br><strong>28.1</strong>
We now apply the foundations of Hilbert space theory built in the previous sections to 
spectral theory. For the moment we will sacrifice generality and work only with bounded
linear operators. The spectral theory of unbounded linear operators will be treated later. 

Let us a recall that a linear map <span class='inline'>A: \mathfrak{H}_1 \rightarrow \mathfrak{H}_2</span> between Hilbert spaces 
is continuous if and only if it is bounded, i.e.has finite operator norm, and that 
<span class='inline'>\mathfrak{B} (\mathfrak{H}_1,\mathfrak{H}_2)</span> is a Banach space with the operator norm. 
For the rest of this section, <span class='inline'>\mathfrak{H}</span>, <span class='inline'>\mathfrak{H}_1</span>, <span class='inline'>\mathfrak{H}_2, \ldots</span> will always 
denote complex Hilbert spaces and <span class='inline'>A</span>, <span class='inline'>B</span> bounded linear operators. 
We will also now fix the base field to be complex, i.e.<span class='inline'>\mathbb{K} = \mathbb{C}</span>.
Last we agree on writing <span class='inline'>I_\mathfrak{H}</span> or just <span class='inline'>I</span> for the identity operator on a Hilbert space 
<span class='inline'>\mathfrak{H}</span>. 

</p><h2>Spectrum and Resolvent</h2><p>\addcontentslinetocsubsectionSpectrum and Resolvent

<br><br><strong>Definition 28.2</strong>
  Let <span class='inline'>A:\mathfrak{H} \to \mathfrak{H}</span> be a bounded linear operator.  A complex number <span class='inline'>\lambda</span>
  is then called an <i>eigenvalue</i> of <span class='inline'>A</span> if there exists a nonzero <span class='inline'>v \in H</span> such that
  <span class='inline'>Av = \lambda v</span>. For every <span class='inline'>\lambda \in \mathbb{C}</span> one defines the <span class='inline'>\lambda</span>-<i>eigenspace</i> of
  <span class='inline'>A</span> as
  <br><br><span class='display'>
   \operatorname{Eig}_\lambda  (A) = \big\{ v \in H \bigm\vert Av = \lambda v \big\} \subset \mathfrak{H},
  </span><br>
 which is clearly a linear subspace of <span class='inline'>\mathfrak{H}</span>. 
<br><br>

<br><br><strong>28.3</strong>
  By definition it is immediately clear that 
 <br><br><span class='display'>
   \operatorname{Eig}_\lambda (A) = \ker(A - \lambda),
 </span><br>
 where the <span class='inline'>\lambda</span> on the right stands for the operator <span class='inline'>\lambda I</span>. 
 In other words this means that
 <span class='inline'>\lambda\in \mathbb{C}</span> is an eigenvalue of <span class='inline'>A</span> if and only if <span class='inline'>A - \lambda</span> is not injective.

<br><br><strong>Definition 28.4</strong>
Let <span class='inline'>A \in \mathfrak{B}(\mathfrak{H})</span>. We make the following definitions.

  </p><ol class='enumeration'>

  <li value='(I)'> A <i>regular value</i> of <span class='inline'>A</span> is a complex number <span class='inline'>\lambda</span> such that <span class='inline'>A-\lambda</span> is invertible.
  </li><li value='(II)'> The set of all regular values is the <i>resolvent</i> of <span class='inline'>A</span>, denoted <span class='inline'>\varrho(A)</span>.
  </li><li value='(III)'> A <i>spectral value</i> of <span class='inline'>A</span> is a complex number <span class='inline'>\lambda</span> such that <span class='inline'>A - \lambda</span> is not 
        invertible.
  </li><li value='(IV)'> The set of all spectral values is the <i>spectrum</i> of <span class='inline'>A</span>, denoted <span class='inline'>\sigma(A)</span>.
  </li><li value='(V)'> The <i>point</i> or <i>eigenspectrum</i> of <span class='inline'>A</span> is the set
	<br><br><span class='display'>
	\sigma_{p}(A) = \big\{\lambda \in \mathbb{C} \bigm\vert \ker(A - \lambda) \neq \{0 \} \big\}.
	</span><br>
  </li><li value='(VI)'> An <i>approximate eigenvalue</i> of <span class='inline'>A</span> is a complex number <span class='inline'>\lambda</span> for which there exists 
        a sequence of unit vectors <span class='inline'>(v_n)_{n\in \mathbb{N}}\subset \mathfrak{H}</span> such that
	<br><br><span class='display'>
   	   \lim_{n \rightarrow \infty} (A - \lambda)v_n = 0.
	</span><br>
	The set <span class='inline'>\sigma_{ap}(A)</span> is the set of all approximate eigenvalues.

  </li></ol><p>

<br><br><strong>28.1</strong> 
Evidently, <span class='inline'>\sigma(A) = \mathbb{C} \setminus \varrho(A)</span> and <span class='inline'>\sigma_{p}(A) \subset \sigma_{ap}(A) \subset \sigma(A)</span>,
and these may all be strict inclusions. Note that <span class='inline'>A - \lambda</span> is bounded for any <span class='inline'>\lambda \in \mathbb{C}</span>, 
so the open mapping theorem ref_error implies that <span class='inline'>(A - \lambda)^{-1} \in \mathfrak{B}(\mathfrak{H})</span> when <span class='inline'>\lambda \in \varrho(A)</span>.
We call the map 
<br><br><span class='display'>
  R_\bullet (A ):\varrho(A) \rightarrow \mathfrak{B}(\mathfrak{H}), \quad R_\lambda (A) = (A-\lambda)^{-1}
</span><br>
the <i>resolvent</i> of <span class='inline'>A</span>, not to be confused with the resolvent set <span class='inline'>\varrho(A)</span>. 
To keep the notation clean, we often briefly write <span class='inline'>R_\lambda</span> for <span class='inline'>R_\lambda(A)</span> and leave implicit that <span class='inline'>R_\lambda</span> depends on <span class='inline'>A</span>.
<br><br>
First, we prove some topological properties of the spectrum and resolvent. Recall the following lemma, which generalizes the geometric series.

<br><br><strong>Lemma 28.5</strong>[Carl Neumann] Let <span class='inline'>A \in \mathfrak{B}(\mathfrak{H})</span>. If <span class='inline'>\left\|A\right\|  <  1</span>, then <span class='inline'>I - A</span> is invertible,
<br><br><span class='display'>
(I - A)^{-1} = \sum_{n=0}^\infty A^n,
</span><br>
and
<br><br><span class='display'>
\left\|(I-A)^{-1}\right\| \leq \frac{1}{1 - \left\|A\right\|}.
</span><br>
<br><br>

<br><i>Proof.</i>
  Since <span class='inline'>\left\|A\right\|  <  1</span> and <span class='inline'>\left\|A^n\right\| \leq \left\|A\right\|^n</span> by submultiplicativity of the operator norm, we know
  <span class='inline'>\sum_{n=0}^\infty \left\|A^n\right\|  <  \infty</span>. This implies that the  family <span class='inline'>(A^n)_{n\in\mathbb{N}}</span> is absolutely summable,
  so <span class='inline'>\sum_{n=0}^\infty A^n</span> exists. Furthermore, for every <span class='inline'>N \in \mathbb{N}</span> we have
  <br><br><span class='display'>
    (I-A)\sum_{n=0}^N A^n = \left(\sum_{n=0}^N A^n \right)(I-A)= \sum_{n=0}^N A^n - \sum_{n=1}^{N+1}A^n = I - A^{N+1},
  </span><br>
which implies that 
<br><br><span class='display'>
\lim_{N \rightarrow \infty}(I-A)\sum_{n=0}^N A^n = \lim_{N \rightarrow \infty} \left(\sum_{n=0}^N A^n\right) (I-A) = I.
</span><br>
By continuity of multiplication in <span class='inline'>\mathfrak{B}(\mathfrak{H})</span> one gets
<br><br><span class='display'>
(I-A) \sum_{n=0}^\infty A^n = \left(\sum_{n=0}^\infty A^n\right) (I-A) = I,
</span><br>
which proves that <span class='inline'>I-A</span> is invertible and <span class='inline'>(I-A)^{-1} = \sum_{n=0}^\infty A^n</span>.

Finally,  one concludes by the triangle inequality and submultiplicativity of the operator norm 
<br><br><span class='display'>
  \left\|(I - A)^{-1}\right\| \leq \sum_{n=0}^\infty \left\|A^n\right\| \leq \sum_{n=0}^\infty \left\|A\right\|^n = \frac{1}{1 - \left\|A\right\|}. 
</span><br>


<br><br><strong>Proposition 28.6</strong>
Let <span class='inline'>A \in \mathfrak{B}(\mathfrak{H})</span>. 

  </p><ol class='enumeration'>

<li value='(I)'> For any <span class='inline'>\lambda \in \varrho(A)</span>, one has
	<br><br><span class='display'>
	B_{\left\|R_{\lambda}\right\|^{-1}}(\lambda) \subset \varrho(A) .
	</span><br>
	Hence, <span class='inline'>\varrho(A) \subset \mathbb{C}</span> is open.
</li><li value='(II)'> The spectrum <span class='inline'>\sigma(A)</span> is compact and
	<br><br><span class='display'>
	\sigma(A) \subset \widebar{B}_{\left\|A\right\|}(0) .
	</span><br>
</li><li value='(III)'> If the complex number <span class='inline'>\lambda</span> satisfies <span class='inline'>{\left|\lambda\right|}  >  \left\|A\right\|</span>, then <span class='inline'>\lambda \in \varrho(A)</span> and
      <br><br><span class='display'>
	R_\lambda = - \frac{1}{\lambda} - \sum_{n=1}^\infty \lambda^{-n-1}A^n ,
      </span><br>
      where convergence is with respect to the operator norm.  

  </li></ol><p>

<br><br>

<br><i>Proof.</i>
 
  </p><ol class='enumeration'>

 <li value='\itshape ad (\itshape I\hspace1pt). '> 
 Fix <span class='inline'>\lambda \in \varrho(A)</span> and set <span class='inline'>r = \left\|R_{\lambda}\right\|^{-1}</span>. Let <span class='inline'>\mu \in B_r(\lambda)</span>. Then
<br><br><span class='display'>
 \left\|(\mu - \lambda)R_{\lambda}\right\| = {\left|\mu - \lambda\right|} \left\|R_{\lambda}\right\|  <  1.
</span><br>
Thus, by Lemma 28.5, one knows that <span class='inline'>I - (\mu - \lambda)R_{\lambda}</span> is invertible. Since <span class='inline'>A - \lambda</span> is invertible,
the composition
<br><br><span class='display'>
(A - \lambda) \, \big( I - (\mu - \lambda)R_{\lambda} \big) = A - \mu
</span><br>
is invertible, which proves that <span class='inline'>\mu \in \varrho(A)</span>. Hence <span class='inline'>\varrho(A)</span> is open.


</li><li value='\itshape ad (\itshape II\hspace1pt). '> Since <span class='inline'>\varrho(A)</span> is open, the complement <span class='inline'>\sigma(A) = \mathbb{C} \setminus \varrho(A)</span> is closed. Furthermore, if <span class='inline'>{\left|\lambda\right|}  >  \left\|A\right\|</span>, then <span class='inline'>\left\|\lambda^{-1}A\right\|  <  1</span>, so <span class='inline'>I - \lambda^{-1}A</span> and hence <span class='inline'>A - \lambda</span> are invertible by Lemma 28.5. This implies that <span class='inline'>\lambda \in \varrho(A)</span>, so <span class='inline'>\sigma(A) \subset \widebar{B}_{\left\|A\right\|}(0)</span>. Since <span class='inline'>\sigma(A)</span> is closed and bounded, it is compact.
</li><li value='\itshape ad (\itshape III\hspace1pt). '> If <span class='inline'>{\left|\lambda\right|}  >  \left\|A\right\|</span>, then <span class='inline'>I - \lambda^{-1}A</span> is invertible by Lemma 28.5 and
<br><br><span class='display'>
(I - \lambda^{-1}A)^{-1} = \sum_{n=0}^\infty \lambda^{-n}A^n.
</span><br>
Since <span class='inline'>-\lambda(A - \lambda)^{-1} = (I - \lambda^{-1}A)^{-1}</span>, one obtains
<br><br><span class='display'>
R_\lambda = -\frac{1}{\lambda}\sum_{n=0}^\infty \lambda^{-n}A^n = -\frac{1}{\lambda} - \sum_{n=1}^\infty \lambda^{-n-1}A^n,
</span><br>
as desired.   

  </li></ol><p>



Next, we prove some algebraic properties of the resolvent. Hereby, <span class='inline'>[A,B] = AB - BA</span> denotes the commutator of two operators,
as usual.

<br><br><strong>Proposition 28.7</strong>
Let <span class='inline'>A,B \in \mathfrak{B}(\mathfrak{H})</span>. Then the following holds true.

  </p><ol class='enumeration'>

<li value='(I)'> The resolvent commutes with the operator which means that
  <br><br><span class='display'> [A, R_\lambda(A) ] = 0 \quad\text{for all } \lambda \in \varrho(A) . </span><br>
</li><li value='(II)'>
   The values of the resolvent commute with each other that is
 <br><br><span class='display'> [R_\lambda (A), R_\mu (A)] = 0 \quad\text{for all } \lambda,\mu \in \varrho(A) . </span><br>
</li><li value='(III)'>( First resolvent identity) For all <span class='inline'>\lambda, \mu \in \varrho(A)</span>
  <br><br><span class='display'> R_\lambda(A) - R_\mu (A)= (\lambda - \mu)R_\lambda(A) R_\mu(A) . </span><br>
</li><li value='(IV)'>( Second resolvent identity) For all <span class='inline'>\lambda \in \varrho(A)\cap \varrho(B)</span>
  <br><br><span class='display'> R_\lambda (A)- R_\lambda (B) = R_\lambda(A)\, (B-A) \, R_\lambda (B) . </span><br> 

  </li></ol><p>

<br><br>

<br><i>Proof.</i>

  </p><ol class='enumeration'>

<li value='\itshape ad (\itshape I\hspace1pt). '> Obviously  <span class='inline'>[A, A - \lambda] = 0</span>, so
  <br><br><span class='display'>
    0 = R_\lambda [A, A - \lambda]R_\lambda = R_\lambda A - AR_\lambda,
  </span><br>
as desired.
\setcounterenumi2
</li><li value='\itshape ad (\itshape II\hspace1pt). '> We compute
<br><br><span class='display'>
(R_\lambda - R_\mu)(A - \mu)(A - \lambda) = (R_\lambda A - \mu R_\lambda)(A - \lambda) - (A - \lambda)</span><br><br><span class='display'>
= (A - \mu)R_\lambda (A - \lambda) - (A - \lambda)</span><br><br><span class='display'>
= \lambda - \mu ,
</span><br>
where we used part (I) to commute <span class='inline'>R_\lambda</span> past <span class='inline'>A</span> in the second step.
Now multiplying both sides with <span class='inline'>R_\lambda R_\mu </span> from the right yields the desired equality. 
\setcounterenumi1
</li><li value='\itshape ad (\itshape III\hspace1pt). '> 
  For <span class='inline'>\lambda = \mu</span>, one obviously has <span class='inline'>[A_\lambda, A_\mu] = 0</span>. For <span class='inline'>\lambda \neq \mu</span>, one concludes from
  (II)
  <br><br><span class='display'>
     R_\mu R_\lambda = \frac{R_\mu - R_\lambda}{\mu - \lambda} = \frac{R_\lambda - R_\mu}{\lambda - \mu} = R_\lambda R_\mu,
  </span><br>
  so <span class='inline'>[R_\lambda, R_\mu] = 0</span> for <span class='inline'>\lambda \neq \mu </span> as well.
\setcounterenumi3
</li><li value='\itshape ad (\itshape IV\hspace1pt). '>  The  last equality follows by
  <br><br><span class='display'> R_\lambda(A)\, (B-A) \, R_\lambda (B) =  R_\lambda(A)\, \big((B-\lambda)-(A-\lambda) \big) \, R_\lambda (B) =
     R_\lambda(A) - R_\lambda (B) . </span><br>

  </li></ol><p>



The resolvent <span class='inline'>R_\bullet (A)</span> also has some nice analytic properties which we are going to prove next. 
<br><br><strong>Proposition 28.8</strong>
  The resolvent <span class='inline'>R_\bullet (A) :\varrho(A) \rightarrow \mathfrak{B}(\mathfrak{H})</span>, <span class='inline'>\lambda \mapsto R_\lambda</span> is continuous and complex
  differentiable with derivative given by 
  <br><br><span class='display'>
    R_\bullet(A)' :\: \varrho(A) \rightarrow \mathfrak{B}(\mathfrak{H}),  \: \lambda \mapsto \lim_{\mu \rightarrow \lambda} \frac{R_\mu - R_\lambda}{\mu - \lambda} =  R_\lambda^2
  </span><br>
<br><br>

<br><i>Proof.</i>
Fix <span class='inline'>\lambda \in \varrho(A)</span> and <span class='inline'>\varepsilon  >  0</span>. Let <span class='inline'>0  <  {\left|\mu - \lambda\right|}  <  \delta</span>, where 
<br><br><span class='display'>
  \delta = \min\left( \frac{\varepsilon}{2\left\|R_\lambda\right\|^2},\, \frac{1}{2\left\|R_\lambda\right\|} \right) .
</span><br>
Note that <span class='inline'>\mu \in \varrho(A)</span> by Proposition 28.6. Moreover, <span class='inline'>\left\|(\mu - \lambda)R_\lambda\right\|  < 1</span>, so <span class='inline'>I - (\mu - \lambda)R_\lambda</span> is invertible with norm less than <span class='inline'>(1 - \left\|(\mu - \lambda) R_\lambda\right\|)^{-1}</span> by Lemma 28.5.
Now observe that the first resolvent identity can be rearranged to
<br><br><span class='display'>
R_\mu =  R_\lambda[I - (\mu - \lambda)R_\lambda]^{-1} .
</span><br>
Hence
<br><br><span class='display'>
\left\|R_\mu - R_\lambda\right\| \leq {\left|\mu - \lambda\right|}\left\|R_\mu\right\|\left\|R_\lambda\right\| </span><br><br><span class='display'>
\leq {\left|\mu - \lambda\right|} \left\|R_\lambda\right\|^2 \left\|(I - (\mu - \lambda)R_\lambda)^{-1}\right\|</span><br><br><span class='display'>
\leq \frac{{\left|\mu - \lambda\right|} \left\|R_\lambda\right\|^2}{1 - \left\|(\mu - \lambda)R_\lambda\right\|}</span><br><br><span class='display'>
 <  \frac{\varepsilon/2}{1-1/2} = \varepsilon .
</span><br>
This proves that <span class='inline'>\lambda \mapsto R_\lambda</span> is continuous. 

As for complex differentiability, we simply use the first resolvent identity and continuity to conclude
<br><br><span class='display'>
\lim_{\mu \rightarrow \lambda} \frac{R_\mu - R_\lambda}{\mu - \lambda} = \lim_{\mu \rightarrow \lambda} R_\mu R_\lambda = R_\lambda^2. 
</span><br>


<br><br><strong>Proposition 28.9</strong>
Let <span class='inline'>A \in \mathfrak{B}(\mathfrak{H})</span>. Then <span class='inline'>\lambda R_\lambda \rightarrow -I</span> as <span class='inline'>{\left|\lambda\right|} \rightarrow \infty</span>. In particular, <span class='inline'>R_\lambda \rightarrow 0</span> as <span class='inline'>{\left|\lambda\right|} \rightarrow \infty</span>.
<br><br>

<br><i>Proof.</i>
Fix <span class='inline'>\varepsilon  >  0</span>.  For <span class='inline'>{\left|\lambda\right|}  >  \left\|A\right\|</span>, we have by \Crefthm:resolvent-topological-properties (III)
<br><br><span class='display'>
\lambda R_\lambda = -I - \sum_{n=1}^\infty \lambda^{-n}A^n.
</span><br>
Since 
<br><br><span class='display'>
\left\|\sum_{n=1}^\infty \lambda^{-n}A^n\right\| \leq  \frac{\left\|A\right\|}{{\left|\lambda\right|}-\left\|A\right\|},
</span><br>
one sees that <span class='inline'>\lambda R_\lambda \rightarrow - I</span> as <span class='inline'>{\left|\lambda\right|} \rightarrow \infty</span>. Similarly, for <span class='inline'>{\left|\lambda\right|}  >  \left\|A\right\|</span> one has
<br><br><span class='display'>
\left\|R_\lambda\right\| \leq \frac{1}{{\left|\lambda\right|}} + \frac{1}{{\left|\lambda\right|}}\sum_{n=1}^\infty \left\|\lambda^{-n}A^n\right\| \leq \frac{1}{{\left|\lambda\right|}} + \frac{1}{{\left|\lambda\right|}} \frac{\left\|A\right\|}{{\left|\lambda\right|} - \left\|A\right\|},
</span><br>
which shows that <span class='inline'>R_\lambda \rightarrow 0</span> as <span class='inline'>{\left|\lambda\right|} \rightarrow \infty</span>.


<br><br><strong>Proposition 28.10</strong>
For all <span class='inline'>v, w \in \mathfrak{H}</span>, the map 
<br><br><span class='display'>
 \langle  R_\bullet (A) v,  w \rangle : \: \varrho(A) \rightarrow \mathbb{C} , \: \lambda \mapsto \langle  R_\lambda v, w \rangle
</span><br>
is holomorphic with derivative
<br><br><span class='display'>
 \langle  R_\bullet (A) v, w \rangle' : \: \varrho(A) \rightarrow \mathbb{C} , \: \lambda \mapsto \langle R_\lambda^2 v,  w \rangle.
</span><br>
<br><br>

<br><i>Proof.</i>
Given <span class='inline'>\lambda \in \varrho(A)</span>, we compute
<br><br><span class='display'>
  \lim_{\mu \rightarrow \lambda} \frac{\langle R_\mu v, w \rangle - \langle R_\lambda v,  w \rangle}{\mu - \lambda} =
  \lim_{\mu \rightarrow \lambda} \frac{\langle (\mu - \lambda)R_\mu R_\lambda v,  w \rangle}{\mu - \lambda} =
  \lim_{\mu \rightarrow \lambda} \langle  R_\mu R_\lambda v, w \rangle = \langle R_\lambda^2v , w \rangle,
</span><br>
where we have used the first resolvent identity in the first step and continuity of the inner product in the last.


<br><br><strong>Proposition 28.11</strong>
The spectrum of an operator <span class='inline'>A \in \mathfrak{B}(\mathfrak{H})</span> is nonempty.
<br><br>

<br><i>Proof.</i>
Suppose <span class='inline'>\sigma(A) = \emptyset</span>, hence <span class='inline'>\varrho(A) = \mathbb{C}</span>. The map
<br><br><span class='display'>
\mathbb{C} \to \mathbb{C} , \: \lambda \mapsto \langle R_\lambda v, w \rangle
</span><br>
then is entire for every <span class='inline'>v, w \in \mathfrak{H}</span>. Furthermore, one has  for <span class='inline'>\left\|v\right\|, \left\|w\right\| \leq 1</span>
<br><br><span class='display'>
  {\left|\langle R_\lambda v,  w \rangle\right|} \leq  \left\|R_\lambda\right\| \left\|v\right\| \left\|w\right\| \leq \left\|R_\lambda\right\| .
</span><br>
Since <span class='inline'>\lambda \mapsto \left\|R_\lambda\right\|</span> is continuous and <span class='inline'>\left\|R_\lambda\right\| \rightarrow 0</span> as <span class='inline'>{\left|\lambda\right|} \rightarrow \infty</span>, one sees
that <span class='inline'>\left\|R_\lambda\right\|</span> is bounded. Hence <span class='inline'>\langle R_\bullet v,  w \rangle</span> is a bounded entire function, which  by Liouville's theorem implies
that it is zero for every pair <span class='inline'>v, w \in \mathfrak{H}</span> with <span class='inline'>\left\|v\right\| = \left\|w\right\| = 1</span>.
This entails that <span class='inline'>R_\lambda = 0</span> for every <span class='inline'>\lambda \in \mathbb{C}</span>, which 
is a contradiction to <span class='inline'>R_\lambda</span> being invertible. Hence <span class='inline'>\sigma(A) \neq \emptyset</span>.




</p><h1>29 Unbounded linear operators</h1><p>

<br><br><strong>29.1</strong> 
In this section let <span class='inline'>\mathrm{V},\mathrm{W}</span> always denote Banach spaces over the field 
<span class='inline'>\mathbb{K} =\mathbb{R}</span> or <span class='inline'>\mathbb{K}=\mathbb{C}</span>. The symbols <span class='inline'>\mathfrak{H}</span>, <span class='inline'>\mathfrak{H}_1</span>, ... will always stand for Hilbert spaces over <span class='inline'>\mathbb{K}</span>. 

<br><br><strong>Definition 29.2</strong> 
  By an <i>unbounded <span class='inline'>\mathbb{K}</span>-linear operator</i> or shortly by an 
  <i>unbounded operator</i> from <span class='inline'>\mathrm{V}</span> to <span class='inline'>\mathrm{W}</span> we understand a linear map 
  <span class='inline'>A: \operatorname{Dom} (A) \to \mathrm{W}</span> defined on a <span class='inline'>\mathbb{K}</span>-linear subspace <span class='inline'>\operatorname{Dom} (A)\subset \mathrm{V}</span>.
  As usual, <span class='inline'>\operatorname{Dom} (A)</span> is called the <i>domain</i> of the operator <span class='inline'>A</span>.
  The space of unbounded <span class='inline'>\mathbb{K}</span>-linear operators from <span class='inline'>V</span> to <span class='inline'>W</span> will be 
  denoted <span class='inline'>\mathfrak{L}_\mathbb{K} (V,W)</span> or just  <span class='inline'>\mathfrak{L} (V,W)</span>.
<br><br>

<br><br><strong>Remark 29.3</strong>
  In this work, the term ``unbounded'' is meant in the sense of
  ``not necessarily bounded''. Sometimes we just say 
  <i>linear operator</i> or even only <i>operator</i> instead of
  ``unbounded linear operator''.
<br><br>

<br><br><strong>29.4</strong> Observe that besides the domain <span class='inline'>\operatorname{Dom} (A)</span> of an unbounded operator 
  <span class='inline'>A \in \mathfrak{L} (\mathrm{V},\mathrm{W})</span> the 
  <i>kernel</i> 
  <br><br><span class='display'>\operatorname{Ker}(A)=\big\{ v \in \mathrm{V} \bigm\vert Av = 0 \big\}\subset\mathrm{V} , </span><br>
  the <i>image</i> 
  <br><br><span class='display'>\operatorname{Im}(A)=\big\{ w \in \mathrm{W} \bigm\vert \exists v\in \operatorname{Dom} (A): w = Av \big\}
  \subset \mathrm{W} , </span><br> 
  and the <i>graph</i>
  <br><br><span class='display'>\operatorname{Gr}(A)=\big\{ (v,w) \in \operatorname{Dom} (A) \times \mathrm{W} \bigm\vert 
    w = Av \big\} \subset \mathrm{V} \times \mathrm{W} </span><br>
  of <span class='inline'>A</span>  are all linear subspaces. We will frequently make use of this.
  
<br><br><strong>Definition 29.5</strong>
  An unbounded operator <span class='inline'>A\in \mathfrak{L} (\mathrm{V},\mathrm{W})</span> is called 
  <i>densely defined</i> if <span class='inline'>\operatorname{Dom} (A)</span> is dense in <span class='inline'>\mathrm{V}</span>,
  and <i>closed</i> if the graph <span class='inline'>\operatorname{Gr} (A)</span> 
  is closed in <span class='inline'>\mathrm{V} \times \mathrm{W}</span>.
  The operator <span class='inline'>A \in \mathfrak{L} (V,W)</span> is called <i>closable</i> if the closure
  <span class='inline'>\widebar{\operatorname{Gr}(A)}</span> is the graph of an unbounded operator 
  from <span class='inline'>\mathrm{V}</span> to <span class='inline'>\mathrm{W}</span>. 

  An operator <span class='inline'>A \in \mathfrak{L} (V,W)</span> is called an <i>extension</i> of 
  <span class='inline'>B \in \mathfrak{L} (V,W)</span> if <span class='inline'>\operatorname{Gr} (B) \subset \operatorname{Gr} (A)</span>. One writes in this
  situation <span class='inline'>B \subset A</span>. 
<br><br>

  
   


\chapterC<span class='inline'>^*</span>-Algebras




</p><h1>30 Infinite tensor products</h1><p>


<br><br><strong>30.1</strong>
Infinite tensor products of Hilbert spaces were introduced by  <dt-cite key="vNeuIDP"></dt-cite>. They were motivated by mathematical physics
where one needs to describe quantum systems with infinitely many degrees of freedom, see e.g.~<dt-cite key="EmcAMSMQFT"></dt-cite><dt-cite key="BraRobOAQSM2"></dt-cite>.
The original construction of infinite tensor products was generalized to von Neumann  and <span class='inline'>C^*</span>-algebras
by <dt-cite key="GuiPTIRRA"></dt-cite>, <dt-cite key="BlaITPC*A"></dt-cite>, and others. Meanwhile, the topic has been studied in quite some
detail in the operator algebra literature, see e.g.~<dt-cite key="NakITPvNAI"></dt-cite><dt-cite key="NakITPvNAII"></dt-cite><dt-cite key="StoITPvNA"></dt-cite>. 
A purely algebraic or better categorical approach allowing the construction of infinite tensor products of modules over
a given commutative ring has been given in <dt-cite key="ERROR"></dt-cite>[Sec.~III.10]CheFCA. The work <dt-cite key="NgGIATP"></dt-cite> is also in that spirit.
We will essentially follow <dt-cite key="CheFCA"></dt-cite> and construct the infinite tensor product as a module
universal with respect to multilinear maps. First we present the main algebraic construction, then we explain some of
the subtleties which distinguish infinite from finite tensor products, and finally we construct infinite Hilbert
tensor products and infinite tensor products of <span class='inline'>C^*</span>-algebras. 

<br><br><strong>30.2</strong>
Let <span class='inline'>R</span> be a commutative ring and <span class='inline'>(M_i)_{i\in I}</span> a possibly infinite family of <span class='inline'>R</span>-modules.
Consider <span class='inline'>\prod_{i\in I} M_i</span>, the product of the family <span class='inline'>(M_i)_{i\in I}</span>  within the category
of <span class='inline'>R</span>-modules. For each <span class='inline'>j\in I</span> let <span class='inline'>\pi_j : \prod_{i\in I} M_i \to M_j </span> denote the natural
projection onto the <span class='inline'>j</span>-th factor and <span class='inline'>\iota_j :M _j \hookrightarrow  \prod_{i\in I}M_i</span> the
uniquely determined natural embedding such that 
<br><br><span class='display'>
   \pi_j\circ \iota_i =  
   \begin{cases}
       \mathrm{id}_{M_i} & \text{for}\enspace i=j \enspace\text{and} \\
       0 & \text{else} .  
   \end{cases}
</span><br>
Given an <span class='inline'>R</span>-module <span class='inline'>N</span>  one then understands by a <i>multilinear map</i> from <span class='inline'> \prod_{i\in I}M_i</span>
to <span class='inline'>N</span> a map <span class='inline'>f:  \prod_{i\in I}M_i \to N</span>
such that for each <span class='inline'>j\in I</span> and <span class='inline'>x\in \prod_{i\in I} M_i</span> with <span class='inline'>\pi_j (x)=0</span> the map <span class='inline'>M_j\to N</span>, <span class='inline'>m\mapsto f(\iota_j(m)+x)</span> is linear.
The set of multilinear maps from <span class='inline'>\prod_{i\in I} M_i</span> to <span class='inline'>N</span> will be denoted by
<span class='inline'>\mathfrak{Mlin} \big(\prod_{i\in I} M_i,N\big)</span>. It carries a natural structure of an <span class='inline'>R</span>-module
given by pointwise addition of multilinear maps and pointwise action of a scalar on a
multilinear map that is by  
<br><br><span class='display'>
  f+ g =  \left( \prod_{i\in I} M_i \ni x \mapsto f(x) + g(x) \in N \right) \quad\text{and}\quad
  r f =  \left( \prod_{i\in I} M_i \ni x \mapsto rf(x)\in N \right) 
</span><br>
for all <span class='inline'>f,g \in \mathfrak{Mlin} \big(\prod_{i\in I} M_i,N\big)</span> and <span class='inline'>r\in R</span>.
Since for <span class='inline'>j\in I</span> and <span class='inline'>x\in \prod_{i\in I} M_i</span> with <span class='inline'>\pi_j(x)= 0</span> the maps
<span class='inline'>M_j\to N</span>, <span class='inline'>m \mapsto (f+g) (\iota_j(m) + x) = f (\iota_j(m) + x) + g (\iota_j(m) + x)</span>
and <span class='inline'>M_j\to N</span>, <span class='inline'>m \mapsto rf (\iota_j(m) + x) </span> are linear by assumption on <span class='inline'>f</span> and <span class='inline'>g</span>,
the maps <span class='inline'>f+g</span> and <span class='inline'>rf</span> are multilinear again, so <span class='inline'> \mathfrak{Mlin}\big(\prod_{i\in I} M_i,N\big)</span> is an
<span class='inline'>R</span>-module indeed with zero element the constant function mapping to <span class='inline'>0\in N</span>. 

<br><br><strong>Remarks 30.3</strong>
  Before proceeding further let us make several explanations concerning the notation used.
  
  </p><ol class='enumeration'>

  <li value='(a) '>
    The space of multilinear maps <span class='inline'> \mathfrak{Mlin} \big(\prod_{i\in I} M_i,N\big)</span> actually depends
    on the family <span class='inline'>(M_i)_{i\in I}</span> and the <span class='inline'>R</span>-module <span class='inline'>N</span>, so in principle one should  write
    <span class='inline'> \mathfrak{Mlin} \big((M_i)_{i\in I},N\big)</span> instead of <span class='inline'> \mathfrak{Mlin} \big(\prod_{i\in I} M_i,N\big)</span>.
    Nevertheless we stick to the latter notation since it is closer to standard notation for
    linear maps and since it will not lead  to any confusion.
  </li><li value='(b) '>
    In case the index set <span class='inline'>I</span> has just two elements <span class='inline'>i_1,i_2</span>, one calls a multilinear map
    <span class='inline'>\prod_{i\in I}M_i = M_{i_1}\times M_{i_2} \to N</span> a <i>bilinear map</i>. If the cardinality of
    <span class='inline'>I</span> is <span class='inline'>3</span>, one sometimes calls a multilinear map <span class='inline'>\prod_{i\in I}M_i \to N</span> a
    <i>trilinear map</i>. 
    
  </li><li value='(c) '>
     In the following, when saying that <span class='inline'>(I_a)_{a\in A}</span> is a partition of the set <span class='inline'>I</span> we mean that
  each <span class='inline'>I_a</span> is a non-empty subset of <span class='inline'>I</span>, that <span class='inline'>I_a   \cap I_b =\emptyset </span>
  for <span class='inline'>a \neq b</span> and that <span class='inline'>\bigcup_{a \in A} I_a = I</span>. The empty family is regarded as
  a partition of the empty set.
    
  </li><li value='(d) '> We will frequently use in this section the same symbol for 
  maps with the same ``universal'' properties  despite those maps might be  strictly speaking different. 
  For example, <span class='inline'>\pi_k</span> will stand for the canonical projections
  <span class='inline'>\prod_{i\in I} M_i \to M_k</span> and <span class='inline'>\prod_{j\in J} M_j \to M_k</span> whenever <span class='inline'>k\in J \subset I</span>. 
  Likewise we use the same notation for the two canonical embeddings 
  <span class='inline'>M_k \hookrightarrow \prod_{i\in I} M_i </span> and <span class='inline'>M_k \hookrightarrow \prod_{j\in J} M_j </span>
  defined in label_error and denote them both by <span class='inline'>\iota_k</span>.

  
  </li></ol><p>

<br><br>

<br><br><strong>Lemma 30.4</strong>[cf.~<dt-cite key="ERROR"></dt-cite>[Sec.~III.10, Lemma 1 \& 2]CheFCA]
  Assume that <span class='inline'>(M_i)_{i\in I}</span> is a family of <span class='inline'>R</span>-modules, <span class='inline'>N</span> an <span class='inline'>R</span>-module, and
  <span class='inline'>f : \prod_{i\in I}M_i \to N</span> a mutilinear map.
  
  </p><ol class='enumeration'>

  <li value='(I)'>
    If <span class='inline'>g :N \to N^\prime</span> is an <span class='inline'>R</span>-module map, then
    <span class='inline'>g\circ f :  \prod_{i\in I}M_i \to N^\prime</span> is multilinear.
  </li><li value='(II)'>
    Let <span class='inline'>J\subset I</span> be non-empty, <span class='inline'>y= (y_i)_{i\in I\setminus J}</span> an element of the product
    <span class='inline'>\prod_{i\in I\setminus J} M_i</span>, and <span class='inline'> \iota_{J,y} :  \prod_{j\in J} M_j \to \prod_{i\in I} M_i</span> the unique map
    such that for all <span class='inline'>x = (x_j)_{j\in J} \in  (M_j)_{j\in J}</span> and <span class='inline'>k\in I</span>
    <br><br><span class='display'>
      \pi_k \circ \iota_{J,y}\, (x) = 
      \begin{cases}
        x_k & \text{for } k\in J , \\
        y_k & \text{for } k \in I\setminus J .
      \end{cases}
    </span><br>
    Then the composition <span class='inline'>f\circ \iota_{J,x} : \prod_{j\in J} M_j \to N</span> is multilinear.
 </li><li value='(III)'>
   Let <span class='inline'>(I_a)_{a \in A}</span> be a partition of the index set <span class='inline'>I</span> which is assumed to be non-empty.
   Let <span class='inline'>(N_a)_{a \in A}</span> be a family of <span class='inline'>R</span>-modules, <span class='inline'>(g_a)_{a \in A}</span>
   a family of multilinear maps <span class='inline'>g_a : \prod_{i \in I_a} M_i \to N_a</span>, and
   <span class='inline'>h :  \prod_{a \in A}N_a \to N</span> multilinear. Define
   <span class='inline'>g: \prod_{i\in I} M_i \to  \prod_{a \in A} N_a </span> as the unique map
   such that 
   <br><br><span class='display'>
      \pi_b \circ g = g_b \circ \pi_{I_b} \quad 
      \text{for } b \in A  ,
    </span><br>
    where <span class='inline'>\pi_J</span> for <span class='inline'>J\subset I</span> as on the right side stands for the
    projection <span class='inline'>\pi_J : \prod_{i\in I} M_i \to  \prod_{j \in J} M_j</span>
    uniquely determined by <span class='inline'>\pi_j \circ \pi_J =\pi_j</span> for all <span class='inline'>j\in J</span>. 
   Then the  composition <span class='inline'>h \circ g : \prod_{i\in I} M_i \to N</span> is multilinear.
  
  </li></ol><p>

<br><br>

<br><i>Proof.</i>
  
  </p><ol class='enumeration'>

  <li value='\itshape ad (\itshape I\hspace1pt). '>
    Let <span class='inline'>j\in I</span> and <span class='inline'>x\in \prod_{i\in I} M_i</span> with <span class='inline'>\pi_j (x)=0</span>.
    By multilinearity of <span class='inline'>f</span> and linearity of <span class='inline'>g</span>, the map <span class='inline'>M_j\to N^\prime</span>,
    <span class='inline'>m\mapsto g f (\iota_j(m)+x)</span> then has to be linear, hence <span class='inline'>g\circ f</span> is multilinear.
  </li><li value='\itshape ad (\itshape II\hspace1pt). '>
    Let <span class='inline'>j \in J</span> and <span class='inline'>x\in \prod_{i\in J} M_i</span> with <span class='inline'>\pi_j (x)= 0</span>.
                                    Then <span class='inline'>\pi_j(\iota_{J,y}(x))=0</span> and <span class='inline'>f \iota_{J,y} (\iota_j(m)+x) =
    f(\iota_j(m) + \iota_{J,y}(x)</span> for all <span class='inline'>m\in M_j</span> by  construction of <span class='inline'>\iota_{J,y}</span>.
    Hence the map <span class='inline'>M_j\to N</span>, <span class='inline'>m\mapsto f \iota_{J,y} (\iota_j(m)+x)</span> is linear by
    multilinearity of <span class='inline'>f</span>. This proves that <span class='inline'>f\circ \iota_{J,y}</span> is multilinear.
  </li><li value='\itshape ad (\itshape III\hspace1pt). '>
    Given <span class='inline'>j\in I</span> let <span class='inline'>b</span> be the unique element of <span class='inline'>A</span>  such that <span class='inline'>j\in I_b</span>.
    Assume  that <span class='inline'>x\in \prod_{i\in I} M_i</span> with <span class='inline'>\pi_j (x)=0</span>.
    By construction one has <span class='inline'>\pi_j(\pi_{I_b} (x))=0</span>.
    Now let <span class='inline'>y \in \prod_{a \in A}N_a</span> such that
    <br><br><span class='display'>
       \pi_a (y) =
       \begin{cases}
         0 & \text{for } a = b , \\
         g_a \pi_{I_a} (x) & \text{for } a  \neq b.
       \end{cases}
    </span><br>
    One then obtains for <span class='inline'>m\in M_j</span>
    <br><br><span class='display'>
    \pi_a g ( \iota_j(m) + x)= 
    \begin{cases}
      g_b \pi_{I_b} (\iota_j(m)+x) = g_b (\iota_j (m) + \pi_{I_b} (x)) &\text{for }a = b, \\
      g_a \pi_{I_a} (x) =  \pi_a (y)  & \text{for } a  \neq b .
    \end{cases}
    </span><br>
    Hence 
    <br><br><span class='display'>
      h g (\iota_j(m)+ x) =
      h \big( \iota_b \big( g_b ( \iota_j(m) + \pi_{I_b} (x) \big) + y \big) ,
    </span><br>
    and the map <span class='inline'>M_j\to N</span>, <span class='inline'>m\mapsto h g (\iota_j(m)+ x)</span> is linear as the composition of two linear maps. 
  
  </li></ol><p>



<br><br><strong>Lemma 30.5</strong>
  Assume to be given a non-empty family of <span class='inline'>R</span>-modules <span class='inline'>(M_i)_{i\in I}</span> and a partition 
  <span class='inline'>(I_a)_{a \in A}</span> of the index set <span class='inline'>I</span>. Then there exists a natural ismorphism
  <br><br><span class='display'>
    \kappa_{I,A}:  \prod_{i \in I} M_i \to \prod_{a \in A}  \prod_{i \in I_a} M_i
  </span><br>
  uniquely determined by the condition that <span class='inline'>\pi_a \circ \kappa_{I,A} = \pi_{I_a}</span> for all
  <span class='inline'>a\in A</span>.
      <br><br>
<br><i>Proof.</i>
  By the universal property of the product the <span class='inline'>R</span>-module map 
  <span class='inline'> \kappa = \kappa_{I,A}:  \prod_{i \in I} M_i \to \prod_{a \in A}  \prod_{i \in I_a} M_i</span>
  exists and is uniquely determined by the requirement  that <span class='inline'>\pi_a \circ \kappa_{I,A} = \pi_{I_a}</span>
  for all <span class='inline'>a\in A</span>. Naturality also follows from the universal property of the product.
  It remains to show that <span class='inline'>\kappa</span> is an isomorphism. By construction,
  <span class='inline'>\pi_i(x) = \pi_i \pi_a \kappa (x) =0</span> for all <span class='inline'>i\in I</span> and <span class='inline'>a(i)\in A</span> such that <span class='inline'>i\in I_{a(i)}</span>,
  hence <span class='inline'>x=0</span>.
  So <span class='inline'>\kappa</span> is injective. It is also surjective. To see this pick <span class='inline'>x_a \in \prod_{i \in I_a} M_i</span>
  for each <span class='inline'>a\in A</span>. With <span class='inline'>a(i)</span> for <span class='inline'>i\in I</span> defined as before put
  <span class='inline'>x = \big( \pi_i (x_{a(i)} )\big)_{i\in I}</span>. Then, by construction,
  <span class='inline'>\pi_i \pi_{a} \kappa (x) = \pi_i \pi_{a} (x) = \pi_i (x) = \pi_i (x_{a})</span> for all <span class='inline'>a\in A</span> and
  <span class='inline'>i\in I_a</span>,
  hence <span class='inline'>\big(\pi_a \kappa (x) \big)_{a \in A} = (x_a)_{a \in A}</span>
  and <span class='inline'>\kappa</span> is surjective. 


<br><br><strong>Proposition 30.6</strong>[Exponential law for multilinear maps]

  Let <span class='inline'>(M_i)_{i\in I}</span> be a family of <span class='inline'>R</span>-modules over a commutative ring <span class='inline'>R</span>,
  <span class='inline'>N</span> an <span class='inline'>R</span>-module, 
  and assume that <span class='inline'>J \subset I</span> is a non-empty subset such that the complement
  <span class='inline'>K = I\setminus J</span> is also non-empty. Then the map
  <br><br><span class='display'>
  
    \eta_{I,J}: \:
    \mathfrak{Mlin} \left( \prod_{j\in J} M_j , \mathfrak{Mlin} \left(\prod_{k\in K} M_k ,N \right)\right)
    \rightarrow \mathfrak{Mlin} \left( \prod_{i\in I} M_i, N \right), </span><br><br><span class='display'>
     \hspace{1em} f \mapsto \left( \prod_{i\in I} M_i\ni (x_i)_{i\in I} \mapsto
    f\big( (x_j)_{j\in J} \big)\left( (x_k)_{k\in K} \right)  \in N \right) 
  
  </span><br>
  is an isomorphism which is natural in <span class='inline'>(M_i)_{i\in I}</span> and <span class='inline'>N</span>.
<br><br>

<br><i>Proof.</i>
  
  We first show that <span class='inline'>\eta= \eta_{I,J} </span> is linear. To this end let

  <span class='inline'>f,g \in \mathfrak{Mlin} \left( \prod_{j\in J} M_j , \mathfrak{Mlin} \left(\prod_{k\in K} M_k ,N \right)\right)</span> and <span class='inline'>r\in R</span>.
  Then, for all <span class='inline'>x = (x_i)_{i\in I} \in \prod_{i\in I} M_i</span>,
  <br><br><span class='display'>
  
    \big( \eta (f  +g)\big) (x)  = \big(f+g\big) \big( (x_j)_{j\in J} \big)\left( (x_k)_{k\in K} \right)
    = \big( f((x_j)_{j\in J}) + g ((x_j)_{j\in J})\big) \left( (x_k)_{k\in K} \right) = </span><br><br><span class='display'>
     = f((x_j)_{j\in J})  \left( (x_k)_{k\in K} \right) +  g ((x_j)_{j\in J}) \left( (x_k)_{k\in K} \right) =
     \big( \eta f \big) (x) + \big( \eta g \big) (x) =  \big( \eta f + \eta g \big) (x) 
  
  </span><br>
  and
  <br><br><span class='display'>
  
    \big( \eta (rf)\big) (x)  = (rf) ((x_j)_{j\in J})  \left( (x_k)_{k\in K} \right) =
    \big( r f((x_j)_{j\in J})\big) \left( (x_k)_{k\in K} \right) =
    r \big( f((x_j)_{j\in J})\left( (x_k)_{k\in K} \right)\big) = </span><br><br><span class='display'>
     = r \big( \eta f (x)\big) =  \big( r (\eta f ) \big) (x) .
  
  </span><br>
  Hence <span class='inline'>\eta</span> is an <span class='inline'>R</span>-module map.

  Next we show that <span class='inline'>\eta</span> is an isomorphism by constructing an inverse.
  Given <span class='inline'>f \in \mathfrak{Mlin} \big( \prod_{i\in I} M_i, N \big)</span> we define
  <span class='inline'>f^\sharp : \mathfrak{Mlin} \big( \prod_{j\in J} M_j \big) \to \mathfrak{Mlin} \big(\prod_{k\in K} M_k ,N \big)</span> by the requirement that 
  <br><br><span class='display'>
      f^\sharp (y) (z) = f (x_{y,z}) \quad \text{for all}\enspace y = (y_j)_{j\in J}\enspace \text{and} \enspace z = (z_k)_{k \in K} ,
  </span><br>
  where <span class='inline'>x_{y,z}</span> is the  element of <span class='inline'>\prod_{i\in I}M_i</span> uniquely determined by
  <br><br><span class='display'>
    \pi_i (x_{y,z}) =
    \begin{cases}
      y_i & \text{for}\enspace i \in J , \\
      z_i & \text{for}\enspace i \in K .   
    \end{cases}
  </span><br> 
  One thus obtains an <span class='inline'>R</span>-module map 
  <br><br><span class='display'>
    (-)^\sharp_{I,J} :
    \mathfrak{Mlin} \left( \prod_{i\in I} M_i, N \right) \to
    \mathfrak{Mlin} \left( \prod_{j\in J} M_j , \mathfrak{Mlin} \left(\prod_{k\in K} M_k ,N \right)\right),\quad f \mapsto f^\sharp
  </span><br>
  which by construction is inverse to <span class='inline'>\eta_{I,J}</span>. 

  Naturality of <span class='inline'>\eta_{I,J}</span> in <span class='inline'>(M_j)_{j\in J}</span> and <span class='inline'>N</span> is clear by definition. 


<br><br><strong>Definition 30.7</strong>
  Let <span class='inline'>(M_i)_{i\in I}</span> be a family of <span class='inline'>R</span>-modules over a commutative ring <span class='inline'>R</span>. By a
  <i>tensor product</i> of  <span class='inline'>(M_i)_{i\in I}</span> one understands an <span class='inline'>R</span>-module <span class='inline'>\bigotimes_{i\in I}M_i</span>
  together with a multilinear map
  <span class='inline'>\tau : \prod_{i\in I}M_i \to \bigotimes_{i\in I}M_i</span> such that the following universal property is fulfilled:
  </p><ol class='enumeration'>
  <li value='{\sffamily (ITensor)}'>
   
   For every <span class='inline'>R</span>-module <span class='inline'>N</span> and every multilinear map 
   <span class='inline'>f : \prod_{i\in I}M_i \to N</span> there exists a unique <span class='inline'>R</span>-module map
   <span class='inline'>\overline{f}: \bigotimes_{i\in I}M_i \to N</span> 
   such that the diagram 
   <br><br><span class='display'>
   \begin{tikzcd}
       \prod\limits_{i\in I}M_i  \ar[d,"\tau",swap] \ar[r,"f"]   N </span><br><br><span class='display'>
       \bigotimes\limits_{i\in I}M_i \ar[ru,"\overline{f}",swap]
   \end{tikzcd}
   </span><br>
   commutes.
 </li></ol><p> 

 The linear map <span class='inline'>\overline{f}</span> making the diagram comute will sometimes be called the <i>linearization</i>
 of the multilinear map <span class='inline'>f</span>.
   
 Given a tensor product
 <span class='inline'>\big( \bigotimes_{i\in I}M_i,\tau\big)</span>, we will usually denote the image of an element 
 <span class='inline'>(x_i)_{i\in I} \in \prod_{i\in I}M_i</span>
 under the map <span class='inline'>\tau</span> by <span class='inline'>\otimes_{i\in I} x_i</span>. 
<br><br>

<br><br><strong>Remarks 30.8</strong>
  
  </p><ol class='enumeration'>

  <li value='(a) '>
    Strictly speaking, a tensor product of a family <span class='inline'>(M_i)_{i\in I}</span> of <span class='inline'>R</span>-modules is a pair
    <span class='inline'>\big( \bigotimes_{i\in I}M_i,\tau\big)</span> having the above properties. By slight abuse of language, one
    usually denotes a tensor product just by its first component, the <span class='inline'>R</span>-module <span class='inline'>\bigotimes_{i\in I}M_i</span>.
    When helpful for clarity, the associated map <span class='inline'>\tau: \prod_{i\in I}M_i \to \bigotimes_{i\in I}M_i</span>
    will be denoted by <span class='inline'>\tau_{(M_i)_{i\in I}}</span> or by <span class='inline'>\tau_I</span>. 
  </li><li value='(b) '>   
    In the case where the index set <span class='inline'>I</span>  of the family <span class='inline'>(M_i)_{i\in I}</span> is infinite, one
    sometimes calls <span class='inline'>\bigotimes_{i\in I}M_i</span> an <i>infinite tensor product</i>. 
  
  </li></ol><p>

<br><br>



<br><br><strong>Theorem 30.9</strong>
  Let <span class='inline'>(M_i)_{i\in I}</span> be a family of <span class='inline'>R</span>-modules over a commutative ring <span class='inline'>R</span>. Then the following
  holds true.
  
  </p><ol class='enumeration'>

  <li value='(I)'>
    A tensor product <span class='inline'>\bigotimes_{i\in I}M_i</span> of the family <span class='inline'>(M_i)_{i\in I}</span> exists and is
    unique up to isomorphism. 
    If <span class='inline'>I</span> is the empty set, then <span class='inline'>\bigotimes_{i\in I}M_i = R</span>, if <span class='inline'>I</span> contains a single element <span class='inline'>i_\circ</span>,
    then  <span class='inline'>\bigotimes_{i\in I}M_i =M_{i_\circ}</span>.   
  </li><li value='(II)'>
    If <span class='inline'>(N_i)_{i\in I}</span> is a second family of <span class='inline'>R</span>-modules and <span class='inline'>(f_i)_{i\in I}</span> a family
    <span class='inline'>R</span>-module maps <span class='inline'>f_i :M_i \to N_i</span>, then there exists a unique linear map 
    <span class='inline'>\bigotimes_{i\in I}f_i: \bigotimes_{i\in I}M_i \to \bigotimes_{i\in I}N_i</span> making
    the  diagram
    <br><br><span class='display'>
    \begin{tikzcd}
       \prod\limits_{i\in I}M_i  \ar[d,"\tau",swap] \ar[r,"f"]  \bigotimes\limits_{i\in I}N_i   </span><br><br><span class='display'>
       \bigotimes\limits_{i\in I}M_i \ar[ru,"\bigotimes\limits_{i\in I}f_i",swap]
   \end{tikzcd}
   </span><br>
   commute, where <span class='inline'>f:\prod_{i\in I}M_i\to \bigotimes_{i\in I}N_i</span> is the multilinear map
   <span class='inline'>(x_i)_{i\in I}\mapsto \otimes_{i\in I} f_i(x_i)</span>.
 </li><li value='(III)'>
   Let <span class='inline'>J\subset I</span> be a finite non-empty subset set such that  <span class='inline'>M_j</span> is isomorphic  to <span class='inline'>R</span> for all <span class='inline'>j\in J</span>.
   Denote for each <span class='inline'>j\in J</span> by <span class='inline'>1_j</span> the image of the unit <span class='inline'>1\in R</span> under the isomorphism <span class='inline'>R\cong M_j</span>
   and by <span class='inline'>1_J</span> the family <span class='inline'>(1_j)_{j\in J}</span>. Moreover, for every family <span class='inline'>y =(y_j)_{j\in J}</span>
   let <span class='inline'>\iota_{J,y} : \prod_{i\in I\setminus J} M_i \to \prod_{i\in I}M_i</span> be the map which associates
   to <span class='inline'>x\in\prod_{i\in I\setminus J} M_i</span> the family <span class='inline'> (x_i)_{i\in I}</span> such that <span class='inline'>x_i =\pi_i (x)</span> for
   <span class='inline'>i \in I\setminus J</span> and  <span class='inline'>x_i = y_i</span> for <span class='inline'>i \in J</span>. Then the linearization
   <span class='inline'>\overline{\iota}_{J,1_J}: \bigotimes_{i\in I\setminus J}M_i \to  \bigotimes_{i\in I}M_i </span> of the multilinear map
   <span class='inline'>\tau_I \circ \iota_{J,1_J}: \prod_{i\in I\setminus J}M_i \to  \bigotimes_{i\in I}M_i</span> is an isomorphism. 
  
  </li></ol><p>

<br><br> 

<br><i>Proof.</i>

  </p><ol class='enumeration'>

<li value='\itshape ad (\itshape I\hspace1pt). '>
  By its universal property, the tensor product of the family <span class='inline'>(M_i)_{i\in I}</span> is uniquely determined
  up to isomorphism. Hence it remains to show the existence of the tensor product.
  To this end consider the free <span class='inline'>R</span>-module    over the set <span class='inline'>\prod_{i\in I}M_i</span> and denote it by <span class='inline'>F</span>. Let  <span class='inline'>\delta: \prod_{i\in I}M_i \hookrightarrow F</span> be
  the canonical injection  
      and <span class='inline'>U</span> be the submodule of <span class='inline'>F</span> spanned by the elements
  <br><br><span class='display'>
    \delta \big( \iota_j (r y_j + z_j) + (x_i)_{i\in I} \big) - r \delta \big( \iota_j (y_j) + (x_i)_{i\in I}\big)
    - \delta \big( \iota_j (z_j) + (x_i)_{i\in I}\big) ,
  </span><br>
  where <span class='inline'>j\in I</span>, <span class='inline'>y_j , z_j \in M_j</span>, <span class='inline'>r \in R</span>,  and <span class='inline'>(x_i)_{i\in I} \in \pi_j^{-1} (0)</span>. Then put
  <span class='inline'>\bigotimes_{i\in I}M_i = F/U</span> and define <span class='inline'>\tau</span> as the composition of the canonical projection
  <span class='inline'>\pi : F \to \bigotimes_{i\in I}M_i</span>  with <span class='inline'>\delta : \prod_{i\in I}M_i \to F</span>. By construction, <span class='inline'>\tau</span> is multilinear.
  Assume that <span class='inline'>N</span> is an <span class='inline'>R</span>-module and <span class='inline'>f : \prod_{i\in I}M_i \to N</span> is a multilinear map. By the universal property of
  free <span class='inline'>R</span>-modules, <span class='inline'>f</span> lifts to a unique <span class='inline'>R</span>-linear map <span class='inline'>f^\prime : F \to N</span> such that <span class='inline'>f = f^\prime \circ \delta</span>.
  By multilinearity of <span class='inline'>f</span>, the map <span class='inline'>f^\prime</span> vanishes on the submodule <span class='inline'>U</span>, hence descends to an <span class='inline'>R</span>-linear
  <span class='inline'>\overline{f}: \bigotimes_{i\in I}M_i \to N</span> such that <span class='inline'>f^\prime = \overline{f} \circ \pi</span>.
  Hence  <span class='inline'>f = f^\prime \circ \delta = \overline{f} \circ \pi  \circ \delta  = \overline{f} \circ \tau</span>.
  By surjectivity of <span class='inline'>\delta</span> and uniqueness of <span class='inline'>f^\prime</span>, <span class='inline'>\overline{f}</span> is the unique <span class='inline'>R</span>-linear map satisfying
  <span class='inline'>f = \overline{f} \circ \tau</span>. Hence <span class='inline'>\big( \bigotimes_{i\in I}M_i,\tau\big)</span> is a tensor product of the family
  <span class='inline'>(M_i)_{i\in I}</span>.
  
  In case <span class='inline'>I=\emptyset</span>, the cartesian product <span class='inline'>\prod_{i\in I}M_i</span> is final in the category of sets, hence 
  consists of only one element <span class='inline'>\star</span> only. This means in particular that 
  for an <span class='inline'>R</span>-module <span class='inline'>N</span>  any map <span class='inline'>f: \prod_{i\in I}M_i = \{ \star\} \to N</span> is multilinear. Put 
  <span class='inline'>\bigotimes_{i\in I}M_i = R</span> and let <span class='inline'>\tau : \{ \star\} \to R</span> be the map <span class='inline'>\star \mapsto 1</span>. 
  Now let <span class='inline'>\overline{f}: R \to N</span> be the unique linear map such that <span class='inline'>\overline{f}(1)= f(\star)</span>.
  Then <span class='inline'>f = \overline{f}\circ \tau</span> 
  and the pair <span class='inline'>(R,\tau)</span> fulfills the universal property of the tensor product. 
  
  If <span class='inline'>I</span> is a singleton with unique element <span class='inline'>i_0</span>, then <span class='inline'>\prod_{i\in I} M_i = M_{i_0}</span> 
  and a map <span class='inline'>f: \prod_{i\in I} M_i \to N</span> is multilinear if and only if <span class='inline'>f</span> as a map from <span class='inline'>M_{i_\circ}</span> to <span class='inline'>N</span> 
  is linear. This implies that the pair <span class='inline'>(M_{i_0},\mathrm{id}_{M_{i_\circ}})</span> then is a tensor product 
  for the family <span class='inline'>(M_i)_{i\in I}</span>. 
</li><li value='\itshape ad (\itshape II\hspace1pt). '> This is an immediate consequence of the universal property of the tensor product.
</li><li value='\itshape ad (\itshape III\hspace1pt). '>
  We construct an inverse to
  <span class='inline'>\overline{\iota}_{J,1_J}: \bigotimes_{i\in I\setminus J}M_i \to  \bigotimes_{i\in I}M_i </span>.
  Let <span class='inline'>x = (x_i)_{i\in I}</span> be an element of <span class='inline'>\prod_{i\in I}M_i</span> and put
  <br><br><span class='display'>
    \lambda (x) =  \left( \prod_{j\in J} x_j \right)\cdot \otimes_{i\in I\setminus J} x_i
    \left( \prod_{j\in J} x_j \right) \cdot \tau_{I\setminus J} ((x_i)_{i\in I\setminus J}) .
  </span><br>
  Then <span class='inline'>\lambda : \prod_{i\in I}M_i \to \bigotimes_{i\in \setminus J} M_i</span>
  is multilinear by construction, hence factors through a linear map
  <span class='inline'>\overline{\lambda} : \bigotimes_{i\in I}M_i \to \bigotimes_{i\in I \setminus J} M_i</span>.
  By definition, <span class='inline'>\overline{\lambda}</span> is a left inverse of <span class='inline'>\overline{\iota}_{J,1_J}</span>. It is also a
  right inverse since for all <span class='inline'>(x_i)_{i\in I} \in \prod_{i\in I}M_i</span>  by multilinearity of <span class='inline'>\tau_I</span>  
  <br><br><span class='display'>
  
     \overline{\iota}_{J,1_J} \circ  \overline{\lambda}\circ  \tau_I  \left( (x_i)_{i\in I} \right)   =
    \overline{\iota}_{J,1_J}
    \left( \left( \prod_{j\in J} x_j \right) \cdot  \otimes_{i\in I\setminus J} x_i \right)
    =\left( \prod_{j\in J} x_j\right)\cdot\left( \overline{\iota}_{J,1_J} \circ \tau_{I\setminus J}
    \left((x_i)_{i\in I\setminus J}\right)\right) = </span><br><br><span class='display'>  \hspace{-5em}
    =\left( \prod_{j\in J} x_j\right)\cdot\left( \tau_I \circ 
    \iota_{J,1_J}\left( (x_i)_{i\in I\setminus J}\right)\right) =
    \tau_I \circ \iota_{J,(x_j)_{j\in J}}\left( (x_i)_{i\in I\setminus J}\right) =
    \tau_I \left( (x_i)_{i\in I}\right)   
  </span><br>
  and since by construction of the tensor product the image of <span class='inline'>\tau_I</span> is a generating system for
  the <span class='inline'>R</span>-module <span class='inline'>\bigotimes_{i\in I}M_i</span>.

  </li></ol><p>



<br><br><strong>Lemma 30.10</strong> 
  Assume that <span class='inline'>(M_i)_{i\in I}</span> is a finite family of <span class='inline'>R</span>-modules such that for every <span class='inline'>i\in I</span> a
  generating set <span class='inline'>S_i</span> of the <span class='inline'>R</span>-module <span class='inline'>M_i</span> has been given. Then the set
  <span class='inline'>S = \tau \left( \prod_{i\in I}S_i \right)</span> is a generating set of the tensor product
  <span class='inline'>\bigotimes_{i\in I} M_i</span>. 
<br><br>

<br><i>Proof.</i>
  By construction of the tensor product in the proof of
  \Crefthm:construction-fundamental-properties-infinite-tensor-product it is clear that
  a generating set of <span class='inline'>\bigotimes_{i\in I} M_i</span> is given by the set
  of elements of the form <span class='inline'>\otimes_{i\in I}x_i</span> where <span class='inline'>(x_i)_{i\in I}\in \prod_{i\in I}M_i</span>.
  Each of the <span class='inline'>x_i</span> can now be represented in the form
  <br><br><span class='display'>
    x_i = \sum_{k=1}^{n_i} r_{i,k} s_{i,k} \quad\text{with}\enspace r_{i,1},\ldots ,r_{i,n_i}\in R,\enspace
    s_{i,1},\ldots ,s_{i,n_i}\in S_i .
  </span><br>
  Hence, by multilinearity of <span class='inline'>\tau</span> and with <span class='inline'>I=\{ i_1,\ldots ,i_d\}</span>,
  <br><br><span class='display'>
    \otimes_{i\in I}x_i = \tau \left( (x_i)_{i\in I} \right) =
    \sum_{k_{i_1} =1}^{n_{i_1}}\cdots  \sum_{k_{i_d} =1}^{n_{i_d}} r_{i_1,k_{i_1}} \cdot \ldots \cdot r_{i_d,k_{i_d}}
    \cdot \tau \left( (s_{i,k_i})_{i\in I} \right)  ,
  </span><br> 
  so <span class='inline'>\otimes_{i\in I}x_i</span> is a linear combination of elements of <span class='inline'>S</span> and the claim is proved. 


<br><br><strong>Lemma 30.11</strong>
  Let <span class='inline'>(M_i)_{i\in I}</span> be a family of <span class='inline'>R</span>-modules, <span class='inline'>(I_a)_{a\in A}</span> a finite partition
  of the index set <span class='inline'>I</span>, and <span class='inline'>N</span> an <span class='inline'>R</span>-module. For <span class='inline'>a\in A</span> put
  <span class='inline'>N_a = \bigotimes_{i\in I_a} M_i</span> and let <span class='inline'>\tau_a:  \prod_{i\in I_a} M_i \to  N_a</span>
  denote the canonical map. Assume that
  <span class='inline'>f : \prod_{a\in A}\prod_{i\in I_a} M_i \to N</span> is a map which is
  <i>componentwise multilinear</i> in the following sense. 
  \beginitemize
  \item[<span class='inline'>(\mathsf{ CM})</span>\hspace-1mm]
    Let <span class='inline'>b\in A</span> and <span class='inline'>y=(y_a)_{a\in A}   \in \prod_{a\in A}\prod_{i\in I_a} M_i </span>
    a family with <span class='inline'>y_b =0</span>. If for all <span class='inline'>j\in I_b</span> and families
    <span class='inline'>x=(x_i)_{i\in I_b}\in \prod_{i\in I_b} M_i</span> with <span class='inline'>x_j  =0</span> the  map
    <br><br><span class='display'>
       M_j \to N , \enspace m \mapsto f( \iota_b (\iota_j (m) + x) + y)
    </span><br>
    is linear, then <span class='inline'>f</span> factors through
    <span class='inline'>(\tau_a)_{a\in A}: \prod_{a\in A}\prod_{i\in I_a} M_i \to
    \prod_{a\in A}N_a </span>. More precisely, there exists
    a unique multilinear map <span class='inline'>\overline{f} : \prod_{a\in A}N_a \to N</span> such that
    <br><br><span class='display'>
       f = \overline{f} \circ (\tau_a)_{a\in A} .
    </span><br>
  \enditemize
<br><br>

<br><i>Proof.</i>
  We prove the claim by induction on the cardinality of <span class='inline'>A</span>. 
  If <span class='inline'>A</span> is a singleton, then <span class='inline'>\prod_{a \in A} \prod_{i\in I_a} M_i</span> canonically
  coincides with <span class='inline'>\prod_{i\in I} M_i</span> and <span class='inline'>f: \prod_{i\in I_a} M_i \to N</span>
  is multilinear, hence by the universal property of the tensor product there
  exists a unique linear map <span class='inline'>\overline{f}: N_a \to N</span> such that
  <span class='inline'>f = \overline{f} \circ \tau_a</span>. 

  Now assume that the claim holds whenever the cardinality of the index set <span class='inline'>A</span> is
  <span class='inline'>\leq n</span> for some <span class='inline'>n \in \mathbb{N}^*</span>.
  Assume to be given initial data <span class='inline'>(M_i)_{i\in I}</span> and <span class='inline'>§N</span>, a partition
  <span class='inline'>(I_a)_{a\in A}</span> of <span class='inline'>A</span> with <span class='inline'>|A| = n+1</span> and  componentwise multilinear map
  <span class='inline'>f: \prod_{a\in A}\prod_{i\in I_a} M_i \to N</span>. Fix <span class='inline'>a \in A</span> and put
  <span class='inline'>B =A \setminus \{ a\}</span>. Let
  <span class='inline'>x = (x_i)_{i\in I_a} \in \prod_{i\in I_a}M_i</span>
  and <span class='inline'>\widetilde{x}</span> be the element of <span class='inline'> \prod_{d\in A}\prod_{i\in I_d} M_i </span> such that
  <br><br><span class='display'>
    \pi_d (\widetilde{x}) =
    \begin{cases}
      x &\text{for} \enspace d = a , \\
      0 &\text{else} .
    \end{cases}
  </span><br>
  The map
  <br><br><span class='display'>
    f_x: \prod_{b\in B}\prod_{i\in I_b} M_i \to N , \enspace
         y  \mapsto f (\iota_B (y) + \widetilde{x}) 
  </span><br>
  then is componentwise multilinear. Hence by inductive assumption there  exists
  a unique multilinear map <span class='inline'>\overline{f_x} : \prod_{b\in B}N_b \to N</span> such that
  <span class='inline'>f_x = \overline{f_x}\circ (\tau_b)_{b\in B}</span>. By assumption on <span class='inline'>f</span>
  the map
  <span class='inline'>\prod_{i\in I_a} M_i \to \mathfrak{Map} \left( \prod_{b\in B} \prod_{i\in I_b} M_i,N\right) </span>,
  <span class='inline'>x \mapsto f_x</span> is multilinear which implies multilinearity of
  <br><br><span class='display'>
    \overline{f_\bullet} :
    \prod_{i\in I_a} M_i \to \mathfrak{Mlin} \left( \prod_{b\in B} N_b ,N \right),
    \enspace x \mapsto \overline{f_x} .
  </span><br>
  Let <span class='inline'>F: N_a \to \mathfrak{Mlin} \left( \prod_{b\in B} N_b,N \right)</span> be its
  linearization. Application of the exponential law for multilinear maps,
  \Crefthm:exponential-law-multilinear-maps, now gives a
  multilinear map <span class='inline'>\eta (F) : \prod_{d \in A} N_d \to N</span> which we denote 
  by <span class='inline'>\overline{f}</span>. Given a family <span class='inline'>(x_d)_{d\in A}</span> of families
  <span class='inline'>x_d =(x_i)_{i\in I_d}</span> one checks
  <br><br><span class='display'>
    \overline{f} \left( \big(\tau_d (x_d)\big)_{d\in A} \right)
    = F \big( \tau_a(x_a) \big) \left( \big(\tau_b (x_b)\big)_{b\in B} \right)
    = \overline{f}_{x_a} \left( \big(\tau_b (x_b)\big)_{b\in B} \right)
    = f_{x_a} \left( (x_b)_{b\in B} \right) = f  \left( (x_d)_{d\in A} \right) .
  </span><br>
  Hence <span class='inline'>\overline{f} \circ (\tau_d)_{d\in A} =f</span>.
  To finish the induction step it remains to prove uniqueness.
  So let <span class='inline'>\overline{g} :  \prod_{d \in A} N_d \to N</span> be another multilinear map
  such that <span class='inline'>\overline{g} \circ (\tau_d)_{d\in A} =f</span>  and consider
  the induced linear map
  <span class='inline'>\overline{g}^\sharp =\eta^{-1} (\overline{g}) : N_a \mapsto \mathfrak{Mlin} (\prod_{b\in B}N_b, N)</span>.
  Then for every <span class='inline'>x\in \prod_{i\in I_a}M_i</span> the relation 
  <br><br><span class='display'>
    \overline{g}^\sharp (\tau_a(x)) \circ (\tau_b)_{b\in B} = f_x =
    \overline{f}_x \circ (\tau_b)_{b\in B} 
  </span><br>
  is satisfied. 
  Hence <span class='inline'>\overline{g}^\sharp (\tau(x)) = \overline{f}_x</span> for all <span class='inline'>x\in \prod_{i\in I_a}M_i</span> which entails
  that <span class='inline'>\overline{g}^\sharp</span> coincides with <span class='inline'>F</span>. By
  \Crefthm:exponential-law-multilinear-maps one obtains
  <span class='inline'>\overline{g} = \overline{f}</span>. This finishes the induction step and the lemma
  is proved. 


<br><br><strong>Proposition 30.12</strong>
  Let <span class='inline'>(M_i)_{i\in I}</span> be a family of <span class='inline'>R</span>-modules and <span class='inline'>(I_a)_{a\in A}</span> a finite partition of the index set <span class='inline'>I</span>.
  Then there exists a natural isomorphism
  <br><br><span class='display'>
    \alpha_{I,A}: \bigotimes_{i \in I} M_i \to \bigotimes_{a \in A}  \bigotimes_{i \in I_a} M_i .
  </span><br>  
<br><br>

<br><i>Proof.</i>
  Put <span class='inline'>N_a = \bigotimes_{i \in I_a} M_i</span>  for  <span class='inline'>a \in A</span> and let
  <span class='inline'>\tau_a :  \prod_{i \in I_a} M_i \to  N_a</span> be the canonical map to the tensor product.
  Let <span class='inline'>\tau_A :\prod_{a \in A}N_a \to \bigotimes_{a \in A} N_a</span> be the canonical map to
  the tensor product of the modules <span class='inline'>N_a</span>.
  Define <span class='inline'>\tau_{I,A}: \prod_{i \in I} M_i\to \prod_{a \in A} N_a</span> as the unique map so that
  <span class='inline'>\pi_a  \circ \tau_{I,A} = \tau_a \circ \pi_{I_a}</span>  for all <span class='inline'>a\in A</span>.
        By construction <span class='inline'>\tau_{I,A} = (\tau_a)_{a\in A} \circ \kappa_{I,A}</span>,
  where <span class='inline'>\kappa_{I,A} :  \prod_{i\in I} M_i \to \prod_{a \in A} \prod_{i \in I_a} M_i</span> is the natural isomorphism from
  \Crefthm:associator-cartesian-product.  
  The composition <span class='inline'>\tau_A \circ \tau_{I,A}</span> then is multilinear by \Crefthm:construction-multilinear-maps-composition
  (III), hence factors through a linear map
  <span class='inline'>\alpha_{I,A} : \bigotimes_{i\in I} M_i \to \bigotimes_{a \in A} N_a</span> 
  that is
  <br><br><span class='display'> \tag{30.1}
    \tau_A \circ (\tau_a)_{a\in A} \circ \kappa_{I,A} =
    \alpha_{I,A} \circ \tau_I .
  </span><br><br>  
     
  Naturality of <span class='inline'>\alpha_{I,A}</span> in  <span class='inline'>(M_i)_{i\in I}</span> is clear by definition so it remains to
  construct an inverse to <span class='inline'>\alpha_{I,A}</span>.  Consider the composition
  <span class='inline'>\tau_I \circ \kappa^{-1}: \prod_{a \in A} \prod_{i \in I_a} M_i
   \to \bigotimes_{i\in I} M_i</span>. Assume that <span class='inline'>a \in A</span> and
  <span class='inline'>(y_b)_{b\in A\setminus\{a\}} \in \prod_{b \in A\setminus\{a\}} \prod_{i \in I_b} M_i</span>
  have been chosen. Let <span class='inline'>y_a\in \prod_{i \in I_a} M_i</span> be <span class='inline'>0</span>, put
  <span class='inline'>\widetilde{y} =(y_d)_{d\in A} \in \prod_{d \in A}  \prod_{i \in I_d} M_i</span>, and let
  <span class='inline'>y\in  \prod_{i \in I} M_i</span> be the family such that <span class='inline'>\pi_i(y) = \pi_i (y_{a(i)})</span> for
  all <span class='inline'>i\in I</span>, where <span class='inline'>a(i)</span> denotes the unique element of <span class='inline'>A</span>  such that
  <span class='inline'>i\in I_{a(i)}</span>. In other words let <span class='inline'>y =\kappa^{-1} (\widetilde{y})</span>.
  For every <span class='inline'>j\in I_a</span> and <span class='inline'>x= (x_i)_{i\in I_a}\in \prod_{i\in I_a}M_i</span>
  with <span class='inline'>\pi_j (x)=0</span> the map
  <br><br><span class='display'>
    M_j \to \bigotimes_{i\in I} M_i,\enspace m \mapsto \tau_I \circ \kappa^{-1} \left( \iota_a (\iota_j(m)+x)+\widetilde{y}\right)
    = \tau_I \left( \iota_j (m) + \iota_{I_a}(x) + y \right)
  </span><br>
  then is multilinear since <span class='inline'>\tau_I</span> is multilinear and <span class='inline'>\pi_j(\iota_{I_a}(x) + y)=\pi_j(x) +\pi_j(y_a) = 0</span>.
  Hence <span class='inline'>\tau_I \circ \kappa^{-1}</span> is componentwise multilinear and therefore,
  by \Crefthm:componentwise-multilinear-maps-factorization, factors
  through the map
  <span class='inline'>(\tau_a)_{a\in A} : \prod_{a\in A} \prod_{i\in I_a} M_i\to \prod_{a\in A} N_a</span>
  which means that
  <br><br><span class='display'> \tag{30.2}
    \tau_I \circ \kappa^{-1} = \lambda_{I,A}\circ (\tau_a)_{a\in A}
  </span><br><br>
  for some uniquely defined multilinear map
  <span class='inline'>\lambda_{I,A} : \prod_{a\in A} N_a\to\bigotimes_{i\in I} M_i</span>.
  Let
  <br><br><span class='display'> \overline{\lambda}_{I,A} : \bigotimes_{a\in A} N_a\to\bigotimes_{i\in I} M_i</span><br>
  be the linearization of <span class='inline'>\lambda_{I,A}</span>.
  We claim that <span class='inline'>\overline{\lambda_{I,A}}</span> is inverse to <span class='inline'>\alpha_{I,A}</span>.
  By definition of <span class='inline'>\overline{\lambda_{I,A}}</span> and 
  Eqs.~\eqrefeq:defining-equation-associator-map-tensor-product and
  \eqrefeq:defining-equation-inverse-associator-map-tensor-product one concludes
    <br><br><span class='display'>
    \overline{\lambda_{I,A}} \circ \alpha_{I,A} \circ \tau_I =
    \overline{\lambda_{I,A}} \circ \tau_A \circ (\tau_a)_{a\in A} \circ \kappa_{I,A} =
    \lambda_{I,A} \circ (\tau_a)_{a\in A} \circ \kappa_{I,A} = \tau_I . 
  </span><br>
  Since the image of <span class='inline'>\tau_I</span> generates <span class='inline'>\bigotimes_{i\in I} M_i</span> as an <span class='inline'>R</span>-module,
  <span class='inline'>\overline{\lambda_{I,A}}</span> has to be left inverse to <span class='inline'>\alpha_{I,A}</span>.
  Using Eqs.~\eqrefeq:defining-equation-associator-map-tensor-product and
  \eqrefeq:defining-equation-inverse-associator-map-tensor-product again compute
  <br><br><span class='display'>
    \alpha_{I,A} \circ\overline{\lambda_{I,A}} \circ \tau_A \circ (\tau_a)_{a\in A} =
    \alpha_{I,A} \circ \lambda_{I,A} \circ (\tau_a)_{a\in A} = \alpha_{I,A}\circ\tau_A\circ \kappa_{I,A}^{-1}
    =  \tau_A \circ (\tau_a)_{a\in A} .    
  </span><br>
  Since by \Crefthm:image-generating-system-canoncial-map-finite-tensor-product-generating-system
  the image of
  <span class='inline'>\tau_A \circ (\tau_a)_{a\in A}</span> generates <span class='inline'>\bigotimes_{a \in A}  \bigotimes_{i \in I_a} M_i</span>,  the equality
  <br><br><span class='display'> \alpha_{I,A} \circ\overline{\lambda_{I,A}}=\mathrm{id}_{\bigotimes_{a \in A}  \bigotimes_{i \in I_a} M_i} </span><br>
  follows and the proposition is proved.


<br><br><strong>Proposition and Definition 30.13</strong>
  Let <span class='inline'>(A_i)_{i\in I}</span> be a family of <span class='inline'>R</span>-algebras. Then the tensor product
  <span class='inline'>A = \bigotimes_{i\in I} A_i</span> carries in a natural way the structure of an
  <span class='inline'>R</span>-algebra where the product map is defined by
  <br><br><span class='display'>
    \cdot :  A \times A \to A , \enspace
    (\otimes_{i\in I} a_i , \otimes_{i\in I} b_i)\mapsto
    \otimes_{i\in I} (a_i\cdot b_i) .
  </span><br>
  In case each of the algebras <span class='inline'>A_i</span> is commutative, then <span class='inline'>A</span> is commutative
  as well.
  Likewise, if each <span class='inline'>A_i</span> is unital and <span class='inline'>1_i</span> denotes the unit element of
  <span class='inline'>A_i</span>, then <span class='inline'>A</span> is unital with unit given by <span class='inline'>1 = \otimes_{i\in I} 1_i</span>.
  One calls <span class='inline'>A</span> the <i>tensor product algebra</i> of the family of algebras
  <span class='inline'>(A_i)_{i\in I}</span>.
<br><br>

<br><i>Proof.</i>
  The map
  <br><br><span class='display'>
    \prod_{(i,k)\in I \times \{ 1,2\}} A_i \to A,\enspace
    (a_{i,k})_{(i,k) \in I\times \{1,2\}} \mapsto\otimes_{i\in I}(a_{i,1}\cdot a_{i,2})
  </span><br>
  is multilinear by bilinearity of the product maps on the <span class='inline'>A_i</span> and multilinearity of <span class='inline'>\tau_I</span>,
  so factors through a linear map
  <span class='inline'>\mu: A \otimes A \cong \bigotimes_{(i,k)\in I\times \{1,2\}} A_i \to A</span>. Composition of
  <span class='inline'>\mu</span> with the canonical bilinear map <span class='inline'>A \times A \to A\otimes A</span> gives the product map
  <span class='inline'>\cdot : A \times A\to A</span>
  and shows that the product on <span class='inline'>A</span> is well-defined. By construction, the product map <span class='inline'>\cdot</span>
  is bilinear. Given <span class='inline'>\otimes_{i\in I} a_i, \otimes_{i\in I} b_i, \otimes_{i\in I} c_i \in A</span> one
  computes
  <br><br><span class='display'>
    \big( \otimes_{i\in I} a_i \cdot \otimes_{i\in I} b_i \big) \cdot \otimes_{i\in I} c_i
    = \otimes_{i\in I} ((a_i\cdot b_i)\cdot c_i) =
    \otimes_{i\in I} (a_i\cdot( b_i\cdot c_i)) =
    \otimes_{i\in I} a_i \cdot \big( \otimes_{i\in I} b_i  \cdot \otimes_{i\in I} c_i\big) .
  </span><br>
  This entails that the product on <span class='inline'>A</span> is associative. In the same way one shows
  that <span class='inline'>A</span> is commutive respectively unital if each of the <span class='inline'>A_i</span> is. 


<br><br><strong>30.14</strong>
As we have seen, the infinite tensor product construction works well for objects of
algebraic categories like <span class='inline'>R</span>-modules, vector spaces or <span class='inline'>R</span>-algebras. As soon as
a topologies compatible with the algebraic structure come in it becomes difficult and
sometimes even impossible to construct or even define 


 

\bibliographylmlib
\addcontentslinetocpartBibliography
\bibliographystylenewapa
\iheadBibliography
\ohead

\chapter*Licensing

\addcontentslinetocpartLicensing\iheadLicensing
\oheadGNU FDL v1.3
\addcontentslinetocchapterGNU FDL v1.3



</p>
</d-article>

  <d-appendix>
<p>XXXappendixXXX</p>

    <d-bibliography>
        

        <!--@article{gregor2015draw,
            title={DRAW: A recurrent neural network for image generation},
            author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
            journal={arXiv preprint arXiv:1502.04623},
            year={2015},
            url ={https://arxiv.org/pdf/1502.04623.pdf}
          }--->
    <script type="text/bibtex">
        
    </script>

      </d-bibliography>
    </d-appendix>

</body>

<script>
	var math_inline = document.getElementsByClassName('inline');
    for (var i = 0; i < math_inline.length; i++) {
      try {
        katex.render(math_inline[i].textContent, math_inline[i],{throwOnError: false});
      }catch (e) {
      }
    }

  var math_display = document.getElementsByClassName('display');
    for (var i = 0; i < math_display.length; i++) {
	    try {
      katex.render(math_display[i].textContent, math_display[i],{ displayMode: true ,throwOnError: false});
      }catch (e) {
      }
    }
</script>